{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836
    },
    "colab_type": "code",
    "id": "yK2a0WRCOqy9",
    "outputId": "c56c7bea-cffe-469f-b5ef-a557acf3518f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.18.2)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.9.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.3.1.1)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (3.11.2)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.11.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.22.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (4.41.1)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.21.0)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (19.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.18.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.13.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow_datasets) (42.0.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.25.7)\n",
      "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.51.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kZAMW8TOYy9T",
    "outputId": "91bace9c-fd7c-47f1-fafc-5309711e2016"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[1], True)\n",
    "\n",
    "\n",
    "#used to fix bug in keras preprocessing scope\n",
    "temp = tf.zeros([4, 32, 32, 3])  # Or tf.zeros\n",
    "preprocess_input(temp)\n",
    "print(\"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "UEte6RVRhXlm",
    "outputId": "1e130706-8752-403c-d997-74aeca7cbd05"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224)\n",
    "TRAIN_SIZE = 50000\n",
    "VALIDATION_SIZE = 10000\n",
    "BATCH_SIZE_PER_GPU = 96\n",
    "global_batch_size = (BATCH_SIZE_PER_GPU * 1)\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hwfFp6SPasyg"
   },
   "source": [
    "Dataset code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGYc-4KegKLc"
   },
   "outputs": [],
   "source": [
    "def flip(x: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Flip augmentation\n",
    "\n",
    "    Args:\n",
    "        x: Image to flip\n",
    "\n",
    "    Returns:\n",
    "        Augmented image\n",
    "    \"\"\"\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    x = tf.image.random_flip_up_down(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def color(x: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Color augmentation\n",
    "\n",
    "    Args:\n",
    "        x: Image\n",
    "\n",
    "    Returns:\n",
    "        Augmented image\n",
    "    \"\"\"\n",
    "    x = tf.image.random_hue(x, 0.08)\n",
    "    x = tf.image.random_saturation(x, 0.6, 1.6)\n",
    "    x = tf.image.random_brightness(x, 0.05)\n",
    "    x = tf.image.random_contrast(x, 0.7, 1.3)\n",
    "    return x\n",
    "\n",
    "def rotate(x: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Rotation augmentation\n",
    "\n",
    "    Args:\n",
    "        x: Image\n",
    "\n",
    "    Returns:\n",
    "        Augmented image\n",
    "    \"\"\"\n",
    "\n",
    "    return tf.image.rot90(x, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "\n",
    "def zoom(x: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Zoom augmentation\n",
    "\n",
    "    Args:\n",
    "        x: Image\n",
    "\n",
    "    Returns:\n",
    "        Augmented image\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate 20 crop settings, ranging from a 1% to 20% crop.\n",
    "    scales = list(np.arange(0.8, 1.0, 0.01))\n",
    "    boxes = np.zeros((len(scales), 4))\n",
    "\n",
    "    for i, scale in enumerate(scales):\n",
    "        x1 = y1 = 0.5 - (0.5 * scale)\n",
    "        x2 = y2 = 0.5 + (0.5 * scale)\n",
    "        boxes[i] = [x1, y1, x2, y2]\n",
    "\n",
    "    def random_crop(img):\n",
    "        # Create different crops for an image\n",
    "        crops = tf.image.crop_and_resize([img], boxes=boxes, box_indices=np.zeros(len(scales)), crop_size=IMAGE_SIZE)\n",
    "        # Return a random crop\n",
    "        return crops[tf.random.uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n",
    "\n",
    "\n",
    "    choice = tf.random.uniform(())\n",
    "\n",
    "    # Only apply cropping 50% of the time\n",
    "    return tf.cond(choice < 0.5, lambda: x, lambda: random_crop(x))\n",
    "\n",
    "def normalize(input_image):\n",
    "  return preprocess_input(input_image)\n",
    "\n",
    "@tf.function\n",
    "def load_image_train(datapoint):\n",
    "  input_image, label = tf.image.resize(datapoint[\"image\"], IMAGE_SIZE), datapoint['label']\n",
    "  # if tf.random.uniform(()) > 0.5:\n",
    "  #   input_image = tf.image.flip_left_right(input_image)\n",
    "  augmentations = [flip, color, zoom, rotate]\n",
    "  for f in augmentations:\n",
    "    input_image = tf.cond(tf.random.uniform(()) > 0.75, lambda: f(input_image), lambda: input_image)\n",
    "\n",
    "  #input_image = preprocess_input(input_image)\n",
    "  input_image = normalize(input_image)\n",
    "\n",
    "  return input_image, tf.one_hot(label, depth=NUM_CLASSES)\n",
    "\n",
    "@tf.function\n",
    "def load_image_test(datapoint):\n",
    "  input_image, label = tf.image.resize(datapoint[\"image\"], IMAGE_SIZE), datapoint['label']\n",
    "  #input_image = preprocess_input(input_image)\n",
    "\n",
    "  input_image = normalize(input_image)\n",
    "\n",
    "  return input_image, tf.one_hot(label, depth=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UgL-SFoObBw4"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "class LayerBatch(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, input_model, dataset):\n",
    "        self.input_model = input_model\n",
    "        self.dataset = dataset.__iter__()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.ceil(TRAIN_SIZE // global_batch_size )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.input_model(next(self.dataset))\n",
    "        return X, y\n",
    "    \n",
    "import math\n",
    "class LayerTest(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, input_model, dataset):\n",
    "        self.input_model = input_model\n",
    "        self.dataset = dataset.__iter__()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.ceil(VALIDATION_SIZE // global_batch_size )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.input_model(next(self.dataset))\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1O2h3lD9mejI"
   },
   "outputs": [],
   "source": [
    "def add_layers(inputs, layers=2):\n",
    "    X = tf.keras.layers.SeparableConv2D(name=f'sep_conv_{build_replacement.counter}', filters=inputs.get_shape()[-1], \n",
    "                                        kernel_size= (3,3),\n",
    "                                        padding='Same')(inputs)\n",
    "    #X = tf.keras.layers.BatchNormalization(name=f'batch_norm_{build_replacement.counter}')(X)\n",
    "    X = tf.keras.layers.ReLU(name=f'relu_{build_replacement.counter}')(X)\n",
    "    \n",
    "    build_replacement.counter += 1\n",
    "    \n",
    "    for i in range(1, layers):\n",
    "        X = tf.keras.layers.SeparableConv2D(name=f'sep_conv_{build_replacement.counter}', filters=inputs.get_shape()[-1],\n",
    "                                            kernel_size=(3,3), \n",
    "                                            padding='Same')(X)\n",
    "        #X = tf.keras.layers.BatchNormalization(name=f'batch_norm_{build_replacement.counter}')(X)\n",
    "        X = tf.keras.layers.ReLU(name=f'relu_{build_replacement.counter}')(X)\n",
    "        build_replacement.counter += 1\n",
    "    \n",
    "    return X\n",
    "    \n",
    "def build_replacement(get_output, layers=2):\n",
    "    inputs = tf.keras.Input(shape=get_output.output[0].shape[1::])\n",
    "    \n",
    "    X = add_layers(inputs, layers)\n",
    "    replacement_layers = tf.keras.Model(inputs=inputs, outputs=X)\n",
    "    return replacement_layers\n",
    "\n",
    "build_replacement.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5yGnQ2YTVmC1"
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_list(X):\n",
    "    if isinstance(X, list):\n",
    "        return X\n",
    "    return [X]\n",
    "\n",
    "def list_no_list(X):\n",
    "    if len(X) == 1:\n",
    "        return X[0]\n",
    "    return X\n",
    "\n",
    "def replace_layer(model, replace_layer_subname, replacement_fn,\n",
    "**kwargs):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        model :: keras.models.Model instance\n",
    "        replace_layer_subname :: str -- if str in layer name, replace it\n",
    "        replacement_fn :: fn to call to replace all instances\n",
    "            > fn output must produce shape as the replaced layers input\n",
    "    returns:\n",
    "        new model with replaced layers\n",
    "    quick examples:\n",
    "        want to just remove all layers with 'batch_norm' in the name:\n",
    "            > new_model = replace_layer(model, 'batch_norm', lambda **kwargs : (lambda u:u))\n",
    "        want to replace all Conv1D(N, m, padding='same') with an LSTM (lets say all have 'conv1d' in name)\n",
    "            > new_model = replace_layer(model, 'conv1d', lambda layer, **kwargs: LSTM(units=layer.filters, return_sequences=True)\n",
    "    \"\"\"\n",
    "    model_inputs = []\n",
    "    model_outputs = []\n",
    "    tsr_dict = {}\n",
    "\n",
    "    model_output_names = [out.name for out in make_list(model.output)]\n",
    "\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        ### Loop if layer is used multiple times\n",
    "        for j in range(len(layer._inbound_nodes)):\n",
    "\n",
    "            ### check layer inp/outp\n",
    "            inpt_names = [inp.name for inp in make_list(layer.get_input_at(j))]\n",
    "            outp_names = [out.name for out in make_list(layer.get_output_at(j))]\n",
    "\n",
    "            ### setup model inputs\n",
    "            if 'input' in layer.name:\n",
    "                for inpt_tsr in make_list(layer.get_output_at(j)):\n",
    "                    model_inputs.append(inpt_tsr)\n",
    "                    tsr_dict[inpt_tsr.name] = inpt_tsr\n",
    "                continue\n",
    "\n",
    "            ### setup layer inputs\n",
    "            # I added the exception model_3_3/Identity:0 I think the problem is that is the input layer\n",
    "            inpt = list_no_list([tsr_dict[name]  for name in inpt_names])\n",
    "\n",
    "            ### remake layer \n",
    "            if layer.name in replace_layer_subname:\n",
    "              if \"relu\" in layer.name or 'bn' in layer.name:\n",
    "                print('deleting ' + layer.name)\n",
    "                x = inpt\n",
    "              else:\n",
    "                print('replacing '+layer.name)\n",
    "                x = replacement_fn(inpt)\n",
    "            else:\n",
    "                x = layer(inpt)\n",
    "\n",
    "            ### reinstantialize outputs into dict\n",
    "            for name, out_tsr in zip(outp_names, make_list(x)):\n",
    "\n",
    "                ### check if is an output\n",
    "                if name in model_output_names:\n",
    "                    model_outputs.append(out_tsr)\n",
    "                tsr_dict[name] = out_tsr\n",
    "\n",
    "    return tf.keras.models.Model(model_inputs, model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rSiKGjbkZ9j0"
   },
   "outputs": [],
   "source": [
    "def replac(inp):\n",
    "    \n",
    "    return add_layers(inp, layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439,
     "referenced_widgets": [
      "85b3369294534e9a9ba5688aefa6b4a1",
      "037d640ac4344184acd4dbd27f3d1e65",
      "89f1b8ed63c3489198e17b8e8ab2be81",
      "6822853cea6d4a6e95575f6950330be2",
      "01df06a2707a486a99028df405c4cf17",
      "c882433eb399416b860cbd6e81ef29ef",
      "7968af4d08a84ee688361761964f0ce0",
      "6631d750d8cc40d3913134626f89176e",
      "a164b382a8934cdb922318d53f4f2d5d",
      "b05976a78a694bcb8d6f3c427af2a428",
      "44d14ef9e5064e548fa1a1ba6b9e0bd2",
      "8fadedd1c55a432c96905e2bb68282e0",
      "ccfe163873d944f98cae06a04e4120d2",
      "b5d613d984154ad394dfa15aec5b03e2",
      "ffa8e1877134430c973c9d605406dd2c",
      "c7111c5161464283aa9075cecddeab22",
      "a1e4a810cdd9474eaa76e25b3ef8d387",
      "c18c87dd3f1d44769263a45094f633f1",
      "5e550bdef03b4b399a95794b90c0c6f5",
      "196648347fb74e668b9e205f3afc157a",
      "2363abb3bee745a292a8b313016b9d37",
      "69cba96b0f4a4686be29d62d8c9b342d",
      "9b78074873b24b17951a0cf621ee7398",
      "ec7f49f9e75d44a78dff4dd544c262f4",
      "e94eb88a34b447f79b67e4dc0f437084",
      "2a81db0a5e874d2ab27702967997add4",
      "7cca8a3371284de9871a0bafec58b618",
      "d2a9b67bea774176a8ea7b8a527c9244",
      "92c5f2bbaf594a70b4a484d1927ea636",
      "319b7e4dbdaf43359fa5d4e244f16e74",
      "1e925e3031b84395ad9d91cf620c1aee",
      "72d73c0a269643f38f41f7168b2b7273",
      "17f56706a93a4b3a889572a44f8ca2cf",
      "6b2973eb04484bd9be0d312b8b8cf795",
      "fdad4d08019145bb8fabfc2a26581757",
      "dd3e90b7e53e4f5d9b3ce02e7e66b04c",
      "3d86e7fe99444af8ba96666a06a5d048",
      "6b3fcf5db95c4c6396dcdf682a2358cc",
      "445a35e0d6744ea09f15c2d434726f38",
      "bf37f4c25df0407fb8500e88656fef12",
      "a34e1edc304b420f8bf278189c79d163",
      "dcb1e0ef4eb14de48c26262195c9ced9",
      "3345eb5900d84a36ae7e0dc842086b69",
      "801e08b3293646b7be3b3551dcc6a814",
      "d7d2796702524d30b526b31c54052ca8",
      "8143f2874af440a5bbf44763e9e8d88d",
      "29fe3ee019404fea8d836ad8142bf1bb",
      "ad695bf29ce04fa3914d0cfb98cfa271",
      "8529c01dc6d74199bf27620d0e0bed75",
      "7cd9023fe33a4f19bc45c8529e33002c",
      "e9c899f4ac254c41b9e97242f331cf65",
      "a064129c1e2844fd8102a0ba2b3605f0",
      "8fdaed4cca534c7a87d82bbdb756d255",
      "178f108b968647e69f4cfc8b92d58c6f",
      "a01bfa27d30c4893b93b93b990a9db8b",
      "488530f0e5464c6881a96624fcb3f104",
      "3b5e718e47564e63a5b445b785050af8",
      "e95c14ba2c134328bb5cc9e47e96c849",
      "00bbf559bc2b4382a8f8cc7efec1e215",
      "8cb85ec15c1642088b913b0df8418569",
      "932df094e004439490a17f21ab36d951",
      "df2f582d95e64f38b43f6e46c304b58b",
      "c17f9a971b5b4b25ae18d6cde04f210b",
      "aeb85b20a90e4d9bb284c8dec0143d16",
      "f8d0898ddeda41dd8da824b5f328af1c",
      "3afe7a98e460439c8d2d137664cb644d",
      "efe1da6d661c4ad29804e15499822646",
      "7dad383ee1744684addc94a7196cfc27",
      "e24526fcc2c34fbe93bc3201472aacd3",
      "f314b77939d94027b5279559e8d439e9",
      "ec710e458b094cfbbe4fc833eea8b0a8",
      "e00625c08d424230abc03200b127fa99",
      "5820293dba6e46f482464ced31ab9d00",
      "75dd9abf182246e3993d20832a564f52",
      "3c99e900eb4b49759d39221f3b97057f",
      "8804782648e947d59100306fd1cbb113",
      "c4abe08501cb485e88c0b7a1a34d66b1",
      "9536d331871f4ab79b784bef66f480e8",
      "5b607cbe7df244c3aaf5a407bc25ec6b",
      "6b0705a1c162438fa01dc8723ab7cf39",
      "718b66ad3bb647e086e0763657c6adc7",
      "80914034cd9d4b84bf9a86cbfa92dcb0",
      "fe098d028b6148dfb24c8d76f8defa5d",
      "e5f4852f417b493daa2363dc89aba6ad",
      "35c068fdce914e60a3d3b90bb54616e4",
      "4b58120421154f5bafdb685bc27f0291",
      "2fbe8b93ad484562a5f560e1ac30a98c",
      "cd3d52f58a43462d871d2f3ba46e7337",
      "a13da48b270f412e95427f399e6e172c",
      "0bcb0f74d29c48daa5580e3a00b920c5",
      "6a24850934ca4c32b3caf4534103a529",
      "79de1f81bfd945cea860042f08b09c20",
      "d8b079b263ec46d7a8a545d45beb9f57",
      "913be084e16e46b5b56a60e6bf3fec65",
      "088197bb7e574f9a9777596e3eff2e7a",
      "9551c270aed34b9080308cf79245c15a",
      "7e029e943a4c4ce0bf706aacb526f427",
      "e920f480a3b6466fa3d97a312b2c593e",
      "c7d7e95fe9264adeb95c249b4c87b746",
      "9e9bfd6e60264400a6ee1903b435b276",
      "a0eec14ac94744c598bf2cef825cae25",
      "cd6df235ab5b4eb2b7751d73e3b95328",
      "6c286d9756054a60a77124df7cf49357",
      "d9d25f537a9949a2ae272159cf26fd77",
      "d5c79dc23c2a4ebfa2b05653eeb48172",
      "50fe61b368464dc1aac03d2f5a9b3353",
      "f1ee35450304428eae8445e012e06c62",
      "136a59f531af4aff946c056d35d16cc1",
      "1a7a8f8f906a45a0b469682fda4d5b48",
      "cccea809b5cb43ceb227477a50827d73",
      "e6eb8c0850fb4aaf8470b98b2f1a9590",
      "4d4db9b8c8fb4351be91b3700431d081",
      "e9665f28c72642e18a8a019e1fca2ca1",
      "e8f93da361554abea6cb1397d8efcc63",
      "3ebb2da0813c470b815d537b0fde2f5a",
      "4be93a6d768645e5ad4f1b4d1502d908",
      "3c9d01b657df4e8fa99b5a905225a5ca",
      "93e8cf3b87a9438785fa91bcf741f63a",
      "7a470465eeb243358efd8260502d9da2",
      "59e5e76bf0a84fd99ef61df58cf6aa74",
      "ab0e9d315b1d4ba6ae3af8c4eaac5caf",
      "cf649c70c2114fddb27c86a3562b271b",
      "3ff0c249f9014799babc3d99627e50f8",
      "3f064a661b064c9dbe8565226d6e8b57",
      "aa2bfdf132884c778be3168c59d030df",
      "9deb7e94f2e74480ac22752417dccbf1",
      "5b30f8f0caa4437f83e07be0429cf06f",
      "ef78e1d4fdb947c9940eac1944c8ea32",
      "7571f585dcaf412c8fabfe3da4e90a72",
      "494b5bde4c4c48c5ad384603eae6aef3",
      "7a18bce53be24c3a8d79f44cb78f76c0",
      "2319ccc93aa54b4a84de0fd0f8638278",
      "d9521dbb25a443f1839db5fbc7676e77",
      "e11c504fc39146138d3dc43df5fd6bc4",
      "28dca6cd4300492a8e8f13a0e41ccd22",
      "871123b141d8405580c1a0b47c8f193c",
      "c09bd93b56524a169a638ed6304854aa",
      "3071e0a0a0584f298e6dc73dfe5a9574",
      "973972ee071f4177b78d8c360db6bc16",
      "b003544ca82c4aa8955367d28e6beab3",
      "bebcb612c1454e47892a9686eb4c5c57",
      "593fc579dec14f5d8f39a75e0d8a4445",
      "3309caa1185749b8a4cc046052312f28",
      "56986dc4f2254c67af73140ca4dfedbc",
      "061c75d2a6c0422881c00dcf2078c42a",
      "0cd4f58e1c2c466e971f7be8d6d35768",
      "76e757f0395e46b29cca95688d2279e8",
      "b6b7230688334a79a95670ca8cbf5b45",
      "89972f1978be44d893c42720b83cc758",
      "bfc07890a6124155891b4180012ff16a",
      "6283aac770ee4f3099d3d296c48601b0",
      "e2933054e28c460eae2888ef050c8f3b",
      "050aacaf209547d0bc9899c6f3f4d604",
      "6fd2321c588b4d6a88d217b38f7913b4",
      "e51abbcd797a4f22a31f322979a1a821",
      "8c5e71a92ff4497aa6163288cf7ede91",
      "22ea888608bb446e9047981855ee06aa",
      "3037c2a0ab13465281680dd390aded89",
      "1235e70c7520425fa23d470e34e6a418",
      "5b02c906910147b7af7f0dc54b4b948a",
      "94d26bdc3d3f49adbc2929876737643d",
      "fa48a8c281df4b32b69cbb6c57ab3bc6",
      "26dba2cdb1594b728eaa5cbdafe00c6d",
      "75ed948182124fd88ac3383684630432",
      "c229e5748afa453986e6a4ec0412eea4",
      "327614665cd44d5c8e499d15deabdb54",
      "abb6ef548f64470e919e3b09b8266bcb",
      "7ccbd3d75d1c4cb08c0cb291086c047c",
      "ccf20edd1af245b39937aaa40fdf31f0",
      "6a141d5397e8415eb4dd45b69efabcce",
      "f8406bd06c1047009746d0d5336d9073",
      "645ff814089b424ea3da696f6e219815",
      "e0a7f7d0162042b5b411703c3e00ecc5",
      "deadeff67052419cb78bee3638fc2abf",
      "26d8caefc8754651abf70d13d6fc16ce",
      "99ffcf9dd93f4cfbb3ceddc2bb641054",
      "8444725e7bc04db18ad12ec10b8200f6",
      "749e5f565efe4925aa792ec8dc317dae",
      "5bd2c5a241d64785b2e22b1a2524e768",
      "9788f736aed049c286ba5f5c5e3e7132",
      "fa68b8c8d9f34d8193ab02c53e997c6a",
      "9f1ee8b521d7416eb5fe9d6a14ed83f5",
      "71e7570521624ca6b48d751f4c02dda9",
      "b2c7e622431d4b6e90761e83d537a85f",
      "86e1e68d54394142a94fa4e405116ace",
      "6bf9513279eb41b1955eb80a2cb88d6b",
      "2ab619854393458f89b10cf629d66f16",
      "7b98191fb51d4a3aae1cf1dcf546448c",
      "b23f4177df314748b1d89a8d517483da",
      "dc066bc0384747c2bb5cc9e38cc83fe9",
      "1cd3102e4bcb4852a131fcf237a4f823",
      "363269bd4c2648068daeeccc55eb4362",
      "a1073d8a8f2448cf98493ac47ffc6c97",
      "7137ed2e9650437e8b46124c4a291194",
      "351ff6e9d03c49fa9407956ccdf55882",
      "8dd41daa3cbd4b5498f1218db858546f",
      "dc231257ca024a76abc7fb01987e1a80",
      "1520a6bb52ac48269b13fc0154e56311",
      "490491523e3d429cb3d138f597ec30ea",
      "3a3a67866dfb4140be51c74d530be281",
      "20dae69db80943bbb771468b2dd3bbd7",
      "a7e0f33ef31340e08c5d054d757f7ff7",
      "b532e0d5f5bb4fe48e5837b24089cbc4",
      "4d882e72c59f414a8a5592f6820793f0",
      "4c7737be5fac490ca86d490a617ad2d3",
      "c792ac14b5114d9b842d929b46c187bf",
      "1d6de2d069cb40469647afe97dbedafa",
      "bb8b22d4b2bf451f895bbb5fe58f0d5c",
      "e990e901afaf46ccbfd1bee97ace949d",
      "27e833a113b74846906f34612ab4ab3b",
      "4d21268bcab14126a9ea6fac94831b84",
      "3bf80b32406e40cf8777f027aa0fcb67",
      "aed75a1fb79a4f08861245ae4927a57e",
      "2213f20428444ffe91ea8ec4fca4d937",
      "457d3c84187c48d580f3f58898a65020",
      "2a4bf872871045e28f58266aff72db3f",
      "23353a3aa8b948fa82f8aef2127170a7",
      "7c0ed0caa2044d5d97d36df4437342b3",
      "2e1fd6599f5844ab954a8342222f6d41",
      "37d80bb8cf0a40f1991c2029d050d8a4",
      "a2abbd1283984189aaf562eff5dd563e",
      "34f27f156c7f443093ca85f20332444e",
      "2547014e99a0411cbce96d806b7eec8e",
      "f207995c4dbe4806884d759e9a70edde",
      "00ea0dbf84e84d96af7065bfb535faba",
      "6ff5a866f4424ab699f7320d228b3624",
      "e942eb48d26f44f8a255b030b8523426",
      "faab1fbeb7324d07a5532654955162c0",
      "aef0f19968184c6b9265f740a35a26f6",
      "6badd05a454f4d55941d941cf8549357",
      "886b091d3c504c93b39596cd8ce52345",
      "e9b5734a4ed34779a19e89ef23b91191"
     ]
    },
    "colab_type": "code",
    "id": "Wi9OFugvd85a",
    "outputId": "6b72af03-2585-4237-e567-0c540ff48c03"
   },
   "outputs": [],
   "source": [
    "dataset, info = tfds.load('cifar10', with_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_OHrf43azEp"
   },
   "source": [
    "make the upscaled cifar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYzRISF_h8Wo"
   },
   "outputs": [],
   "source": [
    "train = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train.shuffle(buffer_size=1000).batch(global_batch_size).repeat()\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "test_dataset = dataset['test'].map(load_image_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(global_batch_size).repeat()\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YVr1N14ybKLx"
   },
   "source": [
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DzwGO6qbbVlL"
   },
   "source": [
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "T1kyqkChb-H7",
    "outputId": "2666f3bf-32d5-44e6-c963-79cf8876f351"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./base_model_cifar10_resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.SGD(learning_rate=.01, momentum=.9, nesterov=True), loss='mse', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "XbZF7t1k35e-",
    "outputId": "f25be1fe-678b-4d8b-95a0-e9c9f566a02d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/104 [..............................] - ETA: 6:29"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " Blas GEMM launch failed : a.shape=(96, 2048), b.shape=(2048, 10), m=96, n=10, k=2048\n\t [[node model/dense/MatMul (defined at <ipython-input-19-2cb165b647e8>:1) ]] [Op:__inference_distributed_function_26548]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2cb165b647e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALIDATION_SIZE\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mglobal_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m   def predict(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m   def predict(self, model, x, batch_size=None, verbose=0, steps=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    636\u001b[0m               *args, **kwds)\n\u001b[1;32m    637\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m:  Blas GEMM launch failed : a.shape=(96, 2048), b.shape=(2048, 10), m=96, n=10, k=2048\n\t [[node model/dense/MatMul (defined at <ipython-input-19-2cb165b647e8>:1) ]] [Op:__inference_distributed_function_26548]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_dataset, steps=VALIDATION_SIZE//global_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make list of target layers to replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "NGwvaJEI9Tix",
    "outputId": "c49bc449-1212-4aa3-878f-e35fdf08c66a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'layer': 10, 'name': 'conv2_block1_2_conv'},\n",
      " {'layer': 22, 'name': 'conv2_block2_2_conv'},\n",
      " {'layer': 32, 'name': 'conv2_block3_2_conv'},\n",
      " {'layer': 42, 'name': 'conv3_block1_2_conv'},\n",
      " {'layer': 54, 'name': 'conv3_block2_2_conv'},\n",
      " {'layer': 64, 'name': 'conv3_block3_2_conv'},\n",
      " {'layer': 74, 'name': 'conv3_block4_2_conv'},\n",
      " {'layer': 84, 'name': 'conv4_block1_2_conv'},\n",
      " {'layer': 96, 'name': 'conv4_block2_2_conv'},\n",
      " {'layer': 106, 'name': 'conv4_block3_2_conv'},\n",
      " {'layer': 116, 'name': 'conv4_block4_2_conv'},\n",
      " {'layer': 126, 'name': 'conv4_block5_2_conv'},\n",
      " {'layer': 136, 'name': 'conv4_block6_2_conv'},\n",
      " {'layer': 146, 'name': 'conv5_block1_2_conv'},\n",
      " {'layer': 158, 'name': 'conv5_block2_2_conv'},\n",
      " {'layer': 168, 'name': 'conv5_block3_2_conv'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "targets = []\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if layer.__class__.__name__ == \"Conv2D\":\n",
    "        if layer.kernel_size[0] == 3:\n",
    "            #print(f'{i} layer {layer.name} , kernel size {layer.kernel_size}')\n",
    "            targets.append({'name': layer.name, 'layer': i})\n",
    "\n",
    "pprint.pprint(targets)\n",
    "\n",
    "targets[0]['name'][:-4]\n",
    "\n",
    "# add all layers to replace\n",
    "for target in targets:\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if target['name'][:-4] in layer.name:\n",
    "            if 'to_replace' in target:\n",
    "                target['to_replace'].append((layer.name, i))\n",
    "            else:\n",
    "                target['to_replace'] = [(layer.name, i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperdash import monitor_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 684
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "7aFvw1tnEftn",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "c4b12909-606f-4bfc-e88e-07f814aa46ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training layer conv2_block1_2_conv\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 520 steps, validate for 104 steps\n",
      "Epoch 1/250\n",
      "520/520 - 80s - loss: 0.2173 - val_loss: 0.0531\n",
      "Epoch 2/250\n",
      "520/520 - 82s - loss: 0.0420 - val_loss: 0.0327\n",
      "Epoch 3/250\n",
      "520/520 - 83s - loss: 0.0301 - val_loss: 0.0281\n",
      "Epoch 4/250\n",
      "520/520 - 83s - loss: 0.0267 - val_loss: 0.0257\n",
      "Epoch 5/250\n",
      "520/520 - 83s - loss: 0.0252 - val_loss: 0.0242\n",
      "Epoch 6/250\n",
      "520/520 - 83s - loss: 0.0240 - val_loss: 0.0232\n",
      "Epoch 7/250\n",
      "520/520 - 83s - loss: 0.0233 - val_loss: 0.0235\n",
      "Epoch 8/250\n",
      "520/520 - 83s - loss: 0.0228 - val_loss: 0.0232\n",
      "Epoch 9/250\n",
      "520/520 - 83s - loss: 0.0224 - val_loss: 0.0221\n",
      "Epoch 10/250\n",
      "520/520 - 83s - loss: 0.0212 - val_loss: 0.0203\n",
      "Epoch 11/250\n",
      "520/520 - 83s - loss: 0.0205 - val_loss: 0.0201\n",
      "Epoch 12/250\n",
      "520/520 - 83s - loss: 0.0202 - val_loss: 0.0198\n",
      "Epoch 13/250\n",
      "520/520 - 83s - loss: 0.0200 - val_loss: 0.0198\n",
      "Epoch 14/250\n",
      "520/520 - 83s - loss: 0.0199 - val_loss: 0.0198\n",
      "Epoch 15/250\n",
      "520/520 - 83s - loss: 0.0196 - val_loss: 0.0195\n",
      "Epoch 16/250\n",
      "520/520 - 83s - loss: 0.0195 - val_loss: 0.0194\n",
      "Epoch 17/250\n",
      "520/520 - 83s - loss: 0.0192 - val_loss: 0.0176\n",
      "Epoch 18/250\n",
      "520/520 - 83s - loss: 0.0176 - val_loss: 0.0170\n",
      "Epoch 19/250\n",
      "520/520 - 83s - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 20/250\n",
      "520/520 - 83s - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 21/250\n",
      "520/520 - 83s - loss: 0.0169 - val_loss: 0.0165\n",
      "Epoch 22/250\n",
      "520/520 - 83s - loss: 0.0169 - val_loss: 0.0164\n",
      "Epoch 23/250\n",
      "520/520 - 83s - loss: 0.0168 - val_loss: 0.0164\n",
      "Epoch 24/250\n",
      "520/520 - 83s - loss: 0.0166 - val_loss: 0.0164\n",
      "Epoch 25/250\n",
      "520/520 - 83s - loss: 0.0165 - val_loss: 0.0163\n",
      "Epoch 26/250\n",
      "520/520 - 83s - loss: 0.0165 - val_loss: 0.0164\n",
      "Epoch 27/250\n",
      "520/520 - 83s - loss: 0.0159 - val_loss: 0.0153\n",
      "Epoch 28/250\n",
      "520/520 - 83s - loss: 0.0155 - val_loss: 0.0160\n",
      "Epoch 29/250\n",
      "520/520 - 83s - loss: 0.0155 - val_loss: 0.0152\n",
      "Epoch 30/250\n",
      "520/520 - 83s - loss: 0.0154 - val_loss: 0.0151\n",
      "Epoch 31/250\n",
      "520/520 - 83s - loss: 0.0153 - val_loss: 0.0153\n",
      "Epoch 32/250\n",
      "520/520 - 83s - loss: 0.0153 - val_loss: 0.0156\n",
      "Epoch 33/250\n",
      "520/520 - 83s - loss: 0.0152 - val_loss: 0.0151\n",
      "Epoch 34/250\n",
      "520/520 - 83s - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 35/250\n",
      "520/520 - 83s - loss: 0.0151 - val_loss: 0.0149\n",
      "Epoch 36/250\n",
      "520/520 - 83s - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 37/250\n",
      "520/520 - 83s - loss: 0.0150 - val_loss: 0.0147\n",
      "Epoch 38/250\n",
      "520/520 - 83s - loss: 0.0149 - val_loss: 0.0153\n",
      "Epoch 39/250\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.030000000447034835.\n",
      "520/520 - 83s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 40/250\n",
      "520/520 - 83s - loss: 0.0147 - val_loss: 0.0146\n",
      "Epoch 41/250\n",
      "520/520 - 83s - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 42/250\n",
      "520/520 - 83s - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 43/250\n",
      "520/520 - 83s - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 44/250\n",
      "520/520 - 84s - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 45/250\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.009000000357627868.\n",
      "520/520 - 83s - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 46/250\n",
      "520/520 - 83s - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 47/250\n",
      "520/520 - 83s - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 48/250\n",
      "520/520 - 83s - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 49/250\n",
      "520/520 - 83s - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 50/250\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.002700000163167715.\n",
      "520/520 - 83s - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 51/250\n",
      "520/520 - 83s - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 52/250\n",
      "520/520 - 83s - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 53/250\n",
      "520/520 - 83s - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 54/250\n",
      "520/520 - 83s - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 55/250\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0008100000210106373.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "520/520 - 83s - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 00055: early stopping\n",
      "training layer conv2_block2_2_conv\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 520 steps, validate for 104 steps\n",
      "Epoch 1/250\n",
      "520/520 - 88s - loss: 0.2494 - val_loss: 0.1234\n",
      "Epoch 2/250\n",
      "520/520 - 87s - loss: 0.1031 - val_loss: 0.0886\n",
      "Epoch 3/250\n",
      "520/520 - 88s - loss: 0.0814 - val_loss: 0.0749\n",
      "Epoch 4/250\n",
      "520/520 - 88s - loss: 0.0718 - val_loss: 0.0682\n",
      "Epoch 5/250\n",
      "520/520 - 87s - loss: 0.0663 - val_loss: 0.0635\n",
      "Epoch 6/250\n",
      "520/520 - 87s - loss: 0.0621 - val_loss: 0.0601\n",
      "Epoch 7/250\n",
      "520/520 - 88s - loss: 0.0595 - val_loss: 0.0578\n",
      "Epoch 8/250\n",
      "520/520 - 88s - loss: 0.0571 - val_loss: 0.0559\n",
      "Epoch 9/250\n",
      "520/520 - 87s - loss: 0.0556 - val_loss: 0.0545\n",
      "Epoch 10/250\n",
      "520/520 - 87s - loss: 0.0544 - val_loss: 0.0535\n",
      "Epoch 11/250\n",
      "Unable to send heartbeat message\n",
      "520/520 - 87s - loss: 0.0511 - val_loss: 0.0455\n",
      "Epoch 12/250\n",
      "520/520 - 87s - loss: 0.0451 - val_loss: 0.0443\n",
      "Epoch 13/250\n",
      "520/520 - 87s - loss: 0.0432 - val_loss: 0.0415\n",
      "Epoch 14/250\n",
      "520/520 - 87s - loss: 0.0415 - val_loss: 0.0405\n",
      "Epoch 15/250\n",
      "520/520 - 87s - loss: 0.0407 - val_loss: 0.0398\n",
      "Epoch 16/250\n",
      "520/520 - 87s - loss: 0.0401 - val_loss: 0.0393\n",
      "Epoch 17/250\n",
      "520/520 - 87s - loss: 0.0396 - val_loss: 0.0389\n",
      "Epoch 18/250\n",
      "520/520 - 88s - loss: 0.0392 - val_loss: 0.0385\n",
      "Epoch 19/250\n",
      "520/520 - 87s - loss: 0.0387 - val_loss: 0.0382\n",
      "Epoch 20/250\n",
      "520/520 - 87s - loss: 0.0386 - val_loss: 0.0378\n",
      "Epoch 21/250\n",
      "520/520 - 87s - loss: 0.0381 - val_loss: 0.0376\n",
      "Epoch 22/250\n",
      "520/520 - 87s - loss: 0.0378 - val_loss: 0.0374\n",
      "Epoch 23/250\n",
      "520/520 - 87s - loss: 0.0376 - val_loss: 0.0370\n",
      "Epoch 24/250\n",
      "520/520 - 87s - loss: 0.0372 - val_loss: 0.0365\n",
      "Epoch 25/250\n",
      "520/520 - 88s - loss: 0.0370 - val_loss: 0.0363\n",
      "Epoch 26/250\n",
      "520/520 - 87s - loss: 0.0368 - val_loss: 0.0361\n",
      "Epoch 27/250\n",
      "520/520 - 87s - loss: 0.0365 - val_loss: 0.0360\n",
      "Epoch 28/250\n",
      "520/520 - 86s - loss: 0.0364 - val_loss: 0.0359\n",
      "Epoch 29/250\n",
      "520/520 - 87s - loss: 0.0363 - val_loss: 0.0357\n",
      "Epoch 30/250\n",
      "520/520 - 87s - loss: 0.0361 - val_loss: 0.0355\n",
      "Epoch 31/250\n",
      "520/520 - 87s - loss: 0.0360 - val_loss: 0.0354\n",
      "Epoch 32/250\n",
      "520/520 - 87s - loss: 0.0359 - val_loss: 0.0352\n",
      "Epoch 33/250\n",
      "520/520 - 87s - loss: 0.0355 - val_loss: 0.0346\n",
      "Epoch 34/250\n",
      "520/520 - 87s - loss: 0.0315 - val_loss: 0.0259\n",
      "Epoch 35/250\n",
      "520/520 - 87s - loss: 0.0260 - val_loss: 0.0262\n",
      "Epoch 36/250\n",
      "520/520 - 87s - loss: 0.0256 - val_loss: 0.0248\n",
      "Epoch 37/250\n",
      "520/520 - 87s - loss: 0.0252 - val_loss: 0.0246\n",
      "Epoch 38/250\n",
      "520/520 - 87s - loss: 0.0251 - val_loss: 0.0246\n",
      "Epoch 39/250\n",
      "520/520 - 87s - loss: 0.0249 - val_loss: 0.0244\n",
      "Epoch 40/250\n",
      "520/520 - 87s - loss: 0.0248 - val_loss: 0.0247\n",
      "Epoch 41/250\n",
      "520/520 - 87s - loss: 0.0247 - val_loss: 0.0241\n",
      "Epoch 42/250\n",
      "520/520 - 87s - loss: 0.0246 - val_loss: 0.0240\n",
      "Epoch 43/250\n",
      "520/520 - 87s - loss: 0.0244 - val_loss: 0.0242\n",
      "Epoch 44/250\n",
      "520/520 - 88s - loss: 0.0245 - val_loss: 0.0238\n",
      "Epoch 45/250\n",
      "520/520 - 87s - loss: 0.0244 - val_loss: 0.0237\n",
      "Epoch 46/250\n",
      "520/520 - 87s - loss: 0.0243 - val_loss: 0.0237\n",
      "Epoch 47/250\n",
      "520/520 - 87s - loss: 0.0241 - val_loss: 0.0236\n",
      "Epoch 48/250\n",
      "520/520 - 87s - loss: 0.0240 - val_loss: 0.0235\n",
      "Epoch 49/250\n",
      "520/520 - 87s - loss: 0.0241 - val_loss: 0.0236\n",
      "Epoch 50/250\n",
      "520/520 - 87s - loss: 0.0239 - val_loss: 0.0234\n",
      "Epoch 51/250\n",
      "520/520 - 87s - loss: 0.0238 - val_loss: 0.0238\n",
      "Epoch 52/250\n",
      "520/520 - 87s - loss: 0.0238 - val_loss: 0.0233\n",
      "Epoch 53/250\n",
      "520/520 - 87s - loss: 0.0237 - val_loss: 0.0233\n",
      "Epoch 54/250\n",
      "520/520 - 87s - loss: 0.0237 - val_loss: 0.0232\n",
      "Epoch 55/250\n",
      "520/520 - 87s - loss: 0.0236 - val_loss: 0.0223\n",
      "Epoch 56/250\n",
      "520/520 - 87s - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 57/250\n",
      "520/520 - 87s - loss: 0.0207 - val_loss: 0.0207\n",
      "Epoch 58/250\n",
      "520/520 - 87s - loss: 0.0205 - val_loss: 0.0205\n",
      "Epoch 59/250\n",
      "520/520 - 88s - loss: 0.0205 - val_loss: 0.0206\n",
      "Epoch 60/250\n",
      "520/520 - 87s - loss: 0.0203 - val_loss: 0.0209\n",
      "Epoch 61/250\n",
      "520/520 - 87s - loss: 0.0203 - val_loss: 0.0198\n",
      "Epoch 62/250\n",
      "520/520 - 87s - loss: 0.0203 - val_loss: 0.0201\n",
      "Epoch 63/250\n",
      "520/520 - 87s - loss: 0.0202 - val_loss: 0.0198\n",
      "Epoch 64/250\n",
      "520/520 - 87s - loss: 0.0202 - val_loss: 0.0201\n",
      "Epoch 65/250\n",
      "520/520 - 87s - loss: 0.0201 - val_loss: 0.0201\n",
      "Epoch 66/250\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.030000000447034835.\n",
      "520/520 - 87s - loss: 0.0201 - val_loss: 0.0213\n",
      "Epoch 67/250\n",
      "520/520 - 87s - loss: 0.0197 - val_loss: 0.0194\n",
      "Epoch 68/250\n",
      "520/520 - 87s - loss: 0.0197 - val_loss: 0.0194\n",
      "Epoch 69/250\n",
      "520/520 - 87s - loss: 0.0196 - val_loss: 0.0194\n",
      "Epoch 70/250\n",
      "520/520 - 87s - loss: 0.0196 - val_loss: 0.0194\n",
      "Epoch 71/250\n",
      "520/520 - 87s - loss: 0.0196 - val_loss: 0.0194\n",
      "Epoch 72/250\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.009000000357627868.\n",
      "520/520 - 87s - loss: 0.0196 - val_loss: 0.0194\n",
      "Epoch 73/250\n",
      "520/520 - 87s - loss: 0.0196 - val_loss: 0.0194\n",
      "Epoch 74/250\n",
      "520/520 - 87s - loss: 0.0196 - val_loss: 0.0194\n",
      "Epoch 75/250\n",
      "520/520 - 87s - loss: 0.0196 - val_loss: 0.0194\n",
      "Epoch 76/250\n",
      "520/520 - 87s - loss: 0.0196 - val_loss: 0.0194\n",
      "Epoch 77/250\n",
      "520/520 - 87s - loss: 0.0196 - val_loss: 0.0193\n",
      "Epoch 78/250\n",
      "520/520 - 87s - loss: 0.0196 - val_loss: 0.0194\n",
      "Epoch 79/250\n",
      "520/520 - 87s - loss: 0.0196 - val_loss: 0.0193\n",
      "Epoch 80/250\n",
      "520/520 - 87s - loss: 0.0195 - val_loss: 0.0194\n",
      "Epoch 81/250\n",
      "520/520 - 87s - loss: 0.0195 - val_loss: 0.0194\n",
      "Epoch 82/250\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 0.002700000163167715.\n",
      "520/520 - 87s - loss: 0.0196 - val_loss: 0.0193\n",
      "Epoch 83/250\n",
      "520/520 - 87s - loss: 0.0195 - val_loss: 0.0193\n",
      "Epoch 84/250\n",
      "520/520 - 88s - loss: 0.0195 - val_loss: 0.0193\n",
      "Epoch 85/250\n",
      "520/520 - 87s - loss: 0.0195 - val_loss: 0.0193\n",
      "Epoch 86/250\n",
      "520/520 - 87s - loss: 0.0196 - val_loss: 0.0193\n",
      "Epoch 87/250\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.0008100000210106373.\n",
      "520/520 - 87s - loss: 0.0195 - val_loss: 0.0193\n",
      "Epoch 88/250\n",
      "520/520 - 87s - loss: 0.0196 - val_loss: 0.0193\n",
      "Epoch 89/250\n",
      "520/520 - 87s - loss: 0.0195 - val_loss: 0.0193\n",
      "Epoch 90/250\n",
      "520/520 - 87s - loss: 0.0195 - val_loss: 0.0193\n",
      "Epoch 91/250\n",
      "520/520 - 87s - loss: 0.0195 - val_loss: 0.0193\n",
      "Epoch 92/250\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.00024299999931827186.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "520/520 - 87s - loss: 0.0195 - val_loss: 0.0193\n",
      "Epoch 00092: early stopping\n",
      "training layer conv2_block3_2_conv\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 520 steps, validate for 104 steps\n",
      "Epoch 1/250\n",
      "520/520 - 90s - loss: 0.4516 - val_loss: 0.2116\n",
      "Epoch 2/250\n",
      "520/520 - 89s - loss: 0.1673 - val_loss: 0.1396\n",
      "Epoch 3/250\n",
      "520/520 - 89s - loss: 0.1238 - val_loss: 0.1117\n",
      "Epoch 4/250\n",
      "520/520 - 91s - loss: 0.1025 - val_loss: 0.0864\n",
      "Epoch 5/250\n",
      "520/520 - 90s - loss: 0.0770 - val_loss: 0.0715\n",
      "Epoch 6/250\n",
      "520/520 - 90s - loss: 0.0682 - val_loss: 0.0644\n",
      "Epoch 7/250\n",
      "520/520 - 90s - loss: 0.0620 - val_loss: 0.0591\n",
      "Epoch 8/250\n",
      "520/520 - 90s - loss: 0.0575 - val_loss: 0.0543\n",
      "Epoch 9/250\n",
      "520/520 - 89s - loss: 0.0536 - val_loss: 0.0510\n",
      "Epoch 10/250\n",
      "520/520 - 90s - loss: 0.0506 - val_loss: 0.0506\n",
      "Epoch 11/250\n",
      "520/520 - 89s - loss: 0.0473 - val_loss: 0.0487\n",
      "Epoch 12/250\n",
      "520/520 - 90s - loss: 0.0451 - val_loss: 0.0451\n",
      "Epoch 13/250\n",
      "520/520 - 90s - loss: 0.0435 - val_loss: 0.0415\n",
      "Epoch 14/250\n",
      "520/520 - 90s - loss: 0.0420 - val_loss: 0.0433\n",
      "Epoch 15/250\n",
      "520/520 - 90s - loss: 0.0406 - val_loss: 0.0389\n",
      "Epoch 16/250\n",
      "520/520 - 90s - loss: 0.0397 - val_loss: 0.0379\n",
      "Epoch 17/250\n",
      "520/520 - 90s - loss: 0.0386 - val_loss: 0.0385\n",
      "Epoch 18/250\n",
      "520/520 - 91s - loss: 0.0378 - val_loss: 0.0361\n",
      "Epoch 19/250\n",
      "520/520 - 90s - loss: 0.0370 - val_loss: 0.0355\n",
      "Epoch 20/250\n",
      "520/520 - 90s - loss: 0.0361 - val_loss: 0.0362\n",
      "Epoch 21/250\n",
      "520/520 - 90s - loss: 0.0355 - val_loss: 0.0343\n",
      "Epoch 22/250\n",
      "520/520 - 90s - loss: 0.0350 - val_loss: 0.0341\n",
      "Epoch 23/250\n",
      "520/520 - 89s - loss: 0.0343 - val_loss: 0.0337\n",
      "Epoch 24/250\n",
      "520/520 - 90s - loss: 0.0338 - val_loss: 0.0356\n",
      "Epoch 25/250\n",
      "520/520 - 90s - loss: 0.0333 - val_loss: 0.0353\n",
      "Epoch 26/250\n",
      "520/520 - 90s - loss: 0.0329 - val_loss: 0.0357\n",
      "Epoch 27/250\n",
      "520/520 - 90s - loss: 0.0324 - val_loss: 0.0341\n",
      "Epoch 28/250\n",
      "520/520 - 90s - loss: 0.0320 - val_loss: 0.0312\n",
      "Epoch 29/250\n",
      "520/520 - 89s - loss: 0.0317 - val_loss: 0.0304\n",
      "Epoch 30/250\n",
      "520/520 - 90s - loss: 0.0313 - val_loss: 0.0300\n",
      "Epoch 31/250\n",
      "520/520 - 90s - loss: 0.0309 - val_loss: 0.0297\n",
      "Epoch 32/250\n",
      "520/520 - 90s - loss: 0.0306 - val_loss: 0.0295\n",
      "Epoch 33/250\n",
      "520/520 - 90s - loss: 0.0303 - val_loss: 0.0296\n",
      "Epoch 34/250\n",
      "520/520 - 89s - loss: 0.0300 - val_loss: 0.0289\n",
      "Epoch 35/250\n",
      "520/520 - 90s - loss: 0.0298 - val_loss: 0.0287\n",
      "Epoch 36/250\n",
      "520/520 - 90s - loss: 0.0295 - val_loss: 0.0285\n",
      "Epoch 37/250\n",
      "520/520 - 89s - loss: 0.0292 - val_loss: 0.0312\n",
      "Epoch 38/250\n",
      "520/520 - 90s - loss: 0.0291 - val_loss: 0.0280\n",
      "Epoch 39/250\n",
      "520/520 - 90s - loss: 0.0288 - val_loss: 0.0280\n",
      "Epoch 40/250\n",
      "520/520 - 90s - loss: 0.0286 - val_loss: 0.0285\n",
      "Epoch 41/250\n",
      "520/520 - 89s - loss: 0.0284 - val_loss: 0.0276\n",
      "Epoch 42/250\n",
      "520/520 - 90s - loss: 0.0282 - val_loss: 0.0276\n",
      "Epoch 43/250\n",
      "520/520 - 90s - loss: 0.0281 - val_loss: 0.0284\n",
      "Epoch 44/250\n",
      "520/520 - 90s - loss: 0.0279 - val_loss: 0.0270\n",
      "Epoch 45/250\n",
      "520/520 - 90s - loss: 0.0277 - val_loss: 0.0268\n",
      "Epoch 46/250\n",
      "520/520 - 90s - loss: 0.0276 - val_loss: 0.0280\n",
      "Epoch 47/250\n",
      "520/520 - 90s - loss: 0.0274 - val_loss: 0.0267\n",
      "Epoch 48/250\n",
      "520/520 - 89s - loss: 0.0273 - val_loss: 0.0263\n",
      "Epoch 49/250\n",
      "520/520 - 90s - loss: 0.0271 - val_loss: 0.0283\n",
      "Epoch 50/250\n",
      "520/520 - 90s - loss: 0.0270 - val_loss: 0.0279\n",
      "Epoch 51/250\n",
      "520/520 - 90s - loss: 0.0269 - val_loss: 0.0262\n",
      "Epoch 52/250\n",
      "520/520 - 90s - loss: 0.0267 - val_loss: 0.0264\n",
      "Epoch 53/250\n",
      "520/520 - 90s - loss: 0.0265 - val_loss: 0.0260\n",
      "Epoch 54/250\n",
      "520/520 - 90s - loss: 0.0265 - val_loss: 0.0257\n",
      "Epoch 55/250\n",
      "520/520 - 90s - loss: 0.0264 - val_loss: 0.0260\n",
      "Epoch 56/250\n",
      "520/520 - 90s - loss: 0.0263 - val_loss: 0.0257\n",
      "Epoch 57/250\n",
      "520/520 - 90s - loss: 0.0261 - val_loss: 0.0261\n",
      "Epoch 58/250\n",
      "520/520 - 90s - loss: 0.0261 - val_loss: 0.0257\n",
      "Epoch 59/250\n",
      "520/520 - 89s - loss: 0.0260 - val_loss: 0.0255\n",
      "Epoch 60/250\n",
      "520/520 - 89s - loss: 0.0259 - val_loss: 0.0254\n",
      "Epoch 61/250\n",
      "520/520 - 89s - loss: 0.0258 - val_loss: 0.0265\n",
      "Epoch 62/250\n",
      "520/520 - 89s - loss: 0.0257 - val_loss: 0.0262\n",
      "Epoch 63/250\n",
      "520/520 - 89s - loss: 0.0256 - val_loss: 0.0267\n",
      "Epoch 64/250\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.030000000447034835.\n",
      "520/520 - 89s - loss: 0.0256 - val_loss: 0.0287\n",
      "Epoch 65/250\n",
      "520/520 - 89s - loss: 0.0246 - val_loss: 0.0246\n",
      "Epoch 66/250\n",
      "520/520 - 89s - loss: 0.0245 - val_loss: 0.0245\n",
      "Epoch 67/250\n",
      "520/520 - 89s - loss: 0.0245 - val_loss: 0.0245\n",
      "Epoch 68/250\n",
      "520/520 - 89s - loss: 0.0245 - val_loss: 0.0244\n",
      "Epoch 69/250\n",
      "520/520 - 89s - loss: 0.0244 - val_loss: 0.0244\n",
      "Epoch 70/250\n",
      "520/520 - 89s - loss: 0.0244 - val_loss: 0.0243\n",
      "Epoch 71/250\n",
      "520/520 - 89s - loss: 0.0243 - val_loss: 0.0243\n",
      "Epoch 72/250\n",
      "520/520 - 89s - loss: 0.0243 - val_loss: 0.0243\n",
      "Epoch 73/250\n",
      "520/520 - 90s - loss: 0.0243 - val_loss: 0.0242\n",
      "Epoch 74/250\n",
      "520/520 - 89s - loss: 0.0242 - val_loss: 0.0242\n",
      "Epoch 75/250\n",
      "520/520 - 89s - loss: 0.0242 - val_loss: 0.0242\n",
      "Epoch 76/250\n",
      "520/520 - 89s - loss: 0.0242 - val_loss: 0.0241\n",
      "Epoch 77/250\n",
      "520/520 - 89s - loss: 0.0241 - val_loss: 0.0241\n",
      "Epoch 78/250\n",
      "520/520 - 89s - loss: 0.0241 - val_loss: 0.0241\n",
      "Epoch 79/250\n",
      "520/520 - 89s - loss: 0.0240 - val_loss: 0.0240\n",
      "Epoch 80/250\n",
      "520/520 - 89s - loss: 0.0240 - val_loss: 0.0240\n",
      "Epoch 81/250\n",
      "520/520 - 89s - loss: 0.0240 - val_loss: 0.0240\n",
      "Epoch 82/250\n",
      "520/520 - 89s - loss: 0.0240 - val_loss: 0.0240\n",
      "Epoch 83/250\n",
      "520/520 - 89s - loss: 0.0239 - val_loss: 0.0239\n",
      "Epoch 84/250\n",
      "520/520 - 89s - loss: 0.0239 - val_loss: 0.0239\n",
      "Epoch 85/250\n",
      "520/520 - 90s - loss: 0.0239 - val_loss: 0.0239\n",
      "Epoch 86/250\n",
      "520/520 - 89s - loss: 0.0238 - val_loss: 0.0238\n",
      "Epoch 87/250\n",
      "520/520 - 89s - loss: 0.0238 - val_loss: 0.0238\n",
      "Epoch 88/250\n",
      "520/520 - 89s - loss: 0.0238 - val_loss: 0.0238\n",
      "Epoch 89/250\n",
      "520/520 - 89s - loss: 0.0238 - val_loss: 0.0237\n",
      "Epoch 90/250\n",
      "520/520 - 89s - loss: 0.0237 - val_loss: 0.0237\n",
      "Epoch 91/250\n",
      "520/520 - 89s - loss: 0.0237 - val_loss: 0.0237\n",
      "Epoch 92/250\n",
      "520/520 - 89s - loss: 0.0237 - val_loss: 0.0237\n",
      "Epoch 93/250\n",
      "520/520 - 89s - loss: 0.0236 - val_loss: 0.0236\n",
      "Epoch 94/250\n",
      "520/520 - 89s - loss: 0.0236 - val_loss: 0.0236\n",
      "Epoch 95/250\n",
      "520/520 - 89s - loss: 0.0236 - val_loss: 0.0236\n",
      "Epoch 96/250\n",
      "520/520 - 88s - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 97/250\n",
      "520/520 - 89s - loss: 0.0235 - val_loss: 0.0235\n",
      "Epoch 98/250\n",
      "520/520 - 89s - loss: 0.0235 - val_loss: 0.0235\n",
      "Epoch 99/250\n",
      "520/520 - 89s - loss: 0.0235 - val_loss: 0.0235\n",
      "Epoch 100/250\n",
      "520/520 - 89s - loss: 0.0234 - val_loss: 0.0234\n",
      "Epoch 101/250\n",
      "520/520 - 89s - loss: 0.0234 - val_loss: 0.0234\n",
      "Epoch 102/250\n",
      "520/520 - 88s - loss: 0.0234 - val_loss: 0.0234\n",
      "Epoch 103/250\n",
      "520/520 - 89s - loss: 0.0234 - val_loss: 0.0234\n",
      "Epoch 104/250\n",
      "520/520 - 89s - loss: 0.0233 - val_loss: 0.0233\n",
      "Epoch 105/250\n",
      "520/520 - 88s - loss: 0.0233 - val_loss: 0.0233\n",
      "Epoch 106/250\n",
      "520/520 - 88s - loss: 0.0233 - val_loss: 0.0233\n",
      "Epoch 107/250\n",
      "520/520 - 89s - loss: 0.0233 - val_loss: 0.0233\n",
      "Epoch 108/250\n",
      "520/520 - 89s - loss: 0.0232 - val_loss: 0.0232\n",
      "Epoch 109/250\n",
      "520/520 - 89s - loss: 0.0232 - val_loss: 0.0232\n",
      "Epoch 110/250\n",
      "520/520 - 89s - loss: 0.0232 - val_loss: 0.0232\n",
      "Epoch 111/250\n",
      "520/520 - 89s - loss: 0.0232 - val_loss: 0.0232\n",
      "Epoch 112/250\n",
      "520/520 - 89s - loss: 0.0231 - val_loss: 0.0231\n",
      "Epoch 113/250\n",
      "520/520 - 88s - loss: 0.0231 - val_loss: 0.0231\n",
      "Epoch 114/250\n",
      "520/520 - 89s - loss: 0.0231 - val_loss: 0.0231\n",
      "Epoch 115/250\n",
      "520/520 - 88s - loss: 0.0231 - val_loss: 0.0231\n",
      "Epoch 116/250\n",
      "520/520 - 89s - loss: 0.0231 - val_loss: 0.0231\n",
      "Epoch 117/250\n",
      "520/520 - 89s - loss: 0.0230 - val_loss: 0.0230\n",
      "Epoch 118/250\n",
      "520/520 - 89s - loss: 0.0230 - val_loss: 0.0230\n",
      "Epoch 119/250\n",
      "520/520 - 88s - loss: 0.0230 - val_loss: 0.0230\n",
      "Epoch 120/250\n",
      "520/520 - 89s - loss: 0.0230 - val_loss: 0.0230\n",
      "Epoch 121/250\n",
      "520/520 - 89s - loss: 0.0229 - val_loss: 0.0229\n",
      "Epoch 122/250\n",
      "520/520 - 89s - loss: 0.0229 - val_loss: 0.0229\n",
      "Epoch 123/250\n",
      "520/520 - 88s - loss: 0.0229 - val_loss: 0.0229\n",
      "Epoch 124/250\n",
      "520/520 - 89s - loss: 0.0229 - val_loss: 0.0229\n",
      "Epoch 125/250\n",
      "520/520 - 88s - loss: 0.0228 - val_loss: 0.0229\n",
      "Epoch 126/250\n",
      "520/520 - 89s - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 127/250\n",
      "520/520 - 88s - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 128/250\n",
      "520/520 - 89s - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 129/250\n",
      "520/520 - 89s - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 130/250\n",
      "520/520 - 88s - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 131/250\n",
      "520/520 - 88s - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 132/250\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 0.009000000357627868.\n",
      "520/520 - 88s - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 133/250\n",
      "520/520 - 89s - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 134/250\n",
      "520/520 - 89s - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 135/250\n",
      "520/520 - 89s - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 136/250\n",
      "520/520 - 88s - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 137/250\n",
      "520/520 - 89s - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 138/250\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 0.002700000163167715.\n",
      "520/520 - 88s - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 139/250\n",
      "520/520 - 89s - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 140/250\n",
      "520/520 - 89s - loss: 0.0226 - val_loss: 0.0227\n",
      "Epoch 141/250\n",
      "520/520 - 89s - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 142/250\n",
      "520/520 - 89s - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 143/250\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 0.0008100000210106373.\n",
      "520/520 - 89s - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 144/250\n",
      "520/520 - 88s - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 145/250\n",
      "520/520 - 89s - loss: 0.0227 - val_loss: 0.0226\n",
      "Epoch 146/250\n",
      "520/520 - 88s - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 147/250\n",
      "520/520 - 89s - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 148/250\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 0.00024299999931827186.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "520/520 - 89s - loss: 0.0226 - val_loss: 0.0226\n",
      "Epoch 00148: early stopping\n",
      "training layer conv3_block1_2_conv\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 520 steps, validate for 104 steps\n",
      "Epoch 1/250\n",
      "520/520 - 51s - loss: 0.2640 - val_loss: 0.1735\n",
      "Epoch 2/250\n",
      "520/520 - 50s - loss: 0.1307 - val_loss: 0.1055\n",
      "Epoch 3/250\n",
      "520/520 - 50s - loss: 0.0927 - val_loss: 0.0816\n",
      "Epoch 4/250\n",
      "520/520 - 51s - loss: 0.0754 - val_loss: 0.0694\n",
      "Epoch 5/250\n",
      "520/520 - 51s - loss: 0.0656 - val_loss: 0.0615\n",
      "Epoch 6/250\n",
      "520/520 - 50s - loss: 0.0588 - val_loss: 0.0557\n",
      "Epoch 7/250\n",
      "520/520 - 51s - loss: 0.0537 - val_loss: 0.0511\n",
      "Epoch 8/250\n",
      "520/520 - 50s - loss: 0.0495 - val_loss: 0.0474\n",
      "Epoch 9/250\n",
      "520/520 - 51s - loss: 0.0458 - val_loss: 0.0438\n",
      "Epoch 10/250\n",
      "520/520 - 51s - loss: 0.0430 - val_loss: 0.0414\n",
      "Epoch 11/250\n",
      "520/520 - 51s - loss: 0.0407 - val_loss: 0.0394\n",
      "Epoch 12/250\n",
      "520/520 - 50s - loss: 0.0389 - val_loss: 0.0377\n",
      "Epoch 13/250\n",
      "520/520 - 50s - loss: 0.0374 - val_loss: 0.0363\n",
      "Epoch 14/250\n",
      "520/520 - 50s - loss: 0.0361 - val_loss: 0.0351\n",
      "Epoch 15/250\n",
      "520/520 - 51s - loss: 0.0349 - val_loss: 0.0340\n",
      "Epoch 16/250\n",
      "520/520 - 50s - loss: 0.0329 - val_loss: 0.0317\n",
      "Epoch 17/250\n",
      "520/520 - 51s - loss: 0.0311 - val_loss: 0.0302\n",
      "Epoch 18/250\n",
      "520/520 - 50s - loss: 0.0302 - val_loss: 0.0294\n",
      "Epoch 19/250\n",
      "520/520 - 50s - loss: 0.0295 - val_loss: 0.0289\n",
      "Epoch 20/250\n",
      "520/520 - 51s - loss: 0.0287 - val_loss: 0.0281\n",
      "Epoch 21/250\n",
      "520/520 - 51s - loss: 0.0281 - val_loss: 0.0274\n",
      "Epoch 22/250\n",
      "520/520 - 51s - loss: 0.0275 - val_loss: 0.0271\n",
      "Epoch 23/250\n",
      "520/520 - 51s - loss: 0.0269 - val_loss: 0.0265\n",
      "Epoch 24/250\n",
      "520/520 - 51s - loss: 0.0264 - val_loss: 0.0250\n",
      "Epoch 25/250\n",
      "520/520 - 50s - loss: 0.0236 - val_loss: 0.0227\n",
      "Epoch 26/250\n",
      "520/520 - 50s - loss: 0.0228 - val_loss: 0.0222\n",
      "Epoch 27/250\n",
      "520/520 - 51s - loss: 0.0223 - val_loss: 0.0220\n",
      "Epoch 28/250\n",
      "520/520 - 50s - loss: 0.0218 - val_loss: 0.0215\n",
      "Epoch 29/250\n",
      "520/520 - 51s - loss: 0.0215 - val_loss: 0.0218\n",
      "Epoch 30/250\n",
      "520/520 - 51s - loss: 0.0212 - val_loss: 0.0208\n",
      "Epoch 31/250\n",
      "520/520 - 50s - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 32/250\n",
      "520/520 - 51s - loss: 0.0206 - val_loss: 0.0204\n",
      "Epoch 33/250\n",
      "520/520 - 50s - loss: 0.0203 - val_loss: 0.0201\n",
      "Epoch 34/250\n",
      "520/520 - 50s - loss: 0.0201 - val_loss: 0.0196\n",
      "Epoch 35/250\n",
      "520/520 - 51s - loss: 0.0198 - val_loss: 0.0196\n",
      "Epoch 36/250\n",
      "520/520 - 51s - loss: 0.0196 - val_loss: 0.0192\n",
      "Epoch 37/250\n",
      "520/520 - 50s - loss: 0.0193 - val_loss: 0.0193\n",
      "Epoch 38/250\n",
      "520/520 - 50s - loss: 0.0192 - val_loss: 0.0188\n",
      "Epoch 39/250\n",
      "520/520 - 51s - loss: 0.0190 - val_loss: 0.0186\n",
      "Epoch 40/250\n",
      "520/520 - 51s - loss: 0.0188 - val_loss: 0.0184\n",
      "Epoch 41/250\n",
      "520/520 - 51s - loss: 0.0186 - val_loss: 0.0182\n",
      "Epoch 42/250\n",
      "520/520 - 51s - loss: 0.0184 - val_loss: 0.0185\n",
      "Epoch 43/250\n",
      "520/520 - 51s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 44/250\n",
      "520/520 - 50s - loss: 0.0181 - val_loss: 0.0178\n",
      "Epoch 45/250\n",
      "520/520 - 50s - loss: 0.0179 - val_loss: 0.0177\n",
      "Epoch 46/250\n",
      "520/520 - 50s - loss: 0.0161 - val_loss: 0.0148\n",
      "Epoch 47/250\n",
      "520/520 - 51s - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 48/250\n",
      "520/520 - 50s - loss: 0.0147 - val_loss: 0.0144\n",
      "Epoch 49/250\n",
      "520/520 - 51s - loss: 0.0146 - val_loss: 0.0142\n",
      "Epoch 50/250\n",
      "520/520 - 50s - loss: 0.0144 - val_loss: 0.0144\n",
      "Epoch 51/250\n",
      "520/520 - 50s - loss: 0.0143 - val_loss: 0.0140\n",
      "Epoch 52/250\n",
      "520/520 - 50s - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 53/250\n",
      "520/520 - 50s - loss: 0.0141 - val_loss: 0.0137\n",
      "Epoch 54/250\n",
      "520/520 - 51s - loss: 0.0139 - val_loss: 0.0137\n",
      "Epoch 55/250\n",
      "520/520 - 51s - loss: 0.0138 - val_loss: 0.0135\n",
      "Epoch 56/250\n",
      "520/520 - 50s - loss: 0.0137 - val_loss: 0.0142\n",
      "Epoch 57/250\n",
      "520/520 - 50s - loss: 0.0136 - val_loss: 0.0136\n",
      "Epoch 58/250\n",
      "520/520 - 51s - loss: 0.0135 - val_loss: 0.0145\n",
      "Epoch 59/250\n",
      "520/520 - 51s - loss: 0.0135 - val_loss: 0.0131\n",
      "Epoch 60/250\n",
      "520/520 - 51s - loss: 0.0134 - val_loss: 0.0135\n",
      "Epoch 61/250\n",
      "520/520 - 51s - loss: 0.0132 - val_loss: 0.0136\n",
      "Epoch 62/250\n",
      "520/520 - 51s - loss: 0.0132 - val_loss: 0.0135\n",
      "Epoch 63/250\n",
      "520/520 - 50s - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 64/250\n",
      "520/520 - 50s - loss: 0.0129 - val_loss: 0.0128\n",
      "Epoch 65/250\n",
      "520/520 - 51s - loss: 0.0129 - val_loss: 0.0136\n",
      "Epoch 66/250\n",
      "520/520 - 50s - loss: 0.0129 - val_loss: 0.0128\n",
      "Epoch 67/250\n",
      "520/520 - 51s - loss: 0.0127 - val_loss: 0.0134\n",
      "Epoch 68/250\n",
      "520/520 - 51s - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 69/250\n",
      "520/520 - 50s - loss: 0.0126 - val_loss: 0.0137\n",
      "Epoch 70/250\n",
      "520/520 - 49s - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 71/250\n",
      "520/520 - 55s - loss: 0.0126 - val_loss: 0.0128\n",
      "Epoch 72/250\n",
      "520/520 - 55s - loss: 0.0124 - val_loss: 0.0126\n",
      "Epoch 73/250\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.030000000447034835.\n",
      "520/520 - 55s - loss: 0.0124 - val_loss: 0.0128\n",
      "Epoch 74/250\n",
      "520/520 - 55s - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 75/250\n",
      "520/520 - 55s - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 76/250\n",
      "520/520 - 55s - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 77/250\n",
      "520/520 - 55s - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 78/250\n",
      "520/520 - 55s - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 79/250\n",
      "520/520 - 55s - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 80/250\n",
      "520/520 - 55s - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 81/250\n",
      "520/520 - 55s - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 82/250\n",
      "520/520 - 55s - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 83/250\n",
      "520/520 - 55s - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 84/250\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.009000000357627868.\n",
      "520/520 - 55s - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 85/250\n",
      "520/520 - 55s - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 86/250\n",
      "520/520 - 55s - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 87/250\n",
      "520/520 - 55s - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 88/250\n",
      "520/520 - 55s - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 89/250\n",
      "520/520 - 55s - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 90/250\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.002700000163167715.\n",
      "520/520 - 55s - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 91/250\n",
      "520/520 - 55s - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 92/250\n",
      "520/520 - 55s - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 93/250\n",
      "520/520 - 55s - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 94/250\n",
      "520/520 - 54s - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 95/250\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0008100000210106373.\n",
      "520/520 - 54s - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 96/250\n",
      "520/520 - 55s - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 97/250\n",
      "520/520 - 55s - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 98/250\n",
      "520/520 - 55s - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 99/250\n",
      "520/520 - 55s - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 100/250\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.00024299999931827186.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "520/520 - 55s - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 00100: early stopping\n",
      "training layer conv3_block2_2_conv\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 520 steps, validate for 104 steps\n",
      "Epoch 1/250\n",
      "520/520 - 60s - loss: 0.2671 - val_loss: 0.2531\n",
      "Epoch 2/250\n",
      "520/520 - 59s - loss: 0.2178 - val_loss: 0.1763\n",
      "Epoch 3/250\n",
      "520/520 - 59s - loss: 0.1470 - val_loss: 0.1245\n",
      "Epoch 4/250\n",
      "520/520 - 60s - loss: 0.1107 - val_loss: 0.0994\n",
      "Epoch 5/250\n",
      "520/520 - 59s - loss: 0.0914 - val_loss: 0.0844\n",
      "Epoch 6/250\n",
      "520/520 - 59s - loss: 0.0790 - val_loss: 0.0741\n",
      "Epoch 7/250\n",
      "520/520 - 59s - loss: 0.0701 - val_loss: 0.0666\n",
      "Epoch 8/250\n",
      "520/520 - 59s - loss: 0.0636 - val_loss: 0.0607\n",
      "Epoch 9/250\n",
      "520/520 - 59s - loss: 0.0583 - val_loss: 0.0561\n",
      "Epoch 10/250\n",
      "520/520 - 59s - loss: 0.0541 - val_loss: 0.0523\n",
      "Epoch 11/250\n",
      "520/520 - 59s - loss: 0.0506 - val_loss: 0.0491\n",
      "Epoch 12/250\n",
      "520/520 - 59s - loss: 0.0472 - val_loss: 0.0452\n",
      "Epoch 13/250\n",
      "520/520 - 59s - loss: 0.0439 - val_loss: 0.0427\n",
      "Epoch 14/250\n",
      "520/520 - 59s - loss: 0.0417 - val_loss: 0.0406\n",
      "Epoch 15/250\n",
      "520/520 - 59s - loss: 0.0397 - val_loss: 0.0389\n",
      "Epoch 16/250\n",
      "520/520 - 59s - loss: 0.0381 - val_loss: 0.0373\n",
      "Epoch 17/250\n",
      "520/520 - 59s - loss: 0.0367 - val_loss: 0.0359\n",
      "Epoch 18/250\n",
      "520/520 - 59s - loss: 0.0353 - val_loss: 0.0347\n",
      "Epoch 19/250\n",
      "520/520 - 59s - loss: 0.0343 - val_loss: 0.0337\n",
      "Epoch 20/250\n",
      "520/520 - 60s - loss: 0.0333 - val_loss: 0.0328\n",
      "Epoch 21/250\n",
      "520/520 - 59s - loss: 0.0324 - val_loss: 0.0318\n",
      "Epoch 22/250\n",
      "520/520 - 59s - loss: 0.0316 - val_loss: 0.0310\n",
      "Epoch 23/250\n",
      "520/520 - 59s - loss: 0.0308 - val_loss: 0.0303\n",
      "Epoch 24/250\n",
      "520/520 - 59s - loss: 0.0300 - val_loss: 0.0296\n",
      "Epoch 25/250\n",
      "520/520 - 59s - loss: 0.0294 - val_loss: 0.0289\n",
      "Epoch 26/250\n",
      "520/520 - 59s - loss: 0.0288 - val_loss: 0.0284\n",
      "Epoch 27/250\n",
      "520/520 - 59s - loss: 0.0282 - val_loss: 0.0277\n",
      "Epoch 28/250\n",
      "520/520 - 59s - loss: 0.0276 - val_loss: 0.0273\n",
      "Epoch 29/250\n",
      "520/520 - 59s - loss: 0.0271 - val_loss: 0.0269\n",
      "Epoch 30/250\n",
      "520/520 - 59s - loss: 0.0267 - val_loss: 0.0263\n",
      "Epoch 31/250\n",
      "520/520 - 59s - loss: 0.0262 - val_loss: 0.0258\n",
      "Epoch 32/250\n",
      "520/520 - 58s - loss: 0.0258 - val_loss: 0.0255\n",
      "Epoch 33/250\n",
      "520/520 - 60s - loss: 0.0254 - val_loss: 0.0252\n",
      "Epoch 34/250\n",
      "520/520 - 59s - loss: 0.0251 - val_loss: 0.0248\n",
      "Epoch 35/250\n",
      "520/520 - 59s - loss: 0.0247 - val_loss: 0.0245\n",
      "Epoch 36/250\n",
      "520/520 - 59s - loss: 0.0244 - val_loss: 0.0240\n",
      "Epoch 37/250\n",
      "520/520 - 58s - loss: 0.0241 - val_loss: 0.0237\n",
      "Epoch 38/250\n",
      "520/520 - 59s - loss: 0.0238 - val_loss: 0.0236\n",
      "Epoch 39/250\n",
      "520/520 - 59s - loss: 0.0235 - val_loss: 0.0235\n",
      "Epoch 40/250\n",
      "520/520 - 59s - loss: 0.0232 - val_loss: 0.0233\n",
      "Epoch 41/250\n",
      "520/520 - 59s - loss: 0.0230 - val_loss: 0.0227\n",
      "Epoch 42/250\n",
      "520/520 - 59s - loss: 0.0227 - val_loss: 0.0224\n",
      "Epoch 43/250\n",
      "520/520 - 59s - loss: 0.0225 - val_loss: 0.0223\n",
      "Epoch 44/250\n",
      "520/520 - 59s - loss: 0.0222 - val_loss: 0.0220\n",
      "Epoch 45/250\n",
      "520/520 - 59s - loss: 0.0220 - val_loss: 0.0218\n",
      "Epoch 46/250\n",
      "520/520 - 59s - loss: 0.0218 - val_loss: 0.0216\n",
      "Epoch 47/250\n",
      "520/520 - 59s - loss: 0.0216 - val_loss: 0.0215\n",
      "Epoch 48/250\n",
      "520/520 - 59s - loss: 0.0214 - val_loss: 0.0214\n",
      "Epoch 49/250\n",
      "520/520 - 59s - loss: 0.0212 - val_loss: 0.0210\n",
      "Epoch 50/250\n",
      "520/520 - 59s - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 51/250\n",
      "520/520 - 59s - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 52/250\n",
      "520/520 - 59s - loss: 0.0207 - val_loss: 0.0207\n",
      "Epoch 53/250\n",
      "520/520 - 58s - loss: 0.0205 - val_loss: 0.0204\n",
      "Epoch 54/250\n",
      "520/520 - 59s - loss: 0.0204 - val_loss: 0.0203\n",
      "Epoch 55/250\n",
      "520/520 - 59s - loss: 0.0202 - val_loss: 0.0201\n",
      "Epoch 56/250\n",
      "520/520 - 59s - loss: 0.0201 - val_loss: 0.0199\n",
      "Epoch 57/250\n",
      "520/520 - 59s - loss: 0.0199 - val_loss: 0.0199\n",
      "Epoch 58/250\n",
      "520/520 - 59s - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 59/250\n",
      "520/520 - 59s - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 60/250\n",
      "520/520 - 59s - loss: 0.0195 - val_loss: 0.0196\n",
      "Epoch 61/250\n",
      "520/520 - 59s - loss: 0.0194 - val_loss: 0.0195\n",
      "Epoch 62/250\n",
      "520/520 - 59s - loss: 0.0193 - val_loss: 0.0195\n",
      "Epoch 63/250\n",
      "520/520 - 59s - loss: 0.0191 - val_loss: 0.0191\n",
      "Epoch 64/250\n",
      "520/520 - 59s - loss: 0.0190 - val_loss: 0.0192\n",
      "Epoch 65/250\n",
      "520/520 - 58s - loss: 0.0189 - val_loss: 0.0192\n",
      "Epoch 66/250\n",
      "520/520 - 59s - loss: 0.0188 - val_loss: 0.0189\n",
      "Epoch 67/250\n",
      "520/520 - 59s - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 68/250\n",
      "520/520 - 59s - loss: 0.0186 - val_loss: 0.0188\n",
      "Epoch 69/250\n",
      "520/520 - 59s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 70/250\n",
      "520/520 - 59s - loss: 0.0184 - val_loss: 0.0185\n",
      "Epoch 71/250\n",
      "520/520 - 59s - loss: 0.0183 - val_loss: 0.0185\n",
      "Epoch 72/250\n",
      "520/520 - 58s - loss: 0.0182 - val_loss: 0.0183\n",
      "Epoch 73/250\n",
      "520/520 - 58s - loss: 0.0181 - val_loss: 0.0182\n",
      "Epoch 74/250\n",
      "520/520 - 59s - loss: 0.0180 - val_loss: 0.0182\n",
      "Epoch 75/250\n",
      "520/520 - 59s - loss: 0.0179 - val_loss: 0.0181\n",
      "Epoch 76/250\n",
      "520/520 - 59s - loss: 0.0178 - val_loss: 0.0180\n",
      "Epoch 77/250\n",
      "520/520 - 59s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 78/250\n",
      "520/520 - 59s - loss: 0.0177 - val_loss: 0.0179\n",
      "Epoch 79/250\n",
      "520/520 - 59s - loss: 0.0176 - val_loss: 0.0177\n",
      "Epoch 80/250\n",
      "520/520 - 59s - loss: 0.0175 - val_loss: 0.0178\n",
      "Epoch 81/250\n",
      "520/520 - 58s - loss: 0.0175 - val_loss: 0.0177\n",
      "Epoch 82/250\n",
      "520/520 - 59s - loss: 0.0174 - val_loss: 0.0175\n",
      "Epoch 83/250\n",
      "520/520 - 59s - loss: 0.0173 - val_loss: 0.0176\n",
      "Epoch 84/250\n",
      "520/520 - 59s - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 85/250\n",
      "520/520 - 59s - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 86/250\n",
      "520/520 - 59s - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 87/250\n",
      "520/520 - 59s - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 88/250\n",
      "520/520 - 59s - loss: 0.0170 - val_loss: 0.0170\n",
      "Epoch 89/250\n",
      "520/520 - 59s - loss: 0.0169 - val_loss: 0.0169\n",
      "Epoch 90/250\n",
      "520/520 - 59s - loss: 0.0168 - val_loss: 0.0169\n",
      "Epoch 91/250\n",
      "520/520 - 59s - loss: 0.0168 - val_loss: 0.0169\n",
      "Epoch 92/250\n",
      "520/520 - 59s - loss: 0.0167 - val_loss: 0.0168\n",
      "Epoch 93/250\n",
      "520/520 - 59s - loss: 0.0166 - val_loss: 0.0169\n",
      "Epoch 94/250\n",
      "520/520 - 59s - loss: 0.0166 - val_loss: 0.0166\n",
      "Epoch 95/250\n",
      "520/520 - 59s - loss: 0.0165 - val_loss: 0.0166\n",
      "Epoch 96/250\n",
      "520/520 - 59s - loss: 0.0165 - val_loss: 0.0165\n",
      "Epoch 97/250\n",
      "520/520 - 59s - loss: 0.0164 - val_loss: 0.0165\n",
      "Epoch 98/250\n",
      "520/520 - 59s - loss: 0.0163 - val_loss: 0.0164\n",
      "Epoch 99/250\n",
      "520/520 - 59s - loss: 0.0163 - val_loss: 0.0163\n",
      "Epoch 100/250\n",
      "520/520 - 59s - loss: 0.0162 - val_loss: 0.0162\n",
      "Epoch 101/250\n",
      "520/520 - 59s - loss: 0.0162 - val_loss: 0.0163\n",
      "Epoch 102/250\n",
      "520/520 - 59s - loss: 0.0161 - val_loss: 0.0161\n",
      "Epoch 103/250\n",
      "520/520 - 59s - loss: 0.0161 - val_loss: 0.0161\n",
      "Epoch 104/250\n",
      "520/520 - 59s - loss: 0.0160 - val_loss: 0.0160\n",
      "Epoch 105/250\n",
      "520/520 - 59s - loss: 0.0160 - val_loss: 0.0160\n",
      "Epoch 106/250\n",
      "520/520 - 59s - loss: 0.0159 - val_loss: 0.0166\n",
      "Epoch 107/250\n",
      "520/520 - 59s - loss: 0.0159 - val_loss: 0.0158\n",
      "Epoch 108/250\n",
      "520/520 - 59s - loss: 0.0158 - val_loss: 0.0157\n",
      "Epoch 109/250\n",
      "520/520 - 59s - loss: 0.0158 - val_loss: 0.0159\n",
      "Epoch 110/250\n",
      "520/520 - 59s - loss: 0.0157 - val_loss: 0.0158\n",
      "Epoch 111/250\n",
      "520/520 - 59s - loss: 0.0157 - val_loss: 0.0155\n",
      "Epoch 112/250\n",
      "520/520 - 58s - loss: 0.0156 - val_loss: 0.0155\n",
      "Epoch 113/250\n",
      "520/520 - 59s - loss: 0.0156 - val_loss: 0.0156\n",
      "Epoch 114/250\n",
      "520/520 - 59s - loss: 0.0156 - val_loss: 0.0155\n",
      "Epoch 115/250\n",
      "520/520 - 59s - loss: 0.0155 - val_loss: 0.0154\n",
      "Epoch 116/250\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 0.030000000447034835.\n",
      "520/520 - 59s - loss: 0.0155 - val_loss: 0.0154\n",
      "Epoch 117/250\n",
      "520/520 - 59s - loss: 0.0151 - val_loss: 0.0151\n",
      "Epoch 118/250\n",
      "520/520 - 59s - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 119/250\n",
      "520/520 - 58s - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 120/250\n",
      "520/520 - 59s - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 121/250\n",
      "520/520 - 59s - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 122/250\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 0.009000000357627868.\n",
      "520/520 - 59s - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 123/250\n",
      "520/520 - 59s - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 124/250\n",
      "520/520 - 59s - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 125/250\n",
      "520/520 - 58s - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 126/250\n",
      "520/520 - 57s - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 127/250\n",
      "520/520 - 58s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 128/250\n",
      "520/520 - 58s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 129/250\n",
      "520/520 - 58s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 130/250\n",
      "520/520 - 58s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 131/250\n",
      "520/520 - 58s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 132/250\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 0.002700000163167715.\n",
      "520/520 - 58s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 133/250\n",
      "520/520 - 58s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 134/250\n",
      "520/520 - 58s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 135/250\n",
      "520/520 - 57s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 136/250\n",
      "520/520 - 58s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 137/250\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 0.0008100000210106373.\n",
      "520/520 - 57s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 138/250\n",
      "520/520 - 57s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 139/250\n",
      "520/520 - 58s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 140/250\n",
      "520/520 - 58s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 141/250\n",
      "520/520 - 58s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 142/250\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 0.00024299999931827186.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "520/520 - 58s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 00142: early stopping\n",
      "training layer conv3_block3_2_conv\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 520 steps, validate for 104 steps\n",
      "Epoch 1/250\n",
      "520/520 - 61s - loss: 0.1910 - val_loss: 0.1501\n",
      "Epoch 2/250\n",
      "520/520 - 60s - loss: 0.1348 - val_loss: 0.1077\n",
      "Epoch 3/250\n",
      "520/520 - 61s - loss: 0.0916 - val_loss: 0.0782\n",
      "Epoch 4/250\n",
      "520/520 - 61s - loss: 0.0726 - val_loss: 0.0652\n",
      "Epoch 5/250\n",
      "520/520 - 60s - loss: 0.0596 - val_loss: 0.0527\n",
      "Epoch 6/250\n",
      "520/520 - 61s - loss: 0.0497 - val_loss: 0.0450\n",
      "Epoch 7/250\n",
      "520/520 - 60s - loss: 0.0428 - val_loss: 0.0392\n",
      "Epoch 8/250\n",
      "520/520 - 60s - loss: 0.0377 - val_loss: 0.0352\n",
      "Epoch 9/250\n",
      "520/520 - 60s - loss: 0.0344 - val_loss: 0.0321\n",
      "Epoch 10/250\n",
      "520/520 - 61s - loss: 0.0318 - val_loss: 0.0303\n",
      "Epoch 11/250\n",
      "520/520 - 60s - loss: 0.0298 - val_loss: 0.0285\n",
      "Epoch 12/250\n",
      "520/520 - 61s - loss: 0.0282 - val_loss: 0.0268\n",
      "Epoch 13/250\n",
      "520/520 - 60s - loss: 0.0268 - val_loss: 0.0259\n",
      "Epoch 14/250\n",
      "520/520 - 61s - loss: 0.0257 - val_loss: 0.0249\n",
      "Epoch 15/250\n",
      "520/520 - 60s - loss: 0.0247 - val_loss: 0.0243\n",
      "Epoch 16/250\n",
      "520/520 - 61s - loss: 0.0239 - val_loss: 0.0229\n",
      "Epoch 17/250\n",
      "520/520 - 60s - loss: 0.0227 - val_loss: 0.0218\n",
      "Epoch 18/250\n",
      "520/520 - 60s - loss: 0.0219 - val_loss: 0.0212\n",
      "Epoch 19/250\n",
      "520/520 - 60s - loss: 0.0212 - val_loss: 0.0204\n",
      "Epoch 20/250\n",
      "520/520 - 60s - loss: 0.0206 - val_loss: 0.0200\n",
      "Epoch 21/250\n",
      "520/520 - 60s - loss: 0.0201 - val_loss: 0.0194\n",
      "Epoch 22/250\n",
      "520/520 - 61s - loss: 0.0196 - val_loss: 0.0192\n",
      "Epoch 23/250\n",
      "520/520 - 60s - loss: 0.0192 - val_loss: 0.0188\n",
      "Epoch 24/250\n",
      "520/520 - 60s - loss: 0.0188 - val_loss: 0.0182\n",
      "Epoch 25/250\n",
      "520/520 - 60s - loss: 0.0185 - val_loss: 0.0179\n",
      "Epoch 26/250\n",
      "520/520 - 60s - loss: 0.0181 - val_loss: 0.0178\n",
      "Epoch 27/250\n",
      "520/520 - 60s - loss: 0.0178 - val_loss: 0.0176\n",
      "Epoch 28/250\n",
      "520/520 - 60s - loss: 0.0175 - val_loss: 0.0172\n",
      "Epoch 29/250\n",
      "520/520 - 61s - loss: 0.0173 - val_loss: 0.0169\n",
      "Epoch 30/250\n",
      "520/520 - 61s - loss: 0.0170 - val_loss: 0.0164\n",
      "Epoch 31/250\n",
      "520/520 - 61s - loss: 0.0168 - val_loss: 0.0165\n",
      "Epoch 32/250\n",
      "520/520 - 60s - loss: 0.0165 - val_loss: 0.0161\n",
      "Epoch 33/250\n",
      "520/520 - 60s - loss: 0.0163 - val_loss: 0.0159\n",
      "Epoch 34/250\n",
      "520/520 - 60s - loss: 0.0161 - val_loss: 0.0156\n",
      "Epoch 35/250\n",
      "520/520 - 60s - loss: 0.0159 - val_loss: 0.0156\n",
      "Epoch 36/250\n",
      "520/520 - 60s - loss: 0.0157 - val_loss: 0.0152\n",
      "Epoch 37/250\n",
      "520/520 - 61s - loss: 0.0156 - val_loss: 0.0153\n",
      "Epoch 38/250\n",
      "520/520 - 61s - loss: 0.0154 - val_loss: 0.0149\n",
      "Epoch 39/250\n",
      "520/520 - 60s - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 40/250\n",
      "520/520 - 61s - loss: 0.0151 - val_loss: 0.0147\n",
      "Epoch 41/250\n",
      "520/520 - 60s - loss: 0.0150 - val_loss: 0.0146\n",
      "Epoch 42/250\n",
      "520/520 - 60s - loss: 0.0148 - val_loss: 0.0145\n",
      "Epoch 43/250\n",
      "520/520 - 60s - loss: 0.0147 - val_loss: 0.0143\n",
      "Epoch 44/250\n",
      "520/520 - 60s - loss: 0.0146 - val_loss: 0.0142\n",
      "Epoch 45/250\n",
      "520/520 - 60s - loss: 0.0145 - val_loss: 0.0140\n",
      "Epoch 46/250\n",
      "520/520 - 60s - loss: 0.0143 - val_loss: 0.0139\n",
      "Epoch 47/250\n",
      "520/520 - 60s - loss: 0.0143 - val_loss: 0.0141\n",
      "Epoch 48/250\n",
      "520/520 - 61s - loss: 0.0141 - val_loss: 0.0137\n",
      "Epoch 49/250\n",
      "520/520 - 61s - loss: 0.0140 - val_loss: 0.0136\n",
      "Epoch 50/250\n",
      "520/520 - 61s - loss: 0.0140 - val_loss: 0.0135\n",
      "Epoch 51/250\n",
      "520/520 - 60s - loss: 0.0138 - val_loss: 0.0134\n",
      "Epoch 52/250\n",
      "520/520 - 60s - loss: 0.0137 - val_loss: 0.0134\n",
      "Epoch 53/250\n",
      "520/520 - 60s - loss: 0.0137 - val_loss: 0.0132\n",
      "Epoch 54/250\n",
      "520/520 - 60s - loss: 0.0136 - val_loss: 0.0132\n",
      "Epoch 55/250\n",
      "520/520 - 60s - loss: 0.0135 - val_loss: 0.0131\n",
      "Epoch 56/250\n",
      "520/520 - 61s - loss: 0.0134 - val_loss: 0.0130\n",
      "Epoch 57/250\n",
      "520/520 - 60s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 58/250\n",
      "520/520 - 60s - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 59/250\n",
      "520/520 - 60s - loss: 0.0132 - val_loss: 0.0128\n",
      "Epoch 60/250\n",
      "520/520 - 60s - loss: 0.0131 - val_loss: 0.0127\n",
      "Epoch 61/250\n",
      "520/520 - 60s - loss: 0.0131 - val_loss: 0.0126\n",
      "Epoch 62/250\n",
      "520/520 - 60s - loss: 0.0130 - val_loss: 0.0125\n",
      "Epoch 63/250\n",
      "520/520 - 60s - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 64/250\n",
      "520/520 - 60s - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 65/250\n",
      "520/520 - 60s - loss: 0.0128 - val_loss: 0.0124\n",
      "Epoch 66/250\n",
      "520/520 - 61s - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 67/250\n",
      "520/520 - 60s - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 68/250\n",
      "520/520 - 60s - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 69/250\n",
      "520/520 - 60s - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 70/250\n",
      "520/520 - 60s - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 71/250\n",
      "520/520 - 60s - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 72/250\n",
      "520/520 - 60s - loss: 0.0124 - val_loss: 0.0120\n",
      "Epoch 73/250\n",
      "520/520 - 60s - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 74/250\n",
      "520/520 - 60s - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 75/250\n",
      "520/520 - 60s - loss: 0.0122 - val_loss: 0.0120\n",
      "Epoch 76/250\n",
      "520/520 - 60s - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 77/250\n",
      "520/520 - 60s - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 78/250\n",
      "520/520 - 60s - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 79/250\n",
      "520/520 - 61s - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 80/250\n",
      "520/520 - 60s - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 81/250\n",
      "520/520 - 60s - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 82/250\n",
      "520/520 - 60s - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 83/250\n",
      "520/520 - 60s - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 84/250\n",
      "520/520 - 60s - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 85/250\n",
      "520/520 - 61s - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 86/250\n",
      "520/520 - 60s - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 87/250\n",
      "520/520 - 61s - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 88/250\n",
      "520/520 - 61s - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 89/250\n",
      "520/520 - 60s - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 90/250\n",
      "520/520 - 61s - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 91/250\n",
      "520/520 - 60s - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 92/250\n",
      "520/520 - 60s - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 93/250\n",
      "520/520 - 60s - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 94/250\n",
      "520/520 - 60s - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 95/250\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.030000000447034835.\n",
      "520/520 - 60s - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 96/250\n",
      "520/520 - 61s - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 97/250\n",
      "520/520 - 60s - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 98/250\n",
      "520/520 - 60s - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 99/250\n",
      "520/520 - 60s - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 100/250\n",
      "520/520 - 60s - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 101/250\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.009000000357627868.\n",
      "520/520 - 61s - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 102/250\n",
      "520/520 - 60s - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 103/250\n",
      "520/520 - 60s - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 104/250\n",
      "520/520 - 60s - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 105/250\n",
      "520/520 - 61s - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 106/250\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 0.002700000163167715.\n",
      "520/520 - 60s - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 107/250\n",
      "520/520 - 60s - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 108/250\n",
      "520/520 - 61s - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 109/250\n",
      "520/520 - 60s - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 110/250\n",
      "520/520 - 61s - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 111/250\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 0.0008100000210106373.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "520/520 - 61s - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 00111: early stopping\n",
      "training layer conv3_block4_2_conv\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 520 steps, validate for 104 steps\n",
      "Epoch 1/250\n",
      "520/520 - 64s - loss: 0.4081 - val_loss: 0.3182\n",
      "Epoch 2/250\n",
      "520/520 - 63s - loss: 0.2510 - val_loss: 0.1993\n",
      "Epoch 3/250\n",
      "520/520 - 64s - loss: 0.1682 - val_loss: 0.1437\n",
      "Epoch 4/250\n",
      "520/520 - 64s - loss: 0.1267 - val_loss: 0.1132\n",
      "Epoch 5/250\n",
      "520/520 - 64s - loss: 0.1029 - val_loss: 0.0944\n",
      "Epoch 6/250\n",
      "520/520 - 64s - loss: 0.0883 - val_loss: 0.0821\n",
      "Epoch 7/250\n",
      "520/520 - 64s - loss: 0.0785 - val_loss: 0.0736\n",
      "Epoch 8/250\n",
      "520/520 - 64s - loss: 0.0712 - val_loss: 0.0672\n",
      "Epoch 9/250\n",
      "520/520 - 64s - loss: 0.0648 - val_loss: 0.0598\n",
      "Epoch 10/250\n",
      "520/520 - 63s - loss: 0.0586 - val_loss: 0.0560\n",
      "Epoch 11/250\n",
      "520/520 - 64s - loss: 0.0544 - val_loss: 0.0559\n",
      "Epoch 12/250\n",
      "520/520 - 63s - loss: 0.0513 - val_loss: 0.0495\n",
      "Epoch 13/250\n",
      "520/520 - 63s - loss: 0.0487 - val_loss: 0.0469\n",
      "Epoch 14/250\n",
      "520/520 - 64s - loss: 0.0464 - val_loss: 0.0443\n",
      "Epoch 15/250\n",
      "520/520 - 64s - loss: 0.0445 - val_loss: 0.0461\n",
      "Epoch 16/250\n",
      "520/520 - 63s - loss: 0.0430 - val_loss: 0.0410\n",
      "Epoch 17/250\n",
      "520/520 - 64s - loss: 0.0415 - val_loss: 0.0398\n",
      "Epoch 18/250\n",
      "520/520 - 64s - loss: 0.0403 - val_loss: 0.0440\n",
      "Epoch 19/250\n",
      "520/520 - 64s - loss: 0.0393 - val_loss: 0.0413\n",
      "Epoch 20/250\n",
      "520/520 - 64s - loss: 0.0384 - val_loss: 0.0372\n",
      "Epoch 21/250\n",
      "520/520 - 63s - loss: 0.0375 - val_loss: 0.0361\n",
      "Epoch 22/250\n",
      "520/520 - 64s - loss: 0.0367 - val_loss: 0.0354\n",
      "Epoch 23/250\n",
      "520/520 - 64s - loss: 0.0361 - val_loss: 0.0370\n",
      "Epoch 24/250\n",
      "520/520 - 64s - loss: 0.0355 - val_loss: 0.0346\n",
      "Epoch 25/250\n",
      "520/520 - 64s - loss: 0.0349 - val_loss: 0.0341\n",
      "Epoch 26/250\n",
      "520/520 - 64s - loss: 0.0344 - val_loss: 0.0337\n",
      "Epoch 27/250\n",
      "520/520 - 64s - loss: 0.0339 - val_loss: 0.0343\n",
      "Epoch 28/250\n",
      "520/520 - 64s - loss: 0.0335 - val_loss: 0.0331\n",
      "Epoch 29/250\n",
      "520/520 - 64s - loss: 0.0331 - val_loss: 0.0323\n",
      "Epoch 30/250\n",
      "520/520 - 63s - loss: 0.0328 - val_loss: 0.0318\n",
      "Epoch 31/250\n",
      "520/520 - 63s - loss: 0.0324 - val_loss: 0.0324\n",
      "Epoch 32/250\n",
      "520/520 - 63s - loss: 0.0321 - val_loss: 0.0313\n",
      "Epoch 33/250\n",
      "520/520 - 64s - loss: 0.0318 - val_loss: 0.0309\n",
      "Epoch 34/250\n",
      "520/520 - 63s - loss: 0.0315 - val_loss: 0.0310\n",
      "Epoch 35/250\n",
      "520/520 - 63s - loss: 0.0313 - val_loss: 0.0304\n",
      "Epoch 36/250\n",
      "520/520 - 63s - loss: 0.0310 - val_loss: 0.0303\n",
      "Epoch 37/250\n",
      "520/520 - 63s - loss: 0.0307 - val_loss: 0.0299\n",
      "Epoch 38/250\n",
      "520/520 - 63s - loss: 0.0306 - val_loss: 0.0298\n",
      "Epoch 39/250\n",
      "520/520 - 64s - loss: 0.0303 - val_loss: 0.0300\n",
      "Epoch 40/250\n",
      "520/520 - 64s - loss: 0.0301 - val_loss: 0.0303\n",
      "Epoch 41/250\n",
      "520/520 - 63s - loss: 0.0299 - val_loss: 0.0296\n",
      "Epoch 42/250\n",
      "520/520 - 63s - loss: 0.0297 - val_loss: 0.0293\n",
      "Epoch 43/250\n",
      "520/520 - 63s - loss: 0.0296 - val_loss: 0.0296\n",
      "Epoch 44/250\n",
      "520/520 - 63s - loss: 0.0294 - val_loss: 0.0289\n",
      "Epoch 45/250\n",
      "520/520 - 63s - loss: 0.0292 - val_loss: 0.0287\n",
      "Epoch 46/250\n",
      "520/520 - 63s - loss: 0.0291 - val_loss: 0.0287\n",
      "Epoch 47/250\n",
      "520/520 - 63s - loss: 0.0289 - val_loss: 0.0285\n",
      "Epoch 48/250\n",
      "520/520 - 64s - loss: 0.0288 - val_loss: 0.0281\n",
      "Epoch 49/250\n",
      "520/520 - 64s - loss: 0.0286 - val_loss: 0.0282\n",
      "Epoch 50/250\n",
      "520/520 - 63s - loss: 0.0285 - val_loss: 0.0285\n",
      "Epoch 51/250\n",
      "520/520 - 61s - loss: 0.0284 - val_loss: 0.0279\n",
      "Epoch 52/250\n",
      "520/520 - 63s - loss: 0.0282 - val_loss: 0.0278\n",
      "Epoch 53/250\n",
      "520/520 - 63s - loss: 0.0282 - val_loss: 0.0275\n",
      "Epoch 54/250\n",
      "520/520 - 63s - loss: 0.0280 - val_loss: 0.0276\n",
      "Epoch 55/250\n",
      "520/520 - 63s - loss: 0.0279 - val_loss: 0.0274\n",
      "Epoch 56/250\n",
      "520/520 - 62s - loss: 0.0278 - val_loss: 0.0273\n",
      "Epoch 57/250\n",
      "520/520 - 63s - loss: 0.0277 - val_loss: 0.0272\n",
      "Epoch 58/250\n",
      "520/520 - 62s - loss: 0.0276 - val_loss: 0.0277\n",
      "Epoch 59/250\n",
      "520/520 - 63s - loss: 0.0275 - val_loss: 0.0274\n",
      "Epoch 60/250\n",
      "520/520 - 62s - loss: 0.0274 - val_loss: 0.0274\n",
      "Epoch 61/250\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.030000000447034835.\n",
      "520/520 - 62s - loss: 0.0273 - val_loss: 0.0274\n",
      "Epoch 62/250\n",
      "520/520 - 63s - loss: 0.0264 - val_loss: 0.0265\n",
      "Epoch 63/250\n",
      "520/520 - 62s - loss: 0.0264 - val_loss: 0.0264\n",
      "Epoch 64/250\n",
      "520/520 - 63s - loss: 0.0263 - val_loss: 0.0264\n",
      "Epoch 65/250\n",
      "520/520 - 63s - loss: 0.0263 - val_loss: 0.0264\n",
      "Epoch 66/250\n",
      "520/520 - 63s - loss: 0.0263 - val_loss: 0.0263\n",
      "Epoch 67/250\n",
      "520/520 - 62s - loss: 0.0262 - val_loss: 0.0263\n",
      "Epoch 68/250\n",
      "520/520 - 63s - loss: 0.0262 - val_loss: 0.0263\n",
      "Epoch 69/250\n",
      "520/520 - 62s - loss: 0.0262 - val_loss: 0.0262\n",
      "Epoch 70/250\n",
      "520/520 - 63s - loss: 0.0261 - val_loss: 0.0262\n",
      "Epoch 71/250\n",
      "520/520 - 63s - loss: 0.0261 - val_loss: 0.0262\n",
      "Epoch 72/250\n",
      "520/520 - 62s - loss: 0.0261 - val_loss: 0.0261\n",
      "Epoch 73/250\n",
      "520/520 - 63s - loss: 0.0260 - val_loss: 0.0261\n",
      "Epoch 74/250\n",
      "520/520 - 62s - loss: 0.0260 - val_loss: 0.0261\n",
      "Epoch 75/250\n",
      "520/520 - 63s - loss: 0.0260 - val_loss: 0.0260\n",
      "Epoch 76/250\n",
      "520/520 - 63s - loss: 0.0259 - val_loss: 0.0260\n",
      "Epoch 77/250\n",
      "520/520 - 62s - loss: 0.0259 - val_loss: 0.0260\n",
      "Epoch 78/250\n",
      "520/520 - 62s - loss: 0.0259 - val_loss: 0.0260\n",
      "Epoch 79/250\n",
      "520/520 - 62s - loss: 0.0259 - val_loss: 0.0259\n",
      "Epoch 80/250\n",
      "520/520 - 63s - loss: 0.0258 - val_loss: 0.0259\n",
      "Epoch 81/250\n",
      "520/520 - 63s - loss: 0.0258 - val_loss: 0.0259\n",
      "Epoch 82/250\n",
      "520/520 - 62s - loss: 0.0258 - val_loss: 0.0259\n",
      "Epoch 83/250\n",
      "520/520 - 63s - loss: 0.0258 - val_loss: 0.0258\n",
      "Epoch 84/250\n",
      "520/520 - 62s - loss: 0.0257 - val_loss: 0.0258\n",
      "Epoch 85/250\n",
      "520/520 - 62s - loss: 0.0257 - val_loss: 0.0258\n",
      "Epoch 86/250\n",
      "520/520 - 62s - loss: 0.0257 - val_loss: 0.0257\n",
      "Epoch 87/250\n",
      "520/520 - 62s - loss: 0.0257 - val_loss: 0.0257\n",
      "Epoch 88/250\n",
      "520/520 - 62s - loss: 0.0256 - val_loss: 0.0257\n",
      "Epoch 89/250\n",
      "520/520 - 62s - loss: 0.0256 - val_loss: 0.0257\n",
      "Epoch 90/250\n",
      "520/520 - 62s - loss: 0.0256 - val_loss: 0.0256\n",
      "Epoch 91/250\n",
      "520/520 - 62s - loss: 0.0255 - val_loss: 0.0256\n",
      "Epoch 92/250\n",
      "520/520 - 62s - loss: 0.0255 - val_loss: 0.0256\n",
      "Epoch 93/250\n",
      "520/520 - 62s - loss: 0.0255 - val_loss: 0.0256\n",
      "Epoch 94/250\n",
      "520/520 - 62s - loss: 0.0255 - val_loss: 0.0256\n",
      "Epoch 95/250\n",
      "520/520 - 62s - loss: 0.0255 - val_loss: 0.0255\n",
      "Epoch 96/250\n",
      "520/520 - 63s - loss: 0.0254 - val_loss: 0.0255\n",
      "Epoch 97/250\n",
      "520/520 - 62s - loss: 0.0254 - val_loss: 0.0255\n",
      "Epoch 98/250\n",
      "520/520 - 62s - loss: 0.0254 - val_loss: 0.0255\n",
      "Epoch 99/250\n",
      "520/520 - 62s - loss: 0.0254 - val_loss: 0.0254\n",
      "Epoch 100/250\n",
      "520/520 - 62s - loss: 0.0253 - val_loss: 0.0254\n",
      "Epoch 101/250\n",
      "520/520 - 62s - loss: 0.0253 - val_loss: 0.0254\n",
      "Epoch 102/250\n",
      "520/520 - 63s - loss: 0.0253 - val_loss: 0.0254\n",
      "Epoch 103/250\n",
      "520/520 - 63s - loss: 0.0253 - val_loss: 0.0254\n",
      "Epoch 104/250\n",
      "520/520 - 63s - loss: 0.0253 - val_loss: 0.0253\n",
      "Epoch 105/250\n",
      "520/520 - 63s - loss: 0.0252 - val_loss: 0.0253\n",
      "Epoch 106/250\n",
      "520/520 - 62s - loss: 0.0252 - val_loss: 0.0253\n",
      "Epoch 107/250\n",
      "520/520 - 62s - loss: 0.0252 - val_loss: 0.0253\n",
      "Epoch 108/250\n",
      "520/520 - 62s - loss: 0.0252 - val_loss: 0.0253\n",
      "Epoch 109/250\n",
      "520/520 - 62s - loss: 0.0252 - val_loss: 0.0252\n",
      "Epoch 110/250\n",
      "520/520 - 63s - loss: 0.0251 - val_loss: 0.0252\n",
      "Epoch 111/250\n",
      "520/520 - 63s - loss: 0.0251 - val_loss: 0.0252\n",
      "Epoch 112/250\n",
      "520/520 - 62s - loss: 0.0251 - val_loss: 0.0252\n",
      "Epoch 113/250\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.009000000357627868.\n",
      "520/520 - 63s - loss: 0.0251 - val_loss: 0.0252\n",
      "Epoch 114/250\n",
      "520/520 - 63s - loss: 0.0251 - val_loss: 0.0252\n",
      "Epoch 115/250\n",
      "520/520 - 63s - loss: 0.0251 - val_loss: 0.0251\n",
      "Epoch 116/250\n",
      "520/520 - 63s - loss: 0.0251 - val_loss: 0.0251\n",
      "Epoch 117/250\n",
      "520/520 - 63s - loss: 0.0251 - val_loss: 0.0251\n",
      "Epoch 118/250\n",
      "520/520 - 63s - loss: 0.0251 - val_loss: 0.0251\n",
      "Epoch 119/250\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 0.002700000163167715.\n",
      "520/520 - 62s - loss: 0.0250 - val_loss: 0.0251\n",
      "Epoch 120/250\n",
      "520/520 - 62s - loss: 0.0250 - val_loss: 0.0251\n",
      "Epoch 121/250\n",
      "520/520 - 63s - loss: 0.0250 - val_loss: 0.0251\n",
      "Epoch 122/250\n",
      "520/520 - 63s - loss: 0.0250 - val_loss: 0.0251\n",
      "Epoch 123/250\n",
      "520/520 - 63s - loss: 0.0250 - val_loss: 0.0251\n",
      "Epoch 124/250\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 0.0008100000210106373.\n",
      "520/520 - 62s - loss: 0.0250 - val_loss: 0.0251\n",
      "Epoch 125/250\n",
      "520/520 - 62s - loss: 0.0250 - val_loss: 0.0251\n",
      "Epoch 126/250\n",
      "520/520 - 63s - loss: 0.0250 - val_loss: 0.0251\n",
      "Epoch 127/250\n",
      "520/520 - 63s - loss: 0.0250 - val_loss: 0.0251\n",
      "Epoch 128/250\n",
      "520/520 - 62s - loss: 0.0250 - val_loss: 0.0251\n",
      "Epoch 129/250\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 0.00024299999931827186.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "520/520 - 62s - loss: 0.0250 - val_loss: 0.0251\n",
      "Epoch 00129: early stopping\n",
      "training layer conv4_block1_2_conv\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 520 steps, validate for 104 steps\n",
      "Epoch 1/250\n",
      "520/520 - 59s - loss: 0.2682 - val_loss: 0.2484\n",
      "Epoch 2/250\n",
      "520/520 - 59s - loss: 0.2370 - val_loss: 0.2257\n",
      "Epoch 3/250\n",
      "520/520 - 59s - loss: 0.2077 - val_loss: 0.1855\n",
      "Epoch 4/250\n",
      "520/520 - 59s - loss: 0.1639 - val_loss: 0.1442\n",
      "Epoch 5/250\n",
      "520/520 - 58s - loss: 0.1307 - val_loss: 0.1178\n",
      "Epoch 6/250\n",
      "520/520 - 59s - loss: 0.1089 - val_loss: 0.1004\n",
      "Epoch 7/250\n",
      "520/520 - 58s - loss: 0.0942 - val_loss: 0.0881\n",
      "Epoch 8/250\n",
      "520/520 - 59s - loss: 0.0837 - val_loss: 0.0792\n",
      "Epoch 9/250\n",
      "520/520 - 59s - loss: 0.0758 - val_loss: 0.0722\n",
      "Epoch 10/250\n",
      "520/520 - 59s - loss: 0.0695 - val_loss: 0.0665\n",
      "Epoch 11/250\n",
      "520/520 - 59s - loss: 0.0642 - val_loss: 0.0617\n",
      "Epoch 12/250\n",
      "520/520 - 58s - loss: 0.0599 - val_loss: 0.0577\n",
      "Epoch 13/250\n",
      "520/520 - 59s - loss: 0.0562 - val_loss: 0.0544\n",
      "Epoch 14/250\n",
      "520/520 - 59s - loss: 0.0531 - val_loss: 0.0515\n",
      "Epoch 15/250\n",
      "520/520 - 59s - loss: 0.0504 - val_loss: 0.0490\n",
      "Epoch 16/250\n",
      "520/520 - 59s - loss: 0.0480 - val_loss: 0.0468\n",
      "Epoch 17/250\n",
      "520/520 - 59s - loss: 0.0460 - val_loss: 0.0449\n",
      "Epoch 18/250\n",
      "520/520 - 59s - loss: 0.0442 - val_loss: 0.0432\n",
      "Epoch 19/250\n",
      "520/520 - 59s - loss: 0.0425 - val_loss: 0.0416\n",
      "Epoch 20/250\n",
      "520/520 - 58s - loss: 0.0410 - val_loss: 0.0402\n",
      "Epoch 21/250\n",
      "520/520 - 59s - loss: 0.0397 - val_loss: 0.0390\n",
      "Epoch 22/250\n",
      "520/520 - 59s - loss: 0.0383 - val_loss: 0.0374\n",
      "Epoch 23/250\n",
      "520/520 - 59s - loss: 0.0369 - val_loss: 0.0362\n",
      "Epoch 24/250\n",
      "520/520 - 59s - loss: 0.0358 - val_loss: 0.0352\n",
      "Epoch 25/250\n",
      "520/520 - 59s - loss: 0.0349 - val_loss: 0.0344\n",
      "Epoch 26/250\n",
      "520/520 - 59s - loss: 0.0340 - val_loss: 0.0335\n",
      "Epoch 27/250\n",
      "520/520 - 59s - loss: 0.0332 - val_loss: 0.0328\n",
      "Epoch 28/250\n",
      "520/520 - 59s - loss: 0.0327 - val_loss: 0.0322\n",
      "Epoch 29/250\n",
      "520/520 - 59s - loss: 0.0320 - val_loss: 0.0317\n",
      "Epoch 30/250\n",
      "520/520 - 59s - loss: 0.0314 - val_loss: 0.0311\n",
      "Epoch 31/250\n",
      "520/520 - 59s - loss: 0.0308 - val_loss: 0.0306\n",
      "Epoch 32/250\n",
      "520/520 - 59s - loss: 0.0303 - val_loss: 0.0301\n",
      "Epoch 33/250\n",
      "520/520 - 59s - loss: 0.0298 - val_loss: 0.0294\n",
      "Epoch 34/250\n",
      "520/520 - 59s - loss: 0.0294 - val_loss: 0.0292\n",
      "Epoch 35/250\n",
      "520/520 - 58s - loss: 0.0289 - val_loss: 0.0286\n",
      "Epoch 36/250\n",
      "520/520 - 58s - loss: 0.0285 - val_loss: 0.0283\n",
      "Epoch 37/250\n",
      "520/520 - 58s - loss: 0.0281 - val_loss: 0.0279\n",
      "Epoch 38/250\n",
      "520/520 - 59s - loss: 0.0278 - val_loss: 0.0276\n",
      "Epoch 39/250\n",
      "520/520 - 59s - loss: 0.0274 - val_loss: 0.0274\n",
      "Epoch 40/250\n",
      "520/520 - 58s - loss: 0.0271 - val_loss: 0.0270\n",
      "Epoch 41/250\n",
      "520/520 - 58s - loss: 0.0268 - val_loss: 0.0265\n",
      "Epoch 42/250\n",
      "520/520 - 58s - loss: 0.0265 - val_loss: 0.0263\n",
      "Epoch 43/250\n",
      "520/520 - 58s - loss: 0.0262 - val_loss: 0.0263\n",
      "Epoch 44/250\n",
      "520/520 - 58s - loss: 0.0260 - val_loss: 0.0258\n",
      "Epoch 45/250\n",
      "520/520 - 58s - loss: 0.0257 - val_loss: 0.0258\n",
      "Epoch 46/250\n",
      "520/520 - 58s - loss: 0.0255 - val_loss: 0.0255\n",
      "Epoch 47/250\n",
      "520/520 - 58s - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 48/250\n",
      "520/520 - 58s - loss: 0.0250 - val_loss: 0.0250\n",
      "Epoch 49/250\n",
      "520/520 - 58s - loss: 0.0248 - val_loss: 0.0247\n",
      "Epoch 50/250\n",
      "520/520 - 58s - loss: 0.0246 - val_loss: 0.0248\n",
      "Epoch 51/250\n",
      "520/520 - 58s - loss: 0.0244 - val_loss: 0.0243\n",
      "Epoch 52/250\n",
      "520/520 - 59s - loss: 0.0242 - val_loss: 0.0243\n",
      "Epoch 53/250\n",
      "520/520 - 59s - loss: 0.0240 - val_loss: 0.0243\n",
      "Epoch 54/250\n",
      "520/520 - 59s - loss: 0.0239 - val_loss: 0.0239\n",
      "Epoch 55/250\n",
      "520/520 - 59s - loss: 0.0236 - val_loss: 0.0236\n",
      "Epoch 56/250\n",
      "520/520 - 59s - loss: 0.0235 - val_loss: 0.0238\n",
      "Epoch 57/250\n",
      "520/520 - 59s - loss: 0.0233 - val_loss: 0.0236\n",
      "Epoch 58/250\n",
      "520/520 - 59s - loss: 0.0232 - val_loss: 0.0232\n",
      "Epoch 59/250\n",
      "520/520 - 59s - loss: 0.0230 - val_loss: 0.0234\n",
      "Epoch 60/250\n",
      "520/520 - 59s - loss: 0.0229 - val_loss: 0.0231\n",
      "Epoch 61/250\n",
      "520/520 - 59s - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 62/250\n",
      "520/520 - 59s - loss: 0.0226 - val_loss: 0.0227\n",
      "Epoch 63/250\n",
      "520/520 - 59s - loss: 0.0225 - val_loss: 0.0225\n",
      "Epoch 64/250\n",
      "520/520 - 59s - loss: 0.0224 - val_loss: 0.0225\n",
      "Epoch 65/250\n",
      "520/520 - 59s - loss: 0.0223 - val_loss: 0.0224\n",
      "Epoch 66/250\n",
      "520/520 - 59s - loss: 0.0221 - val_loss: 0.0222\n",
      "Epoch 67/250\n",
      "520/520 - 59s - loss: 0.0220 - val_loss: 0.0221\n",
      "Epoch 68/250\n",
      "520/520 - 59s - loss: 0.0219 - val_loss: 0.0221\n",
      "Epoch 69/250\n",
      "520/520 - 59s - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 70/250\n",
      "520/520 - 59s - loss: 0.0217 - val_loss: 0.0222\n",
      "Epoch 71/250\n",
      "520/520 - 59s - loss: 0.0216 - val_loss: 0.0217\n",
      "Epoch 72/250\n",
      "520/520 - 60s - loss: 0.0215 - val_loss: 0.0216\n",
      "Epoch 73/250\n",
      "520/520 - 60s - loss: 0.0214 - val_loss: 0.0216\n",
      "Epoch 74/250\n",
      "520/520 - 59s - loss: 0.0213 - val_loss: 0.0217\n",
      "Epoch 75/250\n",
      "520/520 - 59s - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 76/250\n",
      "520/520 - 59s - loss: 0.0211 - val_loss: 0.0212\n",
      "Epoch 77/250\n",
      "520/520 - 59s - loss: 0.0210 - val_loss: 0.0215\n",
      "Epoch 78/250\n",
      "520/520 - 59s - loss: 0.0209 - val_loss: 0.0209\n",
      "Epoch 79/250\n",
      "520/520 - 59s - loss: 0.0209 - val_loss: 0.0211\n",
      "Epoch 80/250\n",
      "520/520 - 59s - loss: 0.0208 - val_loss: 0.0209\n",
      "Epoch 81/250\n",
      "520/520 - 59s - loss: 0.0207 - val_loss: 0.0207\n",
      "Epoch 82/250\n",
      "520/520 - 59s - loss: 0.0206 - val_loss: 0.0206\n",
      "Epoch 83/250\n",
      "520/520 - 59s - loss: 0.0206 - val_loss: 0.0205\n",
      "Epoch 84/250\n",
      "520/520 - 59s - loss: 0.0205 - val_loss: 0.0207\n",
      "Epoch 85/250\n",
      "520/520 - 59s - loss: 0.0204 - val_loss: 0.0205\n",
      "Epoch 86/250\n",
      "520/520 - 59s - loss: 0.0203 - val_loss: 0.0204\n",
      "Epoch 87/250\n",
      "520/520 - 59s - loss: 0.0203 - val_loss: 0.0202\n",
      "Epoch 88/250\n",
      "520/520 - 58s - loss: 0.0202 - val_loss: 0.0202\n",
      "Epoch 89/250\n",
      "520/520 - 58s - loss: 0.0201 - val_loss: 0.0201\n",
      "Epoch 90/250\n",
      "520/520 - 58s - loss: 0.0201 - val_loss: 0.0200\n",
      "Epoch 91/250\n",
      "520/520 - 58s - loss: 0.0200 - val_loss: 0.0200\n",
      "Epoch 92/250\n",
      "520/520 - 58s - loss: 0.0199 - val_loss: 0.0199\n",
      "Epoch 93/250\n",
      "520/520 - 59s - loss: 0.0199 - val_loss: 0.0197\n",
      "Epoch 94/250\n",
      "520/520 - 56s - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 95/250\n",
      "520/520 - 58s - loss: 0.0197 - val_loss: 0.0196\n",
      "Epoch 96/250\n",
      "520/520 - 58s - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 97/250\n",
      "520/520 - 59s - loss: 0.0196 - val_loss: 0.0196\n",
      "Epoch 98/250\n",
      "520/520 - 58s - loss: 0.0196 - val_loss: 0.0194\n",
      "Epoch 99/250\n",
      "520/520 - 58s - loss: 0.0195 - val_loss: 0.0194\n",
      "Epoch 100/250\n",
      "520/520 - 58s - loss: 0.0195 - val_loss: 0.0194\n",
      "Epoch 101/250\n",
      "520/520 - 58s - loss: 0.0194 - val_loss: 0.0194\n",
      "Epoch 102/250\n",
      "520/520 - 58s - loss: 0.0193 - val_loss: 0.0192\n",
      "Epoch 103/250\n",
      "520/520 - 58s - loss: 0.0191 - val_loss: 0.0188\n",
      "Epoch 104/250\n",
      "520/520 - 58s - loss: 0.0189 - val_loss: 0.0187\n",
      "Epoch 105/250\n",
      "520/520 - 58s - loss: 0.0187 - val_loss: 0.0186\n",
      "Epoch 106/250\n",
      "520/520 - 58s - loss: 0.0187 - val_loss: 0.0185\n",
      "Epoch 107/250\n",
      "520/520 - 58s - loss: 0.0186 - val_loss: 0.0184\n",
      "Epoch 108/250\n",
      "520/520 - 58s - loss: 0.0186 - val_loss: 0.0184\n",
      "Epoch 109/250\n",
      "520/520 - 59s - loss: 0.0185 - val_loss: 0.0183\n",
      "Epoch 110/250\n",
      "520/520 - 58s - loss: 0.0184 - val_loss: 0.0183\n",
      "Epoch 111/250\n",
      "520/520 - 58s - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 112/250\n",
      "520/520 - 58s - loss: 0.0183 - val_loss: 0.0182\n",
      "Epoch 113/250\n",
      "520/520 - 58s - loss: 0.0183 - val_loss: 0.0181\n",
      "Epoch 114/250\n",
      "520/520 - 59s - loss: 0.0183 - val_loss: 0.0182\n",
      "Epoch 115/250\n",
      "520/520 - 58s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 116/250\n",
      "520/520 - 58s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 117/250\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 0.030000000447034835.\n",
      "520/520 - 58s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 118/250\n",
      "520/520 - 58s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 119/250\n",
      "520/520 - 58s - loss: 0.0178 - val_loss: 0.0177\n",
      "Epoch 120/250\n",
      "520/520 - 58s - loss: 0.0178 - val_loss: 0.0177\n",
      "Epoch 121/250\n",
      "520/520 - 59s - loss: 0.0178 - val_loss: 0.0177\n",
      "Epoch 122/250\n",
      "520/520 - 58s - loss: 0.0178 - val_loss: 0.0177\n",
      "Epoch 123/250\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.009000000357627868.\n",
      "520/520 - 58s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 124/250\n",
      "520/520 - 57s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 125/250\n",
      "520/520 - 57s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 126/250\n",
      "520/520 - 57s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 127/250\n",
      "520/520 - 58s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 128/250\n",
      "520/520 - 58s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 129/250\n",
      "520/520 - 58s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 130/250\n",
      "520/520 - 58s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 131/250\n",
      "520/520 - 57s - loss: 0.0177 - val_loss: 0.0176\n",
      "Epoch 132/250\n",
      "520/520 - 58s - loss: 0.0177 - val_loss: 0.0176\n",
      "Epoch 133/250\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 0.002700000163167715.\n",
      "520/520 - 58s - loss: 0.0177 - val_loss: 0.0176\n",
      "Epoch 134/250\n",
      "520/520 - 58s - loss: 0.0177 - val_loss: 0.0176\n",
      "Epoch 135/250\n",
      "520/520 - 58s - loss: 0.0177 - val_loss: 0.0176\n",
      "Epoch 136/250\n",
      "520/520 - 58s - loss: 0.0177 - val_loss: 0.0176\n",
      "Epoch 137/250\n",
      "520/520 - 58s - loss: 0.0177 - val_loss: 0.0176\n",
      "Epoch 138/250\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 0.0008100000210106373.\n",
      "520/520 - 58s - loss: 0.0177 - val_loss: 0.0176\n",
      "Epoch 139/250\n",
      "520/520 - 58s - loss: 0.0177 - val_loss: 0.0176\n",
      "Epoch 140/250\n",
      "520/520 - 58s - loss: 0.0177 - val_loss: 0.0176\n",
      "Epoch 141/250\n",
      "520/520 - 58s - loss: 0.0177 - val_loss: 0.0176\n",
      "Epoch 142/250\n",
      "520/520 - 58s - loss: 0.0177 - val_loss: 0.0176\n",
      "Epoch 143/250\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 0.00024299999931827186.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "520/520 - 58s - loss: 0.0177 - val_loss: 0.0176\n",
      "Epoch 00143: early stopping\n",
      "training layer conv4_block2_2_conv\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 520 steps, validate for 104 steps\n",
      "Epoch 1/250\n",
      "520/520 - 62s - loss: 0.1437 - val_loss: 0.1378\n",
      "Epoch 2/250\n",
      "520/520 - 62s - loss: 0.1365 - val_loss: 0.1375\n",
      "Epoch 3/250\n",
      "520/520 - 61s - loss: 0.1358 - val_loss: 0.1362\n",
      "Epoch 4/250\n",
      "520/520 - 62s - loss: 0.1331 - val_loss: 0.1316\n",
      "Epoch 5/250\n",
      "520/520 - 61s - loss: 0.1276 - val_loss: 0.1244\n",
      "Epoch 6/250\n",
      "520/520 - 61s - loss: 0.1186 - val_loss: 0.1133\n",
      "Epoch 7/250\n",
      "520/520 - 61s - loss: 0.1078 - val_loss: 0.1029\n",
      "Epoch 8/250\n",
      "520/520 - 61s - loss: 0.0982 - val_loss: 0.0937\n",
      "Epoch 9/250\n",
      "520/520 - 61s - loss: 0.0893 - val_loss: 0.0851\n",
      "Epoch 10/250\n",
      "520/520 - 61s - loss: 0.0811 - val_loss: 0.0774\n",
      "Epoch 11/250\n",
      "520/520 - 61s - loss: 0.0740 - val_loss: 0.0707\n",
      "Epoch 12/250\n",
      "520/520 - 61s - loss: 0.0678 - val_loss: 0.0650\n",
      "Epoch 13/250\n",
      "520/520 - 62s - loss: 0.0624 - val_loss: 0.0599\n",
      "Epoch 14/250\n",
      "520/520 - 61s - loss: 0.0575 - val_loss: 0.0553\n",
      "Epoch 15/250\n",
      "520/520 - 61s - loss: 0.0533 - val_loss: 0.0514\n",
      "Epoch 16/250\n",
      "520/520 - 62s - loss: 0.0497 - val_loss: 0.0481\n",
      "Epoch 17/250\n",
      "520/520 - 62s - loss: 0.0467 - val_loss: 0.0453\n",
      "Epoch 18/250\n",
      "520/520 - 62s - loss: 0.0440 - val_loss: 0.0428\n",
      "Epoch 19/250\n",
      "520/520 - 62s - loss: 0.0418 - val_loss: 0.0407\n",
      "Epoch 20/250\n",
      "520/520 - 62s - loss: 0.0397 - val_loss: 0.0388\n",
      "Epoch 21/250\n",
      "520/520 - 62s - loss: 0.0380 - val_loss: 0.0371\n",
      "Epoch 22/250\n",
      "520/520 - 62s - loss: 0.0364 - val_loss: 0.0356\n",
      "Epoch 23/250\n",
      "520/520 - 62s - loss: 0.0350 - val_loss: 0.0343\n",
      "Epoch 24/250\n",
      "520/520 - 62s - loss: 0.0337 - val_loss: 0.0330\n",
      "Epoch 25/250\n",
      "520/520 - 62s - loss: 0.0325 - val_loss: 0.0319\n",
      "Epoch 26/250\n",
      "520/520 - 62s - loss: 0.0314 - val_loss: 0.0309\n",
      "Epoch 27/250\n",
      "520/520 - 61s - loss: 0.0304 - val_loss: 0.0299\n",
      "Epoch 28/250\n",
      "520/520 - 62s - loss: 0.0295 - val_loss: 0.0290\n",
      "Epoch 29/250\n",
      "520/520 - 62s - loss: 0.0286 - val_loss: 0.0282\n",
      "Epoch 30/250\n",
      "520/520 - 61s - loss: 0.0278 - val_loss: 0.0274\n",
      "Epoch 31/250\n",
      "520/520 - 61s - loss: 0.0271 - val_loss: 0.0267\n",
      "Epoch 32/250\n",
      "520/520 - 61s - loss: 0.0264 - val_loss: 0.0261\n",
      "Epoch 33/250\n",
      "520/520 - 62s - loss: 0.0258 - val_loss: 0.0254\n",
      "Epoch 34/250\n",
      "520/520 - 62s - loss: 0.0251 - val_loss: 0.0248\n",
      "Epoch 35/250\n",
      "520/520 - 61s - loss: 0.0246 - val_loss: 0.0243\n",
      "Epoch 36/250\n",
      "520/520 - 61s - loss: 0.0240 - val_loss: 0.0238\n",
      "Epoch 37/250\n",
      "520/520 - 61s - loss: 0.0235 - val_loss: 0.0233\n",
      "Epoch 38/250\n",
      "520/520 - 61s - loss: 0.0230 - val_loss: 0.0228\n",
      "Epoch 39/250\n",
      "520/520 - 61s - loss: 0.0226 - val_loss: 0.0223\n",
      "Epoch 40/250\n",
      "520/520 - 61s - loss: 0.0221 - val_loss: 0.0219\n",
      "Epoch 41/250\n",
      "520/520 - 61s - loss: 0.0217 - val_loss: 0.0215\n",
      "Epoch 42/250\n",
      "520/520 - 61s - loss: 0.0213 - val_loss: 0.0211\n",
      "Epoch 43/250\n",
      "520/520 - 61s - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 44/250\n",
      "520/520 - 61s - loss: 0.0206 - val_loss: 0.0204\n",
      "Epoch 45/250\n",
      "520/520 - 61s - loss: 0.0202 - val_loss: 0.0201\n",
      "Epoch 46/250\n",
      "520/520 - 61s - loss: 0.0199 - val_loss: 0.0197\n",
      "Epoch 47/250\n",
      "520/520 - 61s - loss: 0.0196 - val_loss: 0.0194\n",
      "Epoch 48/250\n",
      "520/520 - 61s - loss: 0.0193 - val_loss: 0.0191\n",
      "Epoch 49/250\n",
      "520/520 - 61s - loss: 0.0190 - val_loss: 0.0188\n",
      "Epoch 50/250\n",
      "520/520 - 61s - loss: 0.0187 - val_loss: 0.0186\n",
      "Epoch 51/250\n",
      "520/520 - 61s - loss: 0.0184 - val_loss: 0.0183\n",
      "Epoch 52/250\n",
      "520/520 - 61s - loss: 0.0182 - val_loss: 0.0181\n",
      "Epoch 53/250\n",
      "520/520 - 60s - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 54/250\n",
      "520/520 - 61s - loss: 0.0178 - val_loss: 0.0176\n",
      "Epoch 55/250\n",
      "520/520 - 62s - loss: 0.0176 - val_loss: 0.0174\n",
      "Epoch 56/250\n",
      "520/520 - 62s - loss: 0.0173 - val_loss: 0.0172\n",
      "Epoch 57/250\n",
      "520/520 - 62s - loss: 0.0171 - val_loss: 0.0170\n",
      "Epoch 58/250\n",
      "520/520 - 62s - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 59/250\n",
      "520/520 - 62s - loss: 0.0168 - val_loss: 0.0169\n",
      "Epoch 60/250\n",
      "520/520 - 62s - loss: 0.0166 - val_loss: 0.0167\n",
      "Epoch 61/250\n",
      "520/520 - 62s - loss: 0.0164 - val_loss: 0.0164\n",
      "Epoch 62/250\n",
      "520/520 - 62s - loss: 0.0162 - val_loss: 0.0163\n",
      "Epoch 63/250\n",
      "520/520 - 62s - loss: 0.0161 - val_loss: 0.0162\n",
      "Epoch 64/250\n",
      "520/520 - 62s - loss: 0.0159 - val_loss: 0.0157\n",
      "Epoch 65/250\n",
      "520/520 - 62s - loss: 0.0157 - val_loss: 0.0156\n",
      "Epoch 66/250\n",
      "520/520 - 61s - loss: 0.0156 - val_loss: 0.0155\n",
      "Epoch 67/250\n",
      "520/520 - 62s - loss: 0.0154 - val_loss: 0.0153\n",
      "Epoch 68/250\n",
      "520/520 - 61s - loss: 0.0153 - val_loss: 0.0154\n",
      "Epoch 69/250\n",
      "520/520 - 62s - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 70/250\n",
      "520/520 - 62s - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 71/250\n",
      "520/520 - 61s - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 72/250\n",
      "520/520 - 62s - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 73/250\n",
      "520/520 - 62s - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 74/250\n",
      "520/520 - 62s - loss: 0.0145 - val_loss: 0.0146\n",
      "Epoch 75/250\n",
      "520/520 - 61s - loss: 0.0144 - val_loss: 0.0144\n",
      "Epoch 76/250\n",
      "520/520 - 61s - loss: 0.0142 - val_loss: 0.0143\n",
      "Epoch 77/250\n",
      "520/520 - 62s - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 78/250\n",
      "520/520 - 61s - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 79/250\n",
      "520/520 - 61s - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 80/250\n",
      "520/520 - 62s - loss: 0.0138 - val_loss: 0.0137\n",
      "Epoch 81/250\n",
      "520/520 - 61s - loss: 0.0137 - val_loss: 0.0138\n",
      "Epoch 82/250\n",
      "520/520 - 61s - loss: 0.0136 - val_loss: 0.0139\n",
      "Epoch 83/250\n",
      "520/520 - 61s - loss: 0.0135 - val_loss: 0.0137\n",
      "Epoch 84/250\n",
      "520/520 - 61s - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 85/250\n",
      "520/520 - 61s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 86/250\n",
      "520/520 - 61s - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 87/250\n",
      "520/520 - 61s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 88/250\n",
      "520/520 - 61s - loss: 0.0131 - val_loss: 0.0132\n",
      "Epoch 89/250\n",
      "520/520 - 61s - loss: 0.0130 - val_loss: 0.0130\n",
      "Epoch 90/250\n",
      "520/520 - 61s - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 91/250\n",
      "520/520 - 61s - loss: 0.0128 - val_loss: 0.0129\n",
      "Epoch 92/250\n",
      "520/520 - 61s - loss: 0.0128 - val_loss: 0.0127\n",
      "Epoch 93/250\n",
      "520/520 - 61s - loss: 0.0127 - val_loss: 0.0127\n",
      "Epoch 94/250\n",
      "520/520 - 61s - loss: 0.0126 - val_loss: 0.0126\n",
      "Epoch 95/250\n",
      "520/520 - 61s - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 96/250\n",
      "520/520 - 61s - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 97/250\n",
      "520/520 - 60s - loss: 0.0124 - val_loss: 0.0125\n",
      "Epoch 98/250\n",
      "520/520 - 61s - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 99/250\n",
      "520/520 - 62s - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 100/250\n",
      "520/520 - 62s - loss: 0.0122 - val_loss: 0.0121\n",
      "Epoch 101/250\n",
      "520/520 - 62s - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 102/250\n",
      "520/520 - 62s - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 103/250\n",
      "520/520 - 62s - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 104/250\n",
      "520/520 - 62s - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 105/250\n",
      "520/520 - 62s - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 106/250\n",
      "520/520 - 61s - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 107/250\n",
      "520/520 - 62s - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 108/250\n",
      "520/520 - 59s - loss: 0.0117 - val_loss: 0.0116\n",
      "Epoch 109/250\n",
      "520/520 - 62s - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 110/250\n",
      "520/520 - 62s - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 111/250\n",
      "520/520 - 62s - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 112/250\n",
      "520/520 - 62s - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 113/250\n",
      "520/520 - 62s - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 114/250\n",
      "520/520 - 62s - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 115/250\n",
      "520/520 - 62s - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 116/250\n",
      "520/520 - 62s - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 117/250\n",
      "520/520 - 62s - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 118/250\n",
      "520/520 - 61s - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 119/250\n",
      "520/520 - 61s - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 120/250\n",
      "520/520 - 62s - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 121/250\n",
      "520/520 - 62s - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 122/250\n",
      "520/520 - 62s - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 123/250\n",
      "520/520 - 61s - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 124/250\n",
      "520/520 - 62s - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 125/250\n",
      "520/520 - 61s - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 126/250\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 0.030000000447034835.\n",
      "520/520 - 61s - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 127/250\n",
      "520/520 - 61s - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 128/250\n",
      "520/520 - 61s - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 129/250\n",
      "520/520 - 61s - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 130/250\n",
      "520/520 - 62s - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 131/250\n",
      "520/520 - 61s - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 132/250\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 0.009000000357627868.\n",
      "520/520 - 61s - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 133/250\n",
      "520/520 - 61s - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 134/250\n",
      "520/520 - 61s - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 135/250\n",
      "520/520 - 61s - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 136/250\n",
      "520/520 - 61s - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 137/250\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 0.002700000163167715.\n",
      "520/520 - 62s - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 138/250\n",
      "520/520 - 62s - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 139/250\n",
      "520/520 - 63s - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 140/250\n",
      "520/520 - 62s - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 141/250\n",
      "520/520 - 62s - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 142/250\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 0.0008100000210106373.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "520/520 - 62s - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 00142: early stopping\n",
      "training layer conv4_block3_2_conv\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 520 steps, validate for 104 steps\n",
      "Epoch 1/250\n",
      "520/520 - 65s - loss: 0.1852 - val_loss: 0.1794\n",
      "Epoch 2/250\n",
      "520/520 - 65s - loss: 0.1779 - val_loss: 0.1793\n",
      "Epoch 3/250\n",
      "520/520 - 64s - loss: 0.1777 - val_loss: 0.1789\n",
      "Epoch 4/250\n",
      "520/520 - 65s - loss: 0.1769 - val_loss: 0.1772\n",
      "Epoch 5/250\n",
      "520/520 - 64s - loss: 0.1735 - val_loss: 0.1721\n",
      "Epoch 6/250\n",
      "520/520 - 66s - loss: 0.1685 - val_loss: 0.1658\n",
      "Epoch 7/250\n",
      "520/520 - 65s - loss: 0.1602 - val_loss: 0.1555\n",
      "Epoch 8/250\n",
      "520/520 - 65s - loss: 0.1502 - val_loss: 0.1456\n",
      "Epoch 9/250\n",
      "520/520 - 65s - loss: 0.1406 - val_loss: 0.1360\n",
      "Epoch 10/250\n",
      "520/520 - 65s - loss: 0.1314 - val_loss: 0.1269\n",
      "Epoch 11/250\n",
      "520/520 - 64s - loss: 0.1227 - val_loss: 0.1186\n",
      "Epoch 12/250\n",
      "520/520 - 65s - loss: 0.1149 - val_loss: 0.1111\n",
      "Epoch 13/250\n",
      "520/520 - 65s - loss: 0.1078 - val_loss: 0.1043\n",
      "Epoch 14/250\n",
      "520/520 - 65s - loss: 0.1013 - val_loss: 0.0981\n",
      "Epoch 15/250\n",
      "520/520 - 65s - loss: 0.0955 - val_loss: 0.0926\n",
      "Epoch 16/250\n",
      "520/520 - 65s - loss: 0.0903 - val_loss: 0.0877\n",
      "Epoch 17/250\n",
      "520/520 - 65s - loss: 0.0857 - val_loss: 0.0833\n",
      "Epoch 18/250\n",
      "520/520 - 65s - loss: 0.0815 - val_loss: 0.0794\n",
      "Epoch 19/250\n",
      "520/520 - 65s - loss: 0.0778 - val_loss: 0.0759\n",
      "Epoch 20/250\n",
      "520/520 - 65s - loss: 0.0746 - val_loss: 0.0728\n",
      "Epoch 21/250\n",
      "520/520 - 65s - loss: 0.0716 - val_loss: 0.0701\n",
      "Epoch 22/250\n",
      "520/520 - 65s - loss: 0.0689 - val_loss: 0.0675\n",
      "Epoch 23/250\n",
      "520/520 - 65s - loss: 0.0665 - val_loss: 0.0653\n",
      "Epoch 24/250\n",
      "520/520 - 65s - loss: 0.0644 - val_loss: 0.0632\n",
      "Epoch 25/250\n",
      "520/520 - 65s - loss: 0.0623 - val_loss: 0.0613\n",
      "Epoch 26/250\n",
      "520/520 - 64s - loss: 0.0605 - val_loss: 0.0595\n",
      "Epoch 27/250\n",
      "520/520 - 65s - loss: 0.0588 - val_loss: 0.0579\n",
      "Epoch 28/250\n",
      "520/520 - 65s - loss: 0.0572 - val_loss: 0.0563\n",
      "Epoch 29/250\n",
      "520/520 - 65s - loss: 0.0557 - val_loss: 0.0549\n",
      "Epoch 30/250\n",
      "520/520 - 65s - loss: 0.0543 - val_loss: 0.0536\n",
      "Epoch 31/250\n",
      "520/520 - 66s - loss: 0.0531 - val_loss: 0.0523\n",
      "Epoch 32/250\n",
      "520/520 - 65s - loss: 0.0519 - val_loss: 0.0512\n",
      "Epoch 33/250\n",
      "520/520 - 65s - loss: 0.0507 - val_loss: 0.0500\n",
      "Epoch 34/250\n",
      "520/520 - 65s - loss: 0.0496 - val_loss: 0.0490\n",
      "Epoch 35/250\n",
      "520/520 - 65s - loss: 0.0486 - val_loss: 0.0480\n",
      "Epoch 36/250\n",
      "520/520 - 65s - loss: 0.0476 - val_loss: 0.0470\n",
      "Epoch 37/250\n",
      "520/520 - 64s - loss: 0.0466 - val_loss: 0.0461\n",
      "Epoch 38/250\n",
      "520/520 - 65s - loss: 0.0457 - val_loss: 0.0452\n",
      "Epoch 39/250\n",
      "520/520 - 65s - loss: 0.0449 - val_loss: 0.0444\n",
      "Epoch 40/250\n",
      "520/520 - 65s - loss: 0.0440 - val_loss: 0.0436\n",
      "Epoch 41/250\n",
      "520/520 - 64s - loss: 0.0433 - val_loss: 0.0428\n",
      "Epoch 42/250\n",
      "520/520 - 66s - loss: 0.0425 - val_loss: 0.0420\n",
      "Epoch 43/250\n",
      "520/520 - 65s - loss: 0.0417 - val_loss: 0.0413\n",
      "Epoch 44/250\n",
      "520/520 - 65s - loss: 0.0410 - val_loss: 0.0406\n",
      "Epoch 45/250\n",
      "520/520 - 65s - loss: 0.0404 - val_loss: 0.0399\n",
      "Epoch 46/250\n",
      "520/520 - 65s - loss: 0.0397 - val_loss: 0.0393\n",
      "Epoch 47/250\n",
      "520/520 - 65s - loss: 0.0391 - val_loss: 0.0387\n",
      "Epoch 48/250\n",
      "520/520 - 65s - loss: 0.0385 - val_loss: 0.0381\n",
      "Epoch 49/250\n",
      "520/520 - 64s - loss: 0.0379 - val_loss: 0.0375\n",
      "Epoch 50/250\n",
      "520/520 - 65s - loss: 0.0373 - val_loss: 0.0370\n",
      "Epoch 51/250\n",
      "520/520 - 64s - loss: 0.0368 - val_loss: 0.0365\n",
      "Epoch 52/250\n",
      "520/520 - 64s - loss: 0.0363 - val_loss: 0.0360\n",
      "Epoch 53/250\n",
      "520/520 - 64s - loss: 0.0359 - val_loss: 0.0356\n",
      "Epoch 54/250\n",
      "520/520 - 65s - loss: 0.0355 - val_loss: 0.0352\n",
      "Epoch 55/250\n",
      "520/520 - 65s - loss: 0.0350 - val_loss: 0.0347\n",
      "Epoch 56/250\n",
      "520/520 - 65s - loss: 0.0346 - val_loss: 0.0343\n",
      "Epoch 57/250\n",
      "520/520 - 65s - loss: 0.0342 - val_loss: 0.0339\n",
      "Epoch 58/250\n",
      "520/520 - 65s - loss: 0.0338 - val_loss: 0.0335\n",
      "Epoch 59/250\n",
      "520/520 - 65s - loss: 0.0335 - val_loss: 0.0332\n",
      "Epoch 60/250\n",
      "520/520 - 65s - loss: 0.0331 - val_loss: 0.0328\n",
      "Epoch 61/250\n",
      "520/520 - 64s - loss: 0.0327 - val_loss: 0.0325\n",
      "Epoch 62/250\n",
      "520/520 - 65s - loss: 0.0324 - val_loss: 0.0321\n",
      "Epoch 63/250\n",
      "520/520 - 64s - loss: 0.0321 - val_loss: 0.0318\n",
      "Epoch 64/250\n",
      "520/520 - 64s - loss: 0.0317 - val_loss: 0.0315\n",
      "Epoch 65/250\n",
      "520/520 - 64s - loss: 0.0314 - val_loss: 0.0312\n",
      "Epoch 66/250\n",
      "520/520 - 64s - loss: 0.0311 - val_loss: 0.0308\n",
      "Epoch 67/250\n",
      "520/520 - 65s - loss: 0.0308 - val_loss: 0.0306\n",
      "Epoch 68/250\n",
      "520/520 - 65s - loss: 0.0306 - val_loss: 0.0303\n",
      "Epoch 69/250\n",
      "520/520 - 65s - loss: 0.0303 - val_loss: 0.0301\n",
      "Epoch 70/250\n",
      "520/520 - 65s - loss: 0.0300 - val_loss: 0.0298\n",
      "Epoch 71/250\n",
      "520/520 - 65s - loss: 0.0298 - val_loss: 0.0296\n",
      "Epoch 72/250\n",
      "520/520 - 65s - loss: 0.0295 - val_loss: 0.0293\n",
      "Epoch 73/250\n",
      "520/520 - 64s - loss: 0.0293 - val_loss: 0.0290\n",
      "Epoch 74/250\n",
      "520/520 - 65s - loss: 0.0291 - val_loss: 0.0288\n",
      "Epoch 75/250\n",
      "520/520 - 65s - loss: 0.0288 - val_loss: 0.0286\n",
      "Epoch 76/250\n",
      "520/520 - 64s - loss: 0.0286 - val_loss: 0.0284\n",
      "Epoch 77/250\n",
      "520/520 - 65s - loss: 0.0284 - val_loss: 0.0282\n",
      "Epoch 78/250\n",
      "520/520 - 64s - loss: 0.0282 - val_loss: 0.0280\n",
      "Epoch 79/250\n",
      "520/520 - 65s - loss: 0.0280 - val_loss: 0.0278\n",
      "Epoch 80/250\n",
      "520/520 - 64s - loss: 0.0278 - val_loss: 0.0276\n",
      "Epoch 81/250\n",
      "520/520 - 65s - loss: 0.0276 - val_loss: 0.0274\n",
      "Epoch 82/250\n",
      "520/520 - 65s - loss: 0.0274 - val_loss: 0.0272\n",
      "Epoch 83/250\n",
      "520/520 - 65s - loss: 0.0273 - val_loss: 0.0270\n",
      "Epoch 84/250\n",
      "520/520 - 65s - loss: 0.0271 - val_loss: 0.0269\n",
      "Epoch 85/250\n",
      "520/520 - 66s - loss: 0.0269 - val_loss: 0.0267\n",
      "Epoch 86/250\n",
      "520/520 - 65s - loss: 0.0267 - val_loss: 0.0265\n",
      "Epoch 87/250\n",
      "520/520 - 64s - loss: 0.0266 - val_loss: 0.0263\n",
      "Epoch 88/250\n",
      "520/520 - 65s - loss: 0.0264 - val_loss: 0.0262\n",
      "Epoch 89/250\n",
      "520/520 - 64s - loss: 0.0262 - val_loss: 0.0260\n",
      "Epoch 90/250\n",
      "520/520 - 65s - loss: 0.0261 - val_loss: 0.0259\n",
      "Epoch 91/250\n",
      "520/520 - 65s - loss: 0.0259 - val_loss: 0.0258\n",
      "Epoch 92/250\n",
      "520/520 - 66s - loss: 0.0258 - val_loss: 0.0257\n",
      "Epoch 93/250\n",
      "520/520 - 65s - loss: 0.0256 - val_loss: 0.0255\n",
      "Epoch 94/250\n",
      "520/520 - 65s - loss: 0.0255 - val_loss: 0.0253\n",
      "Epoch 95/250\n",
      "520/520 - 64s - loss: 0.0254 - val_loss: 0.0252\n",
      "Epoch 96/250\n",
      "520/520 - 65s - loss: 0.0252 - val_loss: 0.0251\n",
      "Epoch 97/250\n",
      "520/520 - 65s - loss: 0.0251 - val_loss: 0.0250\n",
      "Epoch 98/250\n",
      "520/520 - 65s - loss: 0.0250 - val_loss: 0.0248\n",
      "Epoch 99/250\n",
      "520/520 - 65s - loss: 0.0249 - val_loss: 0.0247\n",
      "Epoch 100/250\n",
      "520/520 - 65s - loss: 0.0248 - val_loss: 0.0245\n",
      "Epoch 101/250\n",
      "520/520 - 64s - loss: 0.0246 - val_loss: 0.0244\n",
      "Epoch 102/250\n",
      "520/520 - 64s - loss: 0.0245 - val_loss: 0.0243\n",
      "Epoch 103/250\n",
      "520/520 - 65s - loss: 0.0244 - val_loss: 0.0242\n",
      "Epoch 104/250\n",
      "520/520 - 65s - loss: 0.0243 - val_loss: 0.0241\n",
      "Epoch 105/250\n",
      "520/520 - 65s - loss: 0.0242 - val_loss: 0.0240\n",
      "Epoch 106/250\n",
      "520/520 - 65s - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 107/250\n",
      "520/520 - 65s - loss: 0.0240 - val_loss: 0.0238\n",
      "Epoch 108/250\n",
      "520/520 - 65s - loss: 0.0239 - val_loss: 0.0237\n",
      "Epoch 109/250\n",
      "520/520 - 65s - loss: 0.0238 - val_loss: 0.0236\n",
      "Epoch 110/250\n",
      "520/520 - 64s - loss: 0.0237 - val_loss: 0.0235\n",
      "Epoch 111/250\n",
      "520/520 - 64s - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 112/250\n",
      "520/520 - 65s - loss: 0.0235 - val_loss: 0.0233\n",
      "Epoch 113/250\n",
      "520/520 - 65s - loss: 0.0234 - val_loss: 0.0232\n",
      "Epoch 114/250\n",
      "520/520 - 65s - loss: 0.0233 - val_loss: 0.0231\n",
      "Epoch 115/250\n",
      "520/520 - 65s - loss: 0.0232 - val_loss: 0.0231\n",
      "Epoch 116/250\n",
      "520/520 - 65s - loss: 0.0232 - val_loss: 0.0230\n",
      "Epoch 117/250\n",
      "520/520 - 65s - loss: 0.0231 - val_loss: 0.0229\n",
      "Epoch 118/250\n",
      "520/520 - 65s - loss: 0.0230 - val_loss: 0.0229\n",
      "Epoch 119/250\n",
      "520/520 - 65s - loss: 0.0229 - val_loss: 0.0227\n",
      "Epoch 120/250\n",
      "520/520 - 65s - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 121/250\n",
      "520/520 - 65s - loss: 0.0228 - val_loss: 0.0225\n",
      "Epoch 122/250\n",
      "520/520 - 65s - loss: 0.0227 - val_loss: 0.0226\n",
      "Epoch 123/250\n",
      "520/520 - 65s - loss: 0.0226 - val_loss: 0.0225\n",
      "Epoch 124/250\n",
      "520/520 - 64s - loss: 0.0225 - val_loss: 0.0224\n",
      "Epoch 125/250\n",
      "520/520 - 64s - loss: 0.0225 - val_loss: 0.0223\n",
      "Epoch 126/250\n",
      "520/520 - 64s - loss: 0.0224 - val_loss: 0.0222\n",
      "Epoch 127/250\n",
      "520/520 - 65s - loss: 0.0223 - val_loss: 0.0222\n",
      "Epoch 128/250\n",
      "520/520 - 66s - loss: 0.0223 - val_loss: 0.0221\n",
      "Epoch 129/250\n",
      "520/520 - 66s - loss: 0.0222 - val_loss: 0.0220\n",
      "Epoch 130/250\n",
      "520/520 - 65s - loss: 0.0221 - val_loss: 0.0220\n",
      "Epoch 131/250\n",
      "520/520 - 65s - loss: 0.0220 - val_loss: 0.0219\n",
      "Epoch 132/250\n",
      "520/520 - 65s - loss: 0.0220 - val_loss: 0.0219\n",
      "Epoch 133/250\n",
      "520/520 - 64s - loss: 0.0219 - val_loss: 0.0218\n",
      "Epoch 134/250\n",
      "520/520 - 65s - loss: 0.0219 - val_loss: 0.0217\n",
      "Epoch 135/250\n",
      "520/520 - 65s - loss: 0.0218 - val_loss: 0.0216\n",
      "Epoch 136/250\n",
      "520/520 - 65s - loss: 0.0217 - val_loss: 0.0216\n",
      "Epoch 137/250\n",
      "520/520 - 65s - loss: 0.0217 - val_loss: 0.0215\n",
      "Epoch 138/250\n",
      "520/520 - 65s - loss: 0.0216 - val_loss: 0.0214\n",
      "Epoch 139/250\n",
      "520/520 - 65s - loss: 0.0216 - val_loss: 0.0214\n",
      "Epoch 140/250\n",
      "520/520 - 64s - loss: 0.0215 - val_loss: 0.0214\n",
      "Epoch 141/250\n",
      "520/520 - 65s - loss: 0.0215 - val_loss: 0.0213\n",
      "Epoch 142/250\n",
      "520/520 - 65s - loss: 0.0214 - val_loss: 0.0212\n",
      "Epoch 143/250\n",
      "520/520 - 65s - loss: 0.0214 - val_loss: 0.0212\n",
      "Epoch 144/250\n",
      "520/520 - 65s - loss: 0.0213 - val_loss: 0.0212\n",
      "Epoch 145/250\n",
      "520/520 - 65s - loss: 0.0212 - val_loss: 0.0212\n",
      "Epoch 146/250\n",
      "520/520 - 65s - loss: 0.0212 - val_loss: 0.0210\n",
      "Epoch 147/250\n",
      "520/520 - 65s - loss: 0.0212 - val_loss: 0.0210\n",
      "Epoch 148/250\n",
      "520/520 - 64s - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 149/250\n",
      "520/520 - 64s - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 150/250\n",
      "520/520 - 65s - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 151/250\n",
      "520/520 - 64s - loss: 0.0209 - val_loss: 0.0209\n",
      "Epoch 152/250\n",
      "520/520 - 65s - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 153/250\n",
      "520/520 - 65s - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 154/250\n",
      "520/520 - 65s - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 155/250\n",
      "520/520 - 64s - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 156/250\n",
      "520/520 - 65s - loss: 0.0207 - val_loss: 0.0206\n",
      "Epoch 157/250\n",
      "520/520 - 65s - loss: 0.0207 - val_loss: 0.0205\n",
      "Epoch 158/250\n",
      "520/520 - 64s - loss: 0.0206 - val_loss: 0.0205\n",
      "Epoch 159/250\n",
      "520/520 - 65s - loss: 0.0206 - val_loss: 0.0204\n",
      "Epoch 160/250\n",
      "520/520 - 65s - loss: 0.0205 - val_loss: 0.0204\n",
      "Epoch 161/250\n",
      "520/520 - 64s - loss: 0.0205 - val_loss: 0.0204\n",
      "Epoch 162/250\n",
      "520/520 - 64s - loss: 0.0205 - val_loss: 0.0203\n",
      "Epoch 163/250\n",
      "520/520 - 64s - loss: 0.0204 - val_loss: 0.0203\n",
      "Epoch 164/250\n",
      "520/520 - 65s - loss: 0.0204 - val_loss: 0.0203\n",
      "Epoch 165/250\n",
      "520/520 - 65s - loss: 0.0203 - val_loss: 0.0202\n",
      "Epoch 166/250\n",
      "520/520 - 65s - loss: 0.0203 - val_loss: 0.0201\n",
      "Epoch 167/250\n",
      "520/520 - 66s - loss: 0.0203 - val_loss: 0.0201\n",
      "Epoch 168/250\n",
      "520/520 - 65s - loss: 0.0202 - val_loss: 0.0201\n",
      "Epoch 169/250\n",
      "520/520 - 65s - loss: 0.0202 - val_loss: 0.0201\n",
      "Epoch 170/250\n",
      "520/520 - 64s - loss: 0.0202 - val_loss: 0.0200\n",
      "Epoch 171/250\n",
      "520/520 - 64s - loss: 0.0201 - val_loss: 0.0200\n",
      "Epoch 172/250\n",
      "520/520 - 65s - loss: 0.0201 - val_loss: 0.0200\n",
      "Epoch 173/250\n",
      "520/520 - 65s - loss: 0.0201 - val_loss: 0.0199\n",
      "Epoch 174/250\n",
      "520/520 - 65s - loss: 0.0200 - val_loss: 0.0198\n",
      "Epoch 175/250\n",
      "520/520 - 64s - loss: 0.0200 - val_loss: 0.0198\n",
      "Epoch 176/250\n",
      "520/520 - 65s - loss: 0.0199 - val_loss: 0.0198\n",
      "Epoch 177/250\n",
      "520/520 - 65s - loss: 0.0199 - val_loss: 0.0198\n",
      "Epoch 178/250\n",
      "520/520 - 65s - loss: 0.0199 - val_loss: 0.0198\n",
      "Epoch 179/250\n",
      "520/520 - 65s - loss: 0.0199 - val_loss: 0.0197\n",
      "Epoch 180/250\n",
      "520/520 - 65s - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 181/250\n",
      "520/520 - 65s - loss: 0.0198 - val_loss: 0.0196\n",
      "Epoch 182/250\n",
      "520/520 - 65s - loss: 0.0198 - val_loss: 0.0196\n",
      "Epoch 183/250\n",
      "520/520 - 65s - loss: 0.0197 - val_loss: 0.0196\n",
      "Epoch 184/250\n",
      "520/520 - 64s - loss: 0.0197 - val_loss: 0.0196\n",
      "Epoch 185/250\n",
      "520/520 - 64s - loss: 0.0197 - val_loss: 0.0196\n",
      "Epoch 186/250\n",
      "520/520 - 64s - loss: 0.0196 - val_loss: 0.0195\n",
      "Epoch 187/250\n",
      "520/520 - 65s - loss: 0.0196 - val_loss: 0.0194\n",
      "Epoch 188/250\n",
      "520/520 - 65s - loss: 0.0196 - val_loss: 0.0195\n",
      "Epoch 189/250\n",
      "520/520 - 63s - loss: 0.0195 - val_loss: 0.0194\n",
      "Epoch 190/250\n",
      "520/520 - 64s - loss: 0.0195 - val_loss: 0.0194\n",
      "Epoch 191/250\n",
      "520/520 - 64s - loss: 0.0195 - val_loss: 0.0194\n",
      "Epoch 192/250\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 0.030000000447034835.\n",
      "520/520 - 64s - loss: 0.0195 - val_loss: 0.0194\n",
      "Epoch 193/250\n",
      "520/520 - 64s - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 194/250\n",
      "520/520 - 64s - loss: 0.0189 - val_loss: 0.0188\n",
      "Epoch 195/250\n",
      "520/520 - 64s - loss: 0.0189 - val_loss: 0.0188\n",
      "Epoch 196/250\n",
      "520/520 - 64s - loss: 0.0189 - val_loss: 0.0188\n",
      "Epoch 197/250\n",
      "520/520 - 64s - loss: 0.0189 - val_loss: 0.0188\n",
      "Epoch 198/250\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 0.009000000357627868.\n",
      "520/520 - 64s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 199/250\n",
      "520/520 - 63s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 200/250\n",
      "520/520 - 64s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 201/250\n",
      "520/520 - 63s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 202/250\n",
      "520/520 - 64s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 203/250\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 0.002700000163167715.\n",
      "520/520 - 64s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 204/250\n",
      "520/520 - 64s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 205/250\n",
      "520/520 - 65s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 206/250\n",
      "520/520 - 64s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 207/250\n",
      "520/520 - 64s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 208/250\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 0.0008100000210106373.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "520/520 - 64s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 00208: early stopping\n",
      "training layer conv4_block4_2_conv\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 520 steps, validate for 104 steps\n",
      "Epoch 1/250\n",
      "520/520 - 68s - loss: 0.1453 - val_loss: 0.1440\n",
      "Epoch 2/250\n",
      "520/520 - 67s - loss: 0.1402 - val_loss: 0.1440\n",
      "Epoch 3/250\n",
      "520/520 - 68s - loss: 0.1403 - val_loss: 0.1438\n",
      "Epoch 4/250\n",
      "520/520 - 67s - loss: 0.1400 - val_loss: 0.1435\n",
      "Epoch 5/250\n",
      "520/520 - 67s - loss: 0.1396 - val_loss: 0.1427\n",
      "Epoch 6/250\n",
      "520/520 - 68s - loss: 0.1381 - val_loss: 0.1399\n",
      "Epoch 7/250\n",
      "520/520 - 68s - loss: 0.1335 - val_loss: 0.1322\n",
      "Epoch 8/250\n",
      "520/520 - 70s - loss: 0.1240 - val_loss: 0.1214\n",
      "Epoch 9/250\n",
      "520/520 - 80s - loss: 0.1140 - val_loss: 0.1110\n",
      "Epoch 10/250\n",
      "520/520 - 81s - loss: 0.1050 - val_loss: 0.1026\n",
      "Epoch 11/250\n",
      "520/520 - 80s - loss: 0.0978 - val_loss: 0.0958\n",
      "Epoch 12/250\n",
      "520/520 - 81s - loss: 0.0916 - val_loss: 0.0897\n",
      "Epoch 13/250\n",
      "520/520 - 82s - loss: 0.0860 - val_loss: 0.0843\n",
      "Epoch 14/250\n",
      "520/520 - 81s - loss: 0.0808 - val_loss: 0.0792\n",
      "Epoch 15/250\n",
      "520/520 - 81s - loss: 0.0762 - val_loss: 0.0748\n",
      "Epoch 16/250\n",
      "520/520 - 82s - loss: 0.0721 - val_loss: 0.0709\n",
      "Epoch 17/250\n",
      "520/520 - 81s - loss: 0.0685 - val_loss: 0.0675\n",
      "Epoch 18/250\n",
      "520/520 - 81s - loss: 0.0653 - val_loss: 0.0644\n",
      "Epoch 19/250\n",
      "520/520 - 81s - loss: 0.0624 - val_loss: 0.0617\n",
      "Epoch 20/250\n",
      "520/520 - 81s - loss: 0.0598 - val_loss: 0.0592\n",
      "Epoch 21/250\n",
      "520/520 - 81s - loss: 0.0575 - val_loss: 0.0569\n",
      "Epoch 22/250\n",
      "520/520 - 82s - loss: 0.0554 - val_loss: 0.0549\n",
      "Epoch 23/250\n",
      "520/520 - 81s - loss: 0.0534 - val_loss: 0.0530\n",
      "Epoch 24/250\n",
      "520/520 - 82s - loss: 0.0516 - val_loss: 0.0512\n",
      "Epoch 25/250\n",
      "520/520 - 81s - loss: 0.0500 - val_loss: 0.0496\n",
      "Epoch 26/250\n",
      "520/520 - 81s - loss: 0.0484 - val_loss: 0.0481\n",
      "Epoch 27/250\n",
      "520/520 - 80s - loss: 0.0470 - val_loss: 0.0467\n",
      "Epoch 28/250\n",
      "520/520 - 81s - loss: 0.0456 - val_loss: 0.0454\n",
      "Epoch 29/250\n",
      "520/520 - 81s - loss: 0.0444 - val_loss: 0.0442\n",
      "Epoch 30/250\n",
      "520/520 - 81s - loss: 0.0432 - val_loss: 0.0430\n",
      "Epoch 31/250\n",
      "520/520 - 81s - loss: 0.0421 - val_loss: 0.0419\n",
      "Epoch 32/250\n",
      "520/520 - 82s - loss: 0.0411 - val_loss: 0.0409\n",
      "Epoch 33/250\n",
      "520/520 - 81s - loss: 0.0401 - val_loss: 0.0400\n",
      "Epoch 34/250\n",
      "520/520 - 81s - loss: 0.0392 - val_loss: 0.0391\n",
      "Epoch 35/250\n",
      "520/520 - 80s - loss: 0.0383 - val_loss: 0.0382\n",
      "Epoch 36/250\n",
      "520/520 - 81s - loss: 0.0375 - val_loss: 0.0374\n",
      "Epoch 37/250\n",
      "520/520 - 81s - loss: 0.0367 - val_loss: 0.0366\n",
      "Epoch 38/250\n",
      "520/520 - 81s - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 39/250\n",
      "520/520 - 82s - loss: 0.0353 - val_loss: 0.0352\n",
      "Epoch 40/250\n",
      "520/520 - 81s - loss: 0.0346 - val_loss: 0.0346\n",
      "Epoch 41/250\n",
      "520/520 - 82s - loss: 0.0340 - val_loss: 0.0339\n",
      "Epoch 42/250\n",
      "520/520 - 81s - loss: 0.0334 - val_loss: 0.0333\n",
      "Epoch 43/250\n",
      "520/520 - 80s - loss: 0.0328 - val_loss: 0.0327\n",
      "Epoch 44/250\n",
      "520/520 - 81s - loss: 0.0322 - val_loss: 0.0322\n",
      "Epoch 45/250\n",
      "520/520 - 81s - loss: 0.0317 - val_loss: 0.0316\n",
      "Epoch 46/250\n",
      "520/520 - 82s - loss: 0.0312 - val_loss: 0.0311\n",
      "Epoch 47/250\n",
      "520/520 - 81s - loss: 0.0307 - val_loss: 0.0306\n",
      "Epoch 48/250\n",
      "520/520 - 81s - loss: 0.0302 - val_loss: 0.0302\n",
      "Epoch 49/250\n",
      "520/520 - 81s - loss: 0.0297 - val_loss: 0.0297\n",
      "Epoch 50/250\n",
      "520/520 - 81s - loss: 0.0293 - val_loss: 0.0293\n",
      "Epoch 51/250\n",
      "520/520 - 81s - loss: 0.0288 - val_loss: 0.0289\n",
      "Epoch 52/250\n",
      "520/520 - 81s - loss: 0.0285 - val_loss: 0.0285\n",
      "Epoch 53/250\n",
      "520/520 - 81s - loss: 0.0281 - val_loss: 0.0281\n",
      "Epoch 54/250\n",
      "520/520 - 82s - loss: 0.0277 - val_loss: 0.0277\n",
      "Epoch 55/250\n",
      "520/520 - 82s - loss: 0.0273 - val_loss: 0.0273\n",
      "Epoch 56/250\n",
      "520/520 - 82s - loss: 0.0270 - val_loss: 0.0270\n",
      "Epoch 57/250\n",
      "520/520 - 81s - loss: 0.0266 - val_loss: 0.0266\n",
      "Epoch 58/250\n",
      "520/520 - 80s - loss: 0.0263 - val_loss: 0.0263\n",
      "Epoch 59/250\n",
      "520/520 - 82s - loss: 0.0260 - val_loss: 0.0260\n",
      "Epoch 60/250\n",
      "520/520 - 81s - loss: 0.0257 - val_loss: 0.0257\n",
      "Epoch 61/250\n",
      "520/520 - 81s - loss: 0.0254 - val_loss: 0.0254\n",
      "Epoch 62/250\n",
      "520/520 - 81s - loss: 0.0251 - val_loss: 0.0251\n",
      "Epoch 63/250\n",
      "520/520 - 81s - loss: 0.0248 - val_loss: 0.0248\n",
      "Epoch 64/250\n",
      "520/520 - 82s - loss: 0.0245 - val_loss: 0.0246\n",
      "Epoch 65/250\n",
      "520/520 - 81s - loss: 0.0243 - val_loss: 0.0243\n",
      "Epoch 66/250\n",
      "520/520 - 80s - loss: 0.0240 - val_loss: 0.0241\n",
      "Epoch 67/250\n",
      "520/520 - 81s - loss: 0.0238 - val_loss: 0.0238\n",
      "Epoch 68/250\n",
      "520/520 - 81s - loss: 0.0235 - val_loss: 0.0236\n",
      "Epoch 69/250\n",
      "520/520 - 82s - loss: 0.0233 - val_loss: 0.0233\n",
      "Epoch 70/250\n",
      "520/520 - 81s - loss: 0.0231 - val_loss: 0.0231\n",
      "Epoch 71/250\n",
      "520/520 - 80s - loss: 0.0229 - val_loss: 0.0229\n",
      "Epoch 72/250\n",
      "520/520 - 83s - loss: 0.0226 - val_loss: 0.0227\n",
      "Epoch 73/250\n",
      "520/520 - 80s - loss: 0.0224 - val_loss: 0.0225\n",
      "Epoch 74/250\n",
      "520/520 - 81s - loss: 0.0222 - val_loss: 0.0223\n",
      "Epoch 75/250\n",
      "520/520 - 82s - loss: 0.0220 - val_loss: 0.0221\n",
      "Epoch 76/250\n",
      "520/520 - 80s - loss: 0.0218 - val_loss: 0.0219\n",
      "Epoch 77/250\n",
      "520/520 - 81s - loss: 0.0217 - val_loss: 0.0217\n",
      "Epoch 78/250\n",
      "520/520 - 81s - loss: 0.0215 - val_loss: 0.0215\n",
      "Epoch 79/250\n",
      "520/520 - 82s - loss: 0.0213 - val_loss: 0.0213\n",
      "Epoch 80/250\n",
      "520/520 - 81s - loss: 0.0211 - val_loss: 0.0212\n",
      "Epoch 81/250\n",
      "520/520 - 80s - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 82/250\n",
      "520/520 - 81s - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 83/250\n",
      "520/520 - 81s - loss: 0.0206 - val_loss: 0.0207\n",
      "Epoch 84/250\n",
      "520/520 - 82s - loss: 0.0205 - val_loss: 0.0206\n",
      "Epoch 85/250\n",
      "520/520 - 82s - loss: 0.0204 - val_loss: 0.0205\n",
      "Epoch 86/250\n",
      "520/520 - 81s - loss: 0.0202 - val_loss: 0.0203\n",
      "Epoch 87/250\n",
      "520/520 - 81s - loss: 0.0201 - val_loss: 0.0202\n",
      "Epoch 88/250\n",
      "520/520 - 80s - loss: 0.0200 - val_loss: 0.0200\n",
      "Epoch 89/250\n",
      "520/520 - 81s - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 90/250\n",
      "520/520 - 81s - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 91/250\n",
      "520/520 - 81s - loss: 0.0196 - val_loss: 0.0196\n",
      "Epoch 92/250\n",
      "520/520 - 81s - loss: 0.0195 - val_loss: 0.0195\n",
      "Epoch 93/250\n",
      "520/520 - 80s - loss: 0.0194 - val_loss: 0.0194\n",
      "Epoch 94/250\n",
      "520/520 - 80s - loss: 0.0192 - val_loss: 0.0193\n",
      "Epoch 95/250\n",
      "520/520 - 81s - loss: 0.0191 - val_loss: 0.0192\n",
      "Epoch 96/250\n",
      "520/520 - 80s - loss: 0.0190 - val_loss: 0.0191\n",
      "Epoch 97/250\n",
      "520/520 - 80s - loss: 0.0189 - val_loss: 0.0190\n",
      "Epoch 98/250\n",
      "520/520 - 81s - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 99/250\n",
      "520/520 - 81s - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 100/250\n",
      "520/520 - 81s - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 101/250\n",
      "520/520 - 81s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 102/250\n",
      "520/520 - 81s - loss: 0.0183 - val_loss: 0.0184\n",
      "Epoch 103/250\n",
      "520/520 - 81s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 104/250\n",
      "520/520 - 80s - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 105/250\n",
      "520/520 - 81s - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 106/250\n",
      "520/520 - 81s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 107/250\n",
      "520/520 - 81s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 108/250\n",
      "520/520 - 81s - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 109/250\n",
      "520/520 - 82s - loss: 0.0177 - val_loss: 0.0178\n",
      "Epoch 110/250\n",
      "520/520 - 81s - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 111/250\n",
      "520/520 - 80s - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 112/250\n",
      "520/520 - 82s - loss: 0.0174 - val_loss: 0.0175\n",
      "Epoch 113/250\n",
      "520/520 - 81s - loss: 0.0174 - val_loss: 0.0174\n",
      "Epoch 114/250\n",
      "520/520 - 81s - loss: 0.0173 - val_loss: 0.0173\n",
      "Epoch 115/250\n",
      "520/520 - 82s - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 116/250\n",
      "520/520 - 81s - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 117/250\n",
      "520/520 - 80s - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 118/250\n",
      "520/520 - 82s - loss: 0.0170 - val_loss: 0.0170\n",
      "Epoch 119/250\n",
      "520/520 - 81s - loss: 0.0169 - val_loss: 0.0169\n",
      "Epoch 120/250\n",
      "520/520 - 80s - loss: 0.0168 - val_loss: 0.0168\n",
      "Epoch 121/250\n",
      "520/520 - 81s - loss: 0.0167 - val_loss: 0.0167\n",
      "Epoch 122/250\n",
      "520/520 - 81s - loss: 0.0166 - val_loss: 0.0167\n",
      "Epoch 123/250\n",
      "520/520 - 80s - loss: 0.0166 - val_loss: 0.0166\n",
      "Epoch 124/250\n",
      "520/520 - 81s - loss: 0.0165 - val_loss: 0.0165\n",
      "Epoch 125/250\n",
      "520/520 - 81s - loss: 0.0164 - val_loss: 0.0165\n",
      "Epoch 126/250\n",
      "520/520 - 80s - loss: 0.0164 - val_loss: 0.0164\n",
      "Epoch 127/250\n",
      "520/520 - 80s - loss: 0.0163 - val_loss: 0.0164\n",
      "Epoch 128/250\n",
      "520/520 - 81s - loss: 0.0162 - val_loss: 0.0162\n",
      "Epoch 129/250\n",
      "520/520 - 81s - loss: 0.0162 - val_loss: 0.0162\n",
      "Epoch 130/250\n",
      "520/520 - 81s - loss: 0.0161 - val_loss: 0.0162\n",
      "Epoch 131/250\n",
      "520/520 - 81s - loss: 0.0160 - val_loss: 0.0161\n",
      "Epoch 132/250\n",
      "520/520 - 82s - loss: 0.0160 - val_loss: 0.0160\n",
      "Epoch 133/250\n",
      "520/520 - 80s - loss: 0.0159 - val_loss: 0.0160\n",
      "Epoch 134/250\n",
      "520/520 - 81s - loss: 0.0158 - val_loss: 0.0159\n",
      "Epoch 135/250\n",
      "520/520 - 81s - loss: 0.0158 - val_loss: 0.0158\n",
      "Epoch 136/250\n",
      "520/520 - 81s - loss: 0.0157 - val_loss: 0.0158\n",
      "Epoch 137/250\n",
      "520/520 - 81s - loss: 0.0157 - val_loss: 0.0157\n",
      "Epoch 138/250\n",
      "520/520 - 82s - loss: 0.0156 - val_loss: 0.0156\n",
      "Epoch 139/250\n",
      "520/520 - 80s - loss: 0.0156 - val_loss: 0.0156\n",
      "Epoch 140/250\n",
      "520/520 - 81s - loss: 0.0155 - val_loss: 0.0155\n",
      "Epoch 141/250\n",
      "520/520 - 82s - loss: 0.0154 - val_loss: 0.0155\n",
      "Epoch 142/250\n",
      "520/520 - 81s - loss: 0.0154 - val_loss: 0.0154\n",
      "Epoch 143/250\n",
      "520/520 - 80s - loss: 0.0153 - val_loss: 0.0153\n",
      "Epoch 144/250\n",
      "520/520 - 81s - loss: 0.0153 - val_loss: 0.0153\n",
      "Epoch 145/250\n",
      "520/520 - 81s - loss: 0.0152 - val_loss: 0.0153\n",
      "Epoch 146/250\n",
      "520/520 - 81s - loss: 0.0152 - val_loss: 0.0152\n",
      "Epoch 147/250\n",
      "520/520 - 81s - loss: 0.0151 - val_loss: 0.0152\n",
      "Epoch 148/250\n",
      "520/520 - 81s - loss: 0.0151 - val_loss: 0.0151\n",
      "Epoch 149/250\n",
      "520/520 - 81s - loss: 0.0150 - val_loss: 0.0151\n",
      "Epoch 150/250\n",
      "520/520 - 81s - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 151/250\n",
      "520/520 - 80s - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 152/250\n",
      "520/520 - 82s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 153/250\n",
      "520/520 - 80s - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 154/250\n",
      "520/520 - 81s - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 155/250\n",
      "520/520 - 82s - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 156/250\n",
      "520/520 - 81s - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 157/250\n",
      "520/520 - 81s - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 158/250\n",
      "520/520 - 81s - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 159/250\n",
      "520/520 - 81s - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 160/250\n",
      "520/520 - 81s - loss: 0.0145 - val_loss: 0.0146\n",
      "Epoch 161/250\n",
      "520/520 - 81s - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 162/250\n",
      "520/520 - 81s - loss: 0.0144 - val_loss: 0.0145\n",
      "Epoch 163/250\n",
      "520/520 - 81s - loss: 0.0144 - val_loss: 0.0145\n",
      "Epoch 164/250\n",
      "520/520 - 82s - loss: 0.0144 - val_loss: 0.0144\n",
      "Epoch 165/250\n",
      "520/520 - 81s - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 166/250\n",
      "520/520 - 80s - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 167/250\n",
      "520/520 - 81s - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 168/250\n",
      "520/520 - 82s - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 169/250\n",
      "520/520 - 81s - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 170/250\n",
      "520/520 - 81s - loss: 0.0141 - val_loss: 0.0142\n",
      "Epoch 171/250\n",
      "520/520 - 81s - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 172/250\n",
      "520/520 - 82s - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 173/250\n",
      "520/520 - 81s - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 174/250\n",
      "520/520 - 80s - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 175/250\n",
      "520/520 - 81s - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 176/250\n",
      "520/520 - 82s - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 177/250\n",
      "520/520 - 81s - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 178/250\n",
      "520/520 - 82s - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 179/250\n",
      "520/520 - 81s - loss: 0.0138 - val_loss: 0.0138\n",
      "Epoch 180/250\n",
      "520/520 - 80s - loss: 0.0138 - val_loss: 0.0138\n",
      "Epoch 181/250\n",
      "520/520 - 81s - loss: 0.0137 - val_loss: 0.0137\n",
      "Epoch 182/250\n",
      "520/520 - 81s - loss: 0.0137 - val_loss: 0.0137\n",
      "Epoch 183/250\n",
      "520/520 - 81s - loss: 0.0137 - val_loss: 0.0137\n",
      "Epoch 184/250\n",
      "520/520 - 81s - loss: 0.0137 - val_loss: 0.0137\n",
      "Epoch 185/250\n",
      "520/520 - 81s - loss: 0.0136 - val_loss: 0.0136\n",
      "Epoch 186/250\n",
      "520/520 - 81s - loss: 0.0136 - val_loss: 0.0136\n",
      "Epoch 187/250\n",
      "520/520 - 81s - loss: 0.0136 - val_loss: 0.0136\n",
      "Epoch 188/250\n",
      "520/520 - 81s - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 189/250\n",
      "520/520 - 80s - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 190/250\n",
      "520/520 - 81s - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 191/250\n",
      "520/520 - 82s - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 192/250\n",
      "520/520 - 82s - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 193/250\n",
      "520/520 - 81s - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 194/250\n",
      "520/520 - 81s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 195/250\n",
      "520/520 - 82s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 196/250\n",
      "520/520 - 81s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 197/250\n",
      "520/520 - 81s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 198/250\n",
      "520/520 - 82s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 199/250\n",
      "520/520 - 81s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 200/250\n",
      "520/520 - 82s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 201/250\n",
      "520/520 - 82s - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 202/250\n",
      "520/520 - 81s - loss: 0.0131 - val_loss: 0.0132\n",
      "Epoch 203/250\n",
      "520/520 - 81s - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 204/250\n",
      "520/520 - 78s - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 205/250\n",
      "520/520 - 80s - loss: 0.0130 - val_loss: 0.0131\n",
      "Epoch 206/250\n",
      "520/520 - 80s - loss: 0.0130 - val_loss: 0.0131\n",
      "Epoch 207/250\n",
      "520/520 - 80s - loss: 0.0130 - val_loss: 0.0130\n",
      "Epoch 208/250\n",
      "520/520 - 79s - loss: 0.0130 - val_loss: 0.0130\n",
      "Epoch 209/250\n",
      "520/520 - 79s - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 210/250\n",
      "520/520 - 80s - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 211/250\n",
      "520/520 - 78s - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 212/250\n",
      "520/520 - 79s - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 213/250\n",
      "520/520 - 80s - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 214/250\n",
      "520/520 - 79s - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 215/250\n",
      "520/520 - 79s - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 216/250\n",
      "520/520 - 80s - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 217/250\n",
      "520/520 - 79s - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 218/250\n",
      "\n",
      "Epoch 00218: ReduceLROnPlateau reducing learning rate to 0.030000000447034835.\n",
      "520/520 - 80s - loss: 0.0127 - val_loss: 0.0128\n",
      "Epoch 219/250\n",
      "520/520 - 80s - loss: 0.0124 - val_loss: 0.0125\n",
      "Epoch 220/250\n",
      "520/520 - 79s - loss: 0.0124 - val_loss: 0.0125\n",
      "Epoch 221/250\n",
      "520/520 - 80s - loss: 0.0124 - val_loss: 0.0125\n",
      "Epoch 222/250\n",
      "520/520 - 79s - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 223/250\n",
      "520/520 - 79s - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 224/250\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 0.009000000357627868.\n",
      "520/520 - 79s - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 225/250\n",
      "520/520 - 80s - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 226/250\n",
      "520/520 - 79s - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 227/250\n",
      "520/520 - 79s - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 228/250\n",
      "520/520 - 80s - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 229/250\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 0.002700000163167715.\n",
      "520/520 - 80s - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 230/250\n",
      "520/520 - 79s - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 231/250\n",
      "520/520 - 80s - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 232/250\n",
      "520/520 - 79s - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 233/250\n",
      "520/520 - 79s - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 234/250\n",
      "\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 0.0008100000210106373.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "520/520 - 80s - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 00234: early stopping\n",
      "training layer conv4_block5_2_conv\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 520 steps, validate for 104 steps\n",
      "Epoch 1/250\n",
      "520/520 - 85s - loss: 0.2674 - val_loss: 0.2639\n",
      "Epoch 2/250\n",
      "520/520 - 82s - loss: 0.2544 - val_loss: 0.2636\n",
      "Epoch 3/250\n",
      "520/520 - 84s - loss: 0.2530 - val_loss: 0.2600\n",
      "Epoch 4/250\n",
      "520/520 - 84s - loss: 0.2470 - val_loss: 0.2506\n",
      "Epoch 5/250\n",
      "520/520 - 83s - loss: 0.2344 - val_loss: 0.2320\n",
      "Epoch 6/250\n",
      "520/520 - 83s - loss: 0.2158 - val_loss: 0.2097\n",
      "Epoch 7/250\n",
      "520/520 - 84s - loss: 0.1944 - val_loss: 0.1883\n",
      "Epoch 8/250\n",
      "520/520 - 83s - loss: 0.1755 - val_loss: 0.1698\n",
      "Epoch 9/250\n",
      "520/520 - 84s - loss: 0.1590 - val_loss: 0.1541\n",
      "Epoch 10/250\n",
      "520/520 - 83s - loss: 0.1450 - val_loss: 0.1409\n",
      "Epoch 11/250\n",
      "520/520 - 84s - loss: 0.1330 - val_loss: 0.1295\n",
      "Epoch 12/250\n",
      "520/520 - 83s - loss: 0.1226 - val_loss: 0.1196\n",
      "Epoch 13/250\n",
      "520/520 - 83s - loss: 0.1135 - val_loss: 0.1110\n",
      "Epoch 14/250\n",
      "520/520 - 83s - loss: 0.1056 - val_loss: 0.1033\n",
      "Epoch 15/250\n",
      "520/520 - 84s - loss: 0.0987 - val_loss: 0.0968\n",
      "Epoch 16/250\n",
      "520/520 - 84s - loss: 0.0927 - val_loss: 0.0911\n",
      "Epoch 17/250\n",
      "520/520 - 83s - loss: 0.0875 - val_loss: 0.0863\n",
      "Epoch 18/250\n",
      "520/520 - 83s - loss: 0.0830 - val_loss: 0.0820\n",
      "Epoch 19/250\n",
      "520/520 - 82s - loss: 0.0791 - val_loss: 0.0783\n",
      "Epoch 20/250\n",
      "520/520 - 84s - loss: 0.0757 - val_loss: 0.0749\n",
      "Epoch 21/250\n",
      "520/520 - 84s - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 22/250\n",
      "520/520 - 83s - loss: 0.0698 - val_loss: 0.0694\n",
      "Epoch 23/250\n",
      "520/520 - 84s - loss: 0.0673 - val_loss: 0.0670\n",
      "Epoch 24/250\n",
      "520/520 - 83s - loss: 0.0651 - val_loss: 0.0648\n",
      "Epoch 25/250\n",
      "520/520 - 84s - loss: 0.0631 - val_loss: 0.0629\n",
      "Epoch 26/250\n",
      "520/520 - 83s - loss: 0.0612 - val_loss: 0.0610\n",
      "Epoch 27/250\n",
      "520/520 - 84s - loss: 0.0594 - val_loss: 0.0594\n",
      "Epoch 28/250\n",
      "520/520 - 84s - loss: 0.0579 - val_loss: 0.0578\n",
      "Epoch 29/250\n",
      "520/520 - 83s - loss: 0.0564 - val_loss: 0.0563\n",
      "Epoch 30/250\n",
      "520/520 - 83s - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 31/250\n",
      "520/520 - 84s - loss: 0.0537 - val_loss: 0.0537\n",
      "Epoch 32/250\n",
      "520/520 - 83s - loss: 0.0525 - val_loss: 0.0525\n",
      "Epoch 33/250\n",
      "520/520 - 83s - loss: 0.0513 - val_loss: 0.0514\n",
      "Epoch 34/250\n",
      "520/520 - 83s - loss: 0.0502 - val_loss: 0.0503\n",
      "Epoch 35/250\n",
      "520/520 - 83s - loss: 0.0492 - val_loss: 0.0493\n",
      "Epoch 36/250\n",
      "520/520 - 84s - loss: 0.0482 - val_loss: 0.0483\n",
      "Epoch 37/250\n",
      "520/520 - 84s - loss: 0.0473 - val_loss: 0.0474\n",
      "Epoch 38/250\n",
      "520/520 - 83s - loss: 0.0464 - val_loss: 0.0465\n",
      "Epoch 39/250\n",
      "520/520 - 83s - loss: 0.0457 - val_loss: 0.0459\n",
      "Epoch 40/250\n",
      "520/520 - 83s - loss: 0.0449 - val_loss: 0.0452\n",
      "Epoch 41/250\n",
      "520/520 - 84s - loss: 0.0442 - val_loss: 0.0443\n",
      "Epoch 42/250\n",
      "520/520 - 83s - loss: 0.0435 - val_loss: 0.0437\n",
      "Epoch 43/250\n",
      "520/520 - 84s - loss: 0.0428 - val_loss: 0.0430\n",
      "Epoch 44/250\n",
      "520/520 - 83s - loss: 0.0421 - val_loss: 0.0423\n",
      "Epoch 45/250\n",
      "520/520 - 83s - loss: 0.0415 - val_loss: 0.0417\n",
      "Epoch 46/250\n",
      "520/520 - 84s - loss: 0.0409 - val_loss: 0.0410\n",
      "Epoch 47/250\n",
      "520/520 - 83s - loss: 0.0403 - val_loss: 0.0407\n",
      "Epoch 48/250\n",
      "520/520 - 84s - loss: 0.0398 - val_loss: 0.0399\n",
      "Epoch 49/250\n",
      "520/520 - 84s - loss: 0.0392 - val_loss: 0.0393\n",
      "Epoch 50/250\n",
      "520/520 - 83s - loss: 0.0387 - val_loss: 0.0389\n",
      "Epoch 51/250\n",
      "520/520 - 83s - loss: 0.0382 - val_loss: 0.0384\n",
      "Epoch 52/250\n",
      "520/520 - 84s - loss: 0.0377 - val_loss: 0.0379\n",
      "Epoch 53/250\n",
      "520/520 - 83s - loss: 0.0373 - val_loss: 0.0375\n",
      "Epoch 54/250\n",
      "520/520 - 84s - loss: 0.0368 - val_loss: 0.0370\n",
      "Epoch 55/250\n",
      "520/520 - 84s - loss: 0.0364 - val_loss: 0.0366\n",
      "Epoch 56/250\n",
      "520/520 - 84s - loss: 0.0360 - val_loss: 0.0362\n",
      "Epoch 57/250\n",
      "520/520 - 83s - loss: 0.0356 - val_loss: 0.0358\n",
      "Epoch 58/250\n",
      "520/520 - 84s - loss: 0.0352 - val_loss: 0.0356\n",
      "Epoch 59/250\n",
      "520/520 - 83s - loss: 0.0349 - val_loss: 0.0352\n",
      "Epoch 60/250\n",
      "520/520 - 83s - loss: 0.0345 - val_loss: 0.0348\n",
      "Epoch 61/250\n",
      "520/520 - 83s - loss: 0.0341 - val_loss: 0.0345\n",
      "Epoch 62/250\n",
      "520/520 - 84s - loss: 0.0338 - val_loss: 0.0340\n",
      "Epoch 63/250\n",
      "520/520 - 83s - loss: 0.0335 - val_loss: 0.0338\n",
      "Epoch 64/250\n",
      "520/520 - 84s - loss: 0.0332 - val_loss: 0.0334\n",
      "Epoch 65/250\n",
      "520/520 - 83s - loss: 0.0329 - val_loss: 0.0333\n",
      "Epoch 66/250\n",
      "520/520 - 84s - loss: 0.0326 - val_loss: 0.0329\n",
      "Epoch 67/250\n",
      "520/520 - 83s - loss: 0.0324 - val_loss: 0.0328\n",
      "Epoch 68/250\n",
      "520/520 - 84s - loss: 0.0321 - val_loss: 0.0322\n",
      "Epoch 69/250\n",
      "520/520 - 83s - loss: 0.0318 - val_loss: 0.0319\n",
      "Epoch 70/250\n",
      "520/520 - 84s - loss: 0.0316 - val_loss: 0.0318\n",
      "Epoch 71/250\n",
      "520/520 - 84s - loss: 0.0313 - val_loss: 0.0314\n",
      "Epoch 72/250\n",
      "520/520 - 83s - loss: 0.0311 - val_loss: 0.0314\n",
      "Epoch 73/250\n",
      "520/520 - 83s - loss: 0.0308 - val_loss: 0.0310\n",
      "Epoch 74/250\n",
      "520/520 - 84s - loss: 0.0306 - val_loss: 0.0308\n",
      "Epoch 75/250\n",
      "520/520 - 83s - loss: 0.0304 - val_loss: 0.0306\n",
      "Epoch 76/250\n",
      "520/520 - 84s - loss: 0.0302 - val_loss: 0.0304\n",
      "Epoch 77/250\n",
      "520/520 - 84s - loss: 0.0300 - val_loss: 0.0302\n",
      "Epoch 78/250\n",
      "520/520 - 83s - loss: 0.0298 - val_loss: 0.0301\n",
      "Epoch 79/250\n",
      "520/520 - 84s - loss: 0.0296 - val_loss: 0.0297\n",
      "Epoch 80/250\n",
      "520/520 - 84s - loss: 0.0294 - val_loss: 0.0296\n",
      "Epoch 81/250\n",
      "520/520 - 84s - loss: 0.0292 - val_loss: 0.0294\n",
      "Epoch 82/250\n",
      "520/520 - 83s - loss: 0.0290 - val_loss: 0.0295\n",
      "Epoch 83/250\n",
      "520/520 - 83s - loss: 0.0289 - val_loss: 0.0290\n",
      "Epoch 84/250\n",
      "520/520 - 83s - loss: 0.0287 - val_loss: 0.0289\n",
      "Epoch 85/250\n",
      "520/520 - 91s - loss: 0.0285 - val_loss: 0.0289\n",
      "Epoch 86/250\n",
      "520/520 - 94s - loss: 0.0284 - val_loss: 0.0285\n",
      "Epoch 87/250\n",
      "520/520 - 94s - loss: 0.0282 - val_loss: 0.0285\n",
      "Epoch 88/250\n",
      "520/520 - 94s - loss: 0.0281 - val_loss: 0.0284\n",
      "Epoch 89/250\n",
      "520/520 - 93s - loss: 0.0279 - val_loss: 0.0282\n",
      "Epoch 90/250\n",
      "520/520 - 94s - loss: 0.0277 - val_loss: 0.0281\n",
      "Epoch 91/250\n",
      "520/520 - 93s - loss: 0.0276 - val_loss: 0.0279\n",
      "Epoch 92/250\n",
      "520/520 - 93s - loss: 0.0275 - val_loss: 0.0278\n",
      "Epoch 93/250\n",
      "520/520 - 94s - loss: 0.0273 - val_loss: 0.0276\n",
      "Epoch 94/250\n",
      "520/520 - 93s - loss: 0.0272 - val_loss: 0.0274\n",
      "Epoch 95/250\n",
      "520/520 - 94s - loss: 0.0270 - val_loss: 0.0272\n",
      "Epoch 96/250\n",
      "520/520 - 94s - loss: 0.0269 - val_loss: 0.0272\n",
      "Epoch 97/250\n",
      "520/520 - 95s - loss: 0.0268 - val_loss: 0.0269\n",
      "Epoch 98/250\n",
      "520/520 - 92s - loss: 0.0267 - val_loss: 0.0270\n",
      "Epoch 99/250\n",
      "520/520 - 94s - loss: 0.0266 - val_loss: 0.0270\n",
      "Epoch 100/250\n",
      "520/520 - 93s - loss: 0.0264 - val_loss: 0.0267\n",
      "Epoch 101/250\n",
      "520/520 - 93s - loss: 0.0263 - val_loss: 0.0264\n",
      "Epoch 102/250\n",
      "520/520 - 95s - loss: 0.0263 - val_loss: 0.0264\n",
      "Epoch 103/250\n",
      "520/520 - 94s - loss: 0.0261 - val_loss: 0.0263\n",
      "Epoch 104/250\n",
      "520/520 - 94s - loss: 0.0260 - val_loss: 0.0263\n",
      "Epoch 105/250\n",
      "520/520 - 93s - loss: 0.0259 - val_loss: 0.0262\n",
      "Epoch 106/250\n",
      "520/520 - 94s - loss: 0.0258 - val_loss: 0.0261\n",
      "Epoch 107/250\n",
      "520/520 - 92s - loss: 0.0257 - val_loss: 0.0258\n",
      "Epoch 108/250\n",
      "520/520 - 94s - loss: 0.0256 - val_loss: 0.0257\n",
      "Epoch 109/250\n",
      "520/520 - 94s - loss: 0.0254 - val_loss: 0.0257\n",
      "Epoch 110/250\n",
      "520/520 - 94s - loss: 0.0253 - val_loss: 0.0256\n",
      "Epoch 111/250\n",
      "520/520 - 93s - loss: 0.0253 - val_loss: 0.0254\n",
      "Epoch 112/250\n",
      "520/520 - 94s - loss: 0.0251 - val_loss: 0.0253\n",
      "Epoch 113/250\n",
      "520/520 - 93s - loss: 0.0251 - val_loss: 0.0251\n",
      "Epoch 114/250\n",
      "520/520 - 94s - loss: 0.0250 - val_loss: 0.0251\n",
      "Epoch 115/250\n",
      "520/520 - 93s - loss: 0.0249 - val_loss: 0.0251\n",
      "Epoch 116/250\n",
      "520/520 - 94s - loss: 0.0248 - val_loss: 0.0249\n",
      "Epoch 117/250\n",
      "520/520 - 94s - loss: 0.0247 - val_loss: 0.0248\n",
      "Epoch 118/250\n",
      "520/520 - 94s - loss: 0.0246 - val_loss: 0.0247\n",
      "Epoch 119/250\n",
      "520/520 - 94s - loss: 0.0245 - val_loss: 0.0247\n",
      "Epoch 120/250\n",
      "520/520 - 93s - loss: 0.0244 - val_loss: 0.0247\n",
      "Epoch 121/250\n",
      "520/520 - 94s - loss: 0.0243 - val_loss: 0.0245\n",
      "Epoch 122/250\n",
      "520/520 - 93s - loss: 0.0243 - val_loss: 0.0245\n",
      "Epoch 123/250\n",
      "520/520 - 94s - loss: 0.0242 - val_loss: 0.0244\n",
      "Epoch 124/250\n",
      "520/520 - 95s - loss: 0.0241 - val_loss: 0.0243\n",
      "Epoch 125/250\n",
      "520/520 - 94s - loss: 0.0240 - val_loss: 0.0242\n",
      "Epoch 126/250\n",
      "520/520 - 94s - loss: 0.0240 - val_loss: 0.0244\n",
      "Epoch 127/250\n",
      "520/520 - 94s - loss: 0.0239 - val_loss: 0.0241\n",
      "Epoch 128/250\n",
      "520/520 - 94s - loss: 0.0238 - val_loss: 0.0241\n",
      "Epoch 129/250\n",
      "520/520 - 93s - loss: 0.0237 - val_loss: 0.0240\n",
      "Epoch 130/250\n",
      "520/520 - 93s - loss: 0.0236 - val_loss: 0.0240\n",
      "Epoch 131/250\n",
      "520/520 - 94s - loss: 0.0236 - val_loss: 0.0238\n",
      "Epoch 132/250\n",
      "520/520 - 94s - loss: 0.0235 - val_loss: 0.0238\n",
      "Epoch 133/250\n",
      "520/520 - 93s - loss: 0.0235 - val_loss: 0.0236\n",
      "Epoch 134/250\n",
      "520/520 - 95s - loss: 0.0234 - val_loss: 0.0237\n",
      "Epoch 135/250\n",
      "520/520 - 93s - loss: 0.0233 - val_loss: 0.0235\n",
      "Epoch 136/250\n",
      "520/520 - 94s - loss: 0.0233 - val_loss: 0.0235\n",
      "Epoch 137/250\n",
      "520/520 - 94s - loss: 0.0232 - val_loss: 0.0234\n",
      "Epoch 138/250\n",
      "520/520 - 92s - loss: 0.0231 - val_loss: 0.0233\n",
      "Epoch 139/250\n",
      "520/520 - 93s - loss: 0.0231 - val_loss: 0.0233\n",
      "Epoch 140/250\n",
      "520/520 - 94s - loss: 0.0230 - val_loss: 0.0232\n",
      "Epoch 141/250\n",
      "520/520 - 94s - loss: 0.0230 - val_loss: 0.0233\n",
      "Epoch 142/250\n",
      "520/520 - 93s - loss: 0.0229 - val_loss: 0.0231\n",
      "Epoch 143/250\n",
      "520/520 - 95s - loss: 0.0228 - val_loss: 0.0230\n",
      "Epoch 144/250\n",
      "520/520 - 92s - loss: 0.0228 - val_loss: 0.0230\n",
      "Epoch 145/250\n",
      "520/520 - 94s - loss: 0.0227 - val_loss: 0.0229\n",
      "Epoch 146/250\n",
      "520/520 - 93s - loss: 0.0227 - val_loss: 0.0228\n",
      "Epoch 147/250\n",
      "520/520 - 94s - loss: 0.0226 - val_loss: 0.0229\n",
      "Epoch 148/250\n",
      "520/520 - 90s - loss: 0.0226 - val_loss: 0.0228\n",
      "Epoch 149/250\n",
      "520/520 - 92s - loss: 0.0225 - val_loss: 0.0228\n",
      "Epoch 150/250\n",
      "520/520 - 92s - loss: 0.0225 - val_loss: 0.0227\n",
      "Epoch 151/250\n",
      "520/520 - 91s - loss: 0.0224 - val_loss: 0.0227\n",
      "Epoch 152/250\n",
      "520/520 - 93s - loss: 0.0224 - val_loss: 0.0228\n",
      "Epoch 153/250\n",
      "520/520 - 90s - loss: 0.0223 - val_loss: 0.0226\n",
      "Epoch 154/250\n",
      "520/520 - 92s - loss: 0.0223 - val_loss: 0.0224\n",
      "Epoch 155/250\n",
      "520/520 - 91s - loss: 0.0222 - val_loss: 0.0225\n",
      "Epoch 156/250\n",
      "520/520 - 91s - loss: 0.0222 - val_loss: 0.0224\n",
      "Epoch 157/250\n",
      "520/520 - 91s - loss: 0.0221 - val_loss: 0.0224\n",
      "Epoch 158/250\n",
      "520/520 - 91s - loss: 0.0221 - val_loss: 0.0223\n",
      "Epoch 159/250\n",
      "520/520 - 92s - loss: 0.0220 - val_loss: 0.0221\n",
      "Epoch 160/250\n",
      "520/520 - 92s - loss: 0.0220 - val_loss: 0.0221\n",
      "Epoch 161/250\n",
      "520/520 - 90s - loss: 0.0219 - val_loss: 0.0221\n",
      "Epoch 162/250\n",
      "520/520 - 92s - loss: 0.0219 - val_loss: 0.0222\n",
      "Epoch 163/250\n",
      "520/520 - 91s - loss: 0.0218 - val_loss: 0.0222\n",
      "Epoch 164/250\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 0.030000000447034835.\n",
      "520/520 - 90s - loss: 0.0218 - val_loss: 0.0220\n",
      "Epoch 165/250\n",
      "520/520 - 92s - loss: 0.0213 - val_loss: 0.0215\n",
      "Epoch 166/250\n",
      "520/520 - 91s - loss: 0.0212 - val_loss: 0.0215\n",
      "Epoch 167/250\n",
      "520/520 - 90s - loss: 0.0212 - val_loss: 0.0215\n",
      "Epoch 168/250\n",
      "520/520 - 92s - loss: 0.0212 - val_loss: 0.0214\n",
      "Epoch 169/250\n",
      "520/520 - 90s - loss: 0.0212 - val_loss: 0.0214\n",
      "Epoch 170/250\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 0.009000000357627868.\n",
      "520/520 - 92s - loss: 0.0212 - val_loss: 0.0214\n",
      "Epoch 171/250\n",
      "520/520 - 92s - loss: 0.0212 - val_loss: 0.0214\n",
      "Epoch 172/250\n",
      "520/520 - 91s - loss: 0.0211 - val_loss: 0.0214\n",
      "Epoch 173/250\n",
      "520/520 - 92s - loss: 0.0212 - val_loss: 0.0214\n",
      "Epoch 174/250\n",
      "520/520 - 91s - loss: 0.0211 - val_loss: 0.0214\n",
      "Epoch 175/250\n",
      "520/520 - 92s - loss: 0.0212 - val_loss: 0.0214\n",
      "Epoch 176/250\n",
      "520/520 - 92s - loss: 0.0211 - val_loss: 0.0214\n",
      "Epoch 177/250\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 0.002700000163167715.\n",
      "520/520 - 89s - loss: 0.0211 - val_loss: 0.0214\n",
      "Epoch 178/250\n",
      "520/520 - 91s - loss: 0.0211 - val_loss: 0.0214\n",
      "Epoch 179/250\n",
      "520/520 - 92s - loss: 0.0211 - val_loss: 0.0214\n",
      "Epoch 180/250\n",
      "520/520 - 90s - loss: 0.0211 - val_loss: 0.0213\n",
      "Epoch 181/250\n",
      "520/520 - 92s - loss: 0.0211 - val_loss: 0.0214\n",
      "Epoch 182/250\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 0.0008100000210106373.\n",
      "520/520 - 90s - loss: 0.0211 - val_loss: 0.0214\n",
      "Epoch 183/250\n",
      "520/520 - 91s - loss: 0.0211 - val_loss: 0.0213\n",
      "Epoch 184/250\n",
      "520/520 - 92s - loss: 0.0211 - val_loss: 0.0213\n",
      "Epoch 185/250\n",
      "520/520 - 90s - loss: 0.0211 - val_loss: 0.0214\n",
      "Epoch 186/250\n",
      "520/520 - 91s - loss: 0.0211 - val_loss: 0.0213\n",
      "Epoch 187/250\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 0.00024299999931827186.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "520/520 - 92s - loss: 0.0211 - val_loss: 0.0213\n",
      "Epoch 00187: early stopping\n",
      "training layer conv4_block6_2_conv\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 520 steps, validate for 104 steps\n",
      "Epoch 1/250\n",
      "520/520 - 97s - loss: 0.3642 - val_loss: 0.2957\n",
      "Epoch 2/250\n",
      "520/520 - 96s - loss: 0.2767 - val_loss: 0.2781\n",
      "Epoch 3/250\n",
      "520/520 - 95s - loss: 0.2621 - val_loss: 0.2579\n",
      "Epoch 4/250\n",
      "520/520 - 96s - loss: 0.2413 - val_loss: 0.2345\n",
      "Epoch 5/250\n",
      "520/520 - 96s - loss: 0.2183 - val_loss: 0.2104\n",
      "Epoch 6/250\n",
      "520/520 - 92s - loss: 0.1952 - val_loss: 0.1855\n",
      "Epoch 7/250\n",
      "520/520 - 95s - loss: 0.1705 - val_loss: 0.1611\n",
      "Epoch 8/250\n",
      "520/520 - 95s - loss: 0.1488 - val_loss: 0.1413\n",
      "Epoch 9/250\n",
      "520/520 - 94s - loss: 0.1316 - val_loss: 0.1257\n",
      "Epoch 10/250\n",
      "520/520 - 95s - loss: 0.1178 - val_loss: 0.1130\n",
      "Epoch 11/250\n",
      "520/520 - 94s - loss: 0.1064 - val_loss: 0.1027\n",
      "Epoch 12/250\n",
      "520/520 - 94s - loss: 0.0972 - val_loss: 0.0942\n",
      "Epoch 13/250\n",
      "520/520 - 94s - loss: 0.0896 - val_loss: 0.0872\n",
      "Epoch 14/250\n",
      "520/520 - 96s - loss: 0.0832 - val_loss: 0.0813\n",
      "Epoch 15/250\n",
      "520/520 - 94s - loss: 0.0779 - val_loss: 0.0764\n",
      "Epoch 16/250\n",
      "520/520 - 95s - loss: 0.0734 - val_loss: 0.0722\n",
      "Epoch 17/250\n",
      "520/520 - 95s - loss: 0.0695 - val_loss: 0.0685\n",
      "Epoch 18/250\n",
      "520/520 - 94s - loss: 0.0662 - val_loss: 0.0654\n",
      "Epoch 19/250\n",
      "520/520 - 95s - loss: 0.0633 - val_loss: 0.0626\n",
      "Epoch 20/250\n",
      "520/520 - 94s - loss: 0.0606 - val_loss: 0.0601\n",
      "Epoch 21/250\n",
      "520/520 - 94s - loss: 0.0583 - val_loss: 0.0578\n",
      "Epoch 22/250\n",
      "520/520 - 94s - loss: 0.0562 - val_loss: 0.0559\n",
      "Epoch 23/250\n",
      "520/520 - 95s - loss: 0.0543 - val_loss: 0.0540\n",
      "Epoch 24/250\n",
      "520/520 - 95s - loss: 0.0525 - val_loss: 0.0523\n",
      "Epoch 25/250\n",
      "520/520 - 95s - loss: 0.0509 - val_loss: 0.0507\n",
      "Epoch 26/250\n",
      "520/520 - 95s - loss: 0.0493 - val_loss: 0.0490\n",
      "Epoch 27/250\n",
      "520/520 - 95s - loss: 0.0478 - val_loss: 0.0477\n",
      "Epoch 28/250\n",
      "520/520 - 94s - loss: 0.0464 - val_loss: 0.0464\n",
      "Epoch 29/250\n",
      "520/520 - 94s - loss: 0.0450 - val_loss: 0.0449\n",
      "Epoch 30/250\n",
      "520/520 - 94s - loss: 0.0437 - val_loss: 0.0436\n",
      "Epoch 31/250\n",
      "520/520 - 93s - loss: 0.0425 - val_loss: 0.0424\n",
      "Epoch 32/250\n",
      "520/520 - 95s - loss: 0.0414 - val_loss: 0.0415\n",
      "Epoch 33/250\n",
      "520/520 - 94s - loss: 0.0403 - val_loss: 0.0403\n",
      "Epoch 34/250\n",
      "520/520 - 95s - loss: 0.0393 - val_loss: 0.0394\n",
      "Epoch 35/250\n",
      "520/520 - 93s - loss: 0.0384 - val_loss: 0.0384\n",
      "Epoch 36/250\n",
      "520/520 - 95s - loss: 0.0375 - val_loss: 0.0376\n",
      "Epoch 37/250\n",
      "520/520 - 94s - loss: 0.0366 - val_loss: 0.0366\n",
      "Epoch 38/250\n",
      "520/520 - 94s - loss: 0.0359 - val_loss: 0.0360\n",
      "Epoch 39/250\n",
      "520/520 - 94s - loss: 0.0352 - val_loss: 0.0353\n",
      "Epoch 40/250\n",
      "520/520 - 94s - loss: 0.0345 - val_loss: 0.0346\n",
      "Epoch 41/250\n",
      "520/520 - 90s - loss: 0.0339 - val_loss: 0.0340\n",
      "Epoch 42/250\n",
      "520/520 - 95s - loss: 0.0333 - val_loss: 0.0336\n",
      "Epoch 43/250\n",
      "520/520 - 92s - loss: 0.0327 - val_loss: 0.0329\n",
      "Epoch 44/250\n",
      "520/520 - 93s - loss: 0.0321 - val_loss: 0.0323\n",
      "Epoch 45/250\n",
      "520/520 - 93s - loss: 0.0316 - val_loss: 0.0317\n",
      "Epoch 46/250\n",
      "520/520 - 92s - loss: 0.0310 - val_loss: 0.0312\n",
      "Epoch 47/250\n",
      "520/520 - 93s - loss: 0.0306 - val_loss: 0.0307\n",
      "Epoch 48/250\n",
      "520/520 - 93s - loss: 0.0301 - val_loss: 0.0302\n",
      "Epoch 49/250\n",
      "520/520 - 92s - loss: 0.0296 - val_loss: 0.0298\n",
      "Epoch 50/250\n",
      "520/520 - 93s - loss: 0.0292 - val_loss: 0.0294\n",
      "Epoch 51/250\n",
      "520/520 - 94s - loss: 0.0287 - val_loss: 0.0288\n",
      "Epoch 52/250\n",
      "520/520 - 93s - loss: 0.0284 - val_loss: 0.0286\n",
      "Epoch 53/250\n",
      "520/520 - 93s - loss: 0.0280 - val_loss: 0.0283\n",
      "Epoch 54/250\n",
      "520/520 - 93s - loss: 0.0276 - val_loss: 0.0278\n",
      "Epoch 55/250\n",
      "520/520 - 94s - loss: 0.0273 - val_loss: 0.0276\n",
      "Epoch 56/250\n",
      "520/520 - 93s - loss: 0.0270 - val_loss: 0.0273\n",
      "Epoch 57/250\n",
      "520/520 - 93s - loss: 0.0267 - val_loss: 0.0272\n",
      "Epoch 58/250\n",
      "520/520 - 93s - loss: 0.0264 - val_loss: 0.0265\n",
      "Epoch 59/250\n",
      "520/520 - 93s - loss: 0.0261 - val_loss: 0.0266\n",
      "Epoch 60/250\n",
      "520/520 - 94s - loss: 0.0259 - val_loss: 0.0260\n",
      "Epoch 61/250\n",
      "520/520 - 93s - loss: 0.0256 - val_loss: 0.0259\n",
      "Epoch 62/250\n",
      "520/520 - 93s - loss: 0.0254 - val_loss: 0.0255\n",
      "Epoch 63/250\n",
      "520/520 - 92s - loss: 0.0251 - val_loss: 0.0254\n",
      "Epoch 64/250\n",
      "520/520 - 93s - loss: 0.0249 - val_loss: 0.0252\n",
      "Epoch 65/250\n",
      "520/520 - 93s - loss: 0.0247 - val_loss: 0.0249\n",
      "Epoch 66/250\n",
      "520/520 - 94s - loss: 0.0246 - val_loss: 0.0247\n",
      "Epoch 67/250\n",
      "520/520 - 93s - loss: 0.0244 - val_loss: 0.0245\n",
      "Epoch 68/250\n",
      "520/520 - 92s - loss: 0.0242 - val_loss: 0.0243\n",
      "Epoch 69/250\n",
      "520/520 - 94s - loss: 0.0240 - val_loss: 0.0245\n",
      "Epoch 70/250\n",
      "520/520 - 93s - loss: 0.0238 - val_loss: 0.0241\n",
      "Epoch 71/250\n",
      "520/520 - 93s - loss: 0.0237 - val_loss: 0.0238\n",
      "Epoch 72/250\n",
      "520/520 - 94s - loss: 0.0235 - val_loss: 0.0237\n",
      "Epoch 73/250\n",
      "520/520 - 93s - loss: 0.0233 - val_loss: 0.0233\n",
      "Epoch 74/250\n",
      "520/520 - 92s - loss: 0.0232 - val_loss: 0.0233\n",
      "Epoch 75/250\n",
      "520/520 - 94s - loss: 0.0230 - val_loss: 0.0233\n",
      "Epoch 76/250\n",
      "520/520 - 93s - loss: 0.0229 - val_loss: 0.0232\n",
      "Epoch 77/250\n",
      "520/520 - 92s - loss: 0.0228 - val_loss: 0.0229\n",
      "Epoch 78/250\n",
      "520/520 - 94s - loss: 0.0226 - val_loss: 0.0229\n",
      "Epoch 79/250\n",
      "520/520 - 93s - loss: 0.0225 - val_loss: 0.0226\n",
      "Epoch 80/250\n",
      "520/520 - 92s - loss: 0.0224 - val_loss: 0.0225\n",
      "Epoch 81/250\n",
      "520/520 - 94s - loss: 0.0223 - val_loss: 0.0224\n",
      "Epoch 82/250\n",
      "520/520 - 93s - loss: 0.0222 - val_loss: 0.0223\n",
      "Epoch 83/250\n",
      "520/520 - 92s - loss: 0.0220 - val_loss: 0.0222\n",
      "Epoch 84/250\n",
      "520/520 - 94s - loss: 0.0219 - val_loss: 0.0221\n",
      "Epoch 85/250\n",
      "520/520 - 92s - loss: 0.0218 - val_loss: 0.0220\n",
      "Epoch 86/250\n",
      "520/520 - 92s - loss: 0.0217 - val_loss: 0.0220\n",
      "Epoch 87/250\n",
      "520/520 - 93s - loss: 0.0216 - val_loss: 0.0219\n",
      "Epoch 88/250\n",
      "520/520 - 92s - loss: 0.0215 - val_loss: 0.0216\n",
      "Epoch 89/250\n",
      "520/520 - 93s - loss: 0.0214 - val_loss: 0.0219\n",
      "Epoch 90/250\n",
      "520/520 - 94s - loss: 0.0213 - val_loss: 0.0218\n",
      "Epoch 91/250\n",
      "520/520 - 92s - loss: 0.0213 - val_loss: 0.0216\n",
      "Epoch 92/250\n",
      "520/520 - 93s - loss: 0.0211 - val_loss: 0.0215\n",
      "Epoch 93/250\n",
      "520/520 - 94s - loss: 0.0211 - val_loss: 0.0212\n",
      "Epoch 94/250\n",
      "520/520 - 92s - loss: 0.0210 - val_loss: 0.0214\n",
      "Epoch 95/250\n",
      "520/520 - 93s - loss: 0.0209 - val_loss: 0.0210\n",
      "Epoch 96/250\n",
      "520/520 - 93s - loss: 0.0208 - val_loss: 0.0212\n",
      "Epoch 97/250\n",
      "520/520 - 92s - loss: 0.0207 - val_loss: 0.0209\n",
      "Epoch 98/250\n",
      "520/520 - 93s - loss: 0.0206 - val_loss: 0.0208\n",
      "Epoch 99/250\n",
      "520/520 - 94s - loss: 0.0205 - val_loss: 0.0208\n",
      "Epoch 100/250\n",
      "520/520 - 89s - loss: 0.0205 - val_loss: 0.0208\n",
      "Epoch 101/250\n",
      "520/520 - 91s - loss: 0.0204 - val_loss: 0.0208\n",
      "Epoch 102/250\n",
      "520/520 - 92s - loss: 0.0203 - val_loss: 0.0208\n",
      "Epoch 103/250\n",
      "520/520 - 92s - loss: 0.0203 - val_loss: 0.0205\n",
      "Epoch 104/250\n",
      "520/520 - 91s - loss: 0.0202 - val_loss: 0.0205\n",
      "Epoch 105/250\n",
      "520/520 - 92s - loss: 0.0202 - val_loss: 0.0202\n",
      "Epoch 106/250\n",
      "520/520 - 92s - loss: 0.0201 - val_loss: 0.0203\n",
      "Epoch 107/250\n",
      "520/520 - 92s - loss: 0.0200 - val_loss: 0.0201\n",
      "Epoch 108/250\n",
      "520/520 - 92s - loss: 0.0200 - val_loss: 0.0201\n",
      "Epoch 109/250\n",
      "520/520 - 92s - loss: 0.0199 - val_loss: 0.0201\n",
      "Epoch 110/250\n",
      "520/520 - 92s - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 111/250\n",
      "520/520 - 93s - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 112/250\n",
      "520/520 - 91s - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 113/250\n",
      "520/520 - 92s - loss: 0.0196 - val_loss: 0.0199\n",
      "Epoch 114/250\n",
      "520/520 - 92s - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 115/250\n",
      "520/520 - 91s - loss: 0.0195 - val_loss: 0.0198\n",
      "Epoch 116/250\n",
      "520/520 - 92s - loss: 0.0195 - val_loss: 0.0198\n",
      "Epoch 117/250\n",
      "520/520 - 93s - loss: 0.0194 - val_loss: 0.0196\n",
      "Epoch 118/250\n",
      "520/520 - 91s - loss: 0.0194 - val_loss: 0.0195\n",
      "Epoch 119/250\n",
      "520/520 - 91s - loss: 0.0193 - val_loss: 0.0197\n",
      "Epoch 120/250\n",
      "520/520 - 92s - loss: 0.0192 - val_loss: 0.0194\n",
      "Epoch 121/250\n",
      "520/520 - 92s - loss: 0.0192 - val_loss: 0.0197\n",
      "Epoch 122/250\n",
      "520/520 - 91s - loss: 0.0191 - val_loss: 0.0195\n",
      "Epoch 123/250\n",
      "520/520 - 91s - loss: 0.0191 - val_loss: 0.0192\n",
      "Epoch 124/250\n",
      "520/520 - 90s - loss: 0.0190 - val_loss: 0.0193\n",
      "Epoch 125/250\n",
      "520/520 - 92s - loss: 0.0190 - val_loss: 0.0190\n",
      "Epoch 126/250\n",
      "520/520 - 92s - loss: 0.0189 - val_loss: 0.0191\n",
      "Epoch 127/250\n",
      "520/520 - 91s - loss: 0.0188 - val_loss: 0.0191\n",
      "Epoch 128/250\n",
      "520/520 - 92s - loss: 0.0188 - val_loss: 0.0193\n",
      "Epoch 129/250\n",
      "520/520 - 93s - loss: 0.0188 - val_loss: 0.0191\n",
      "Epoch 130/250\n",
      "520/520 - 92s - loss: 0.0187 - val_loss: 0.0188\n",
      "Epoch 131/250\n",
      "520/520 - 92s - loss: 0.0186 - val_loss: 0.0189\n",
      "Epoch 132/250\n",
      "520/520 - 92s - loss: 0.0186 - val_loss: 0.0189\n",
      "Epoch 133/250\n",
      "520/520 - 91s - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 134/250\n",
      "520/520 - 91s - loss: 0.0185 - val_loss: 0.0186\n",
      "Epoch 135/250\n",
      "520/520 - 93s - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 136/250\n",
      "520/520 - 92s - loss: 0.0184 - val_loss: 0.0186\n",
      "Epoch 137/250\n",
      "520/520 - 92s - loss: 0.0183 - val_loss: 0.0186\n",
      "Epoch 138/250\n",
      "520/520 - 91s - loss: 0.0183 - val_loss: 0.0185\n",
      "Epoch 139/250\n",
      "520/520 - 92s - loss: 0.0183 - val_loss: 0.0186\n",
      "Epoch 140/250\n",
      "520/520 - 91s - loss: 0.0182 - val_loss: 0.0184\n",
      "Epoch 141/250\n",
      "520/520 - 92s - loss: 0.0182 - val_loss: 0.0184\n",
      "Epoch 142/250\n",
      "520/520 - 91s - loss: 0.0182 - val_loss: 0.0183\n",
      "Epoch 143/250\n",
      "520/520 - 91s - loss: 0.0181 - val_loss: 0.0182\n",
      "Epoch 144/250\n",
      "520/520 - 92s - loss: 0.0181 - val_loss: 0.0182\n",
      "Epoch 145/250\n",
      "520/520 - 92s - loss: 0.0181 - val_loss: 0.0183\n",
      "Epoch 146/250\n",
      "520/520 - 91s - loss: 0.0180 - val_loss: 0.0183\n",
      "Epoch 147/250\n",
      "520/520 - 93s - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 148/250\n",
      "520/520 - 92s - loss: 0.0179 - val_loss: 0.0181\n",
      "Epoch 149/250\n",
      "520/520 - 91s - loss: 0.0179 - val_loss: 0.0180\n",
      "Epoch 150/250\n",
      "520/520 - 93s - loss: 0.0179 - val_loss: 0.0181\n",
      "Epoch 151/250\n",
      "520/520 - 92s - loss: 0.0179 - val_loss: 0.0180\n",
      "Epoch 152/250\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 0.030000000447034835.\n",
      "520/520 - 91s - loss: 0.0178 - val_loss: 0.0182\n",
      "Epoch 153/250\n",
      "520/520 - 91s - loss: 0.0173 - val_loss: 0.0175\n",
      "Epoch 154/250\n",
      "520/520 - 91s - loss: 0.0173 - val_loss: 0.0175\n",
      "Epoch 155/250\n",
      "520/520 - 92s - loss: 0.0173 - val_loss: 0.0175\n",
      "Epoch 156/250\n",
      "520/520 - 92s - loss: 0.0173 - val_loss: 0.0175\n",
      "Epoch 157/250\n",
      "520/520 - 91s - loss: 0.0173 - val_loss: 0.0175\n",
      "Epoch 158/250\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 0.009000000357627868.\n",
      "520/520 - 92s - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 159/250\n",
      "520/520 - 93s - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 160/250\n",
      "520/520 - 92s - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 161/250\n",
      "520/520 - 91s - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 162/250\n",
      "520/520 - 92s - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 163/250\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 0.002700000163167715.\n",
      "520/520 - 92s - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 164/250\n",
      "520/520 - 91s - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 165/250\n",
      "520/520 - 92s - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 166/250\n",
      "520/520 - 92s - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 167/250\n",
      "520/520 - 92s - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 168/250\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 0.0008100000210106373.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "520/520 - 91s - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 00168: early stopping\n",
      "training layer conv5_block1_2_conv\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 520 steps, validate for 104 steps\n",
      "Epoch 1/250\n",
      "520/520 - 92s - loss: 0.1299 - val_loss: 0.1225\n",
      "Epoch 2/250\n",
      "520/520 - 89s - loss: 0.1239 - val_loss: 0.1221\n",
      "Epoch 3/250\n",
      "520/520 - 93s - loss: 0.1238 - val_loss: 0.1221\n",
      "Epoch 4/250\n",
      "520/520 - 94s - loss: 0.1239 - val_loss: 0.1222\n",
      "Epoch 5/250\n",
      "520/520 - 92s - loss: 0.1239 - val_loss: 0.1221\n",
      "Epoch 6/250\n",
      "520/520 - 93s - loss: 0.1238 - val_loss: 0.1221\n",
      "Epoch 7/250\n",
      "520/520 - 93s - loss: 0.1237 - val_loss: 0.1219\n",
      "Epoch 8/250\n",
      "520/520 - 93s - loss: 0.1234 - val_loss: 0.1215\n",
      "Epoch 9/250\n",
      "520/520 - 93s - loss: 0.1226 - val_loss: 0.1202\n",
      "Epoch 10/250\n",
      "520/520 - 92s - loss: 0.1212 - val_loss: 0.1186\n",
      "Epoch 11/250\n",
      "520/520 - 93s - loss: 0.1195 - val_loss: 0.1169\n",
      "Epoch 12/250\n",
      "520/520 - 93s - loss: 0.1177 - val_loss: 0.1150\n",
      "Epoch 13/250\n",
      "520/520 - 93s - loss: 0.1162 - val_loss: 0.1136\n",
      "Epoch 14/250\n",
      "520/520 - 93s - loss: 0.1150 - val_loss: 0.1126\n",
      "Epoch 15/250\n",
      "520/520 - 93s - loss: 0.1140 - val_loss: 0.1117\n",
      "Epoch 16/250\n",
      "520/520 - 93s - loss: 0.1130 - val_loss: 0.1106\n",
      "Epoch 17/250\n",
      "520/520 - 94s - loss: 0.1118 - val_loss: 0.1091\n",
      "Epoch 18/250\n",
      "520/520 - 93s - loss: 0.1101 - val_loss: 0.1070\n",
      "Epoch 19/250\n",
      "520/520 - 91s - loss: 0.1077 - val_loss: 0.1042\n",
      "Epoch 20/250\n",
      "520/520 - 94s - loss: 0.1048 - val_loss: 0.1012\n",
      "Epoch 21/250\n",
      "520/520 - 94s - loss: 0.1017 - val_loss: 0.0981\n",
      "Epoch 22/250\n",
      "520/520 - 92s - loss: 0.0987 - val_loss: 0.0950\n",
      "Epoch 23/250\n",
      "520/520 - 94s - loss: 0.0957 - val_loss: 0.0921\n",
      "Epoch 24/250\n",
      "520/520 - 93s - loss: 0.0928 - val_loss: 0.0893\n",
      "Epoch 25/250\n",
      "520/520 - 93s - loss: 0.0900 - val_loss: 0.0867\n",
      "Epoch 26/250\n",
      "520/520 - 93s - loss: 0.0874 - val_loss: 0.0843\n",
      "Epoch 27/250\n",
      "520/520 - 92s - loss: 0.0850 - val_loss: 0.0820\n",
      "Epoch 28/250\n",
      "520/520 - 93s - loss: 0.0827 - val_loss: 0.0798\n",
      "Epoch 29/250\n",
      "520/520 - 93s - loss: 0.0805 - val_loss: 0.0777\n",
      "Epoch 30/250\n",
      "520/520 - 92s - loss: 0.0783 - val_loss: 0.0756\n",
      "Epoch 31/250\n",
      "520/520 - 93s - loss: 0.0763 - val_loss: 0.0736\n",
      "Epoch 32/250\n",
      "520/520 - 93s - loss: 0.0743 - val_loss: 0.0717\n",
      "Epoch 33/250\n",
      "520/520 - 92s - loss: 0.0724 - val_loss: 0.0698\n",
      "Epoch 34/250\n",
      "520/520 - 93s - loss: 0.0706 - val_loss: 0.0681\n",
      "Epoch 35/250\n",
      "520/520 - 91s - loss: 0.0687 - val_loss: 0.0664\n",
      "Epoch 36/250\n",
      "520/520 - 94s - loss: 0.0671 - val_loss: 0.0647\n",
      "Epoch 37/250\n",
      "520/520 - 94s - loss: 0.0654 - val_loss: 0.0631\n",
      "Epoch 38/250\n",
      "520/520 - 92s - loss: 0.0638 - val_loss: 0.0616\n",
      "Epoch 39/250\n",
      "520/520 - 93s - loss: 0.0623 - val_loss: 0.0602\n",
      "Epoch 40/250\n",
      "520/520 - 93s - loss: 0.0609 - val_loss: 0.0588\n",
      "Epoch 41/250\n",
      "520/520 - 93s - loss: 0.0596 - val_loss: 0.0575\n",
      "Epoch 42/250\n",
      "520/520 - 93s - loss: 0.0583 - val_loss: 0.0563\n",
      "Epoch 43/250\n",
      "520/520 - 92s - loss: 0.0570 - val_loss: 0.0551\n",
      "Epoch 44/250\n",
      "520/520 - 93s - loss: 0.0559 - val_loss: 0.0540\n",
      "Epoch 45/250\n",
      "520/520 - 93s - loss: 0.0548 - val_loss: 0.0530\n",
      "Epoch 46/250\n",
      "520/520 - 93s - loss: 0.0538 - val_loss: 0.0520\n",
      "Epoch 47/250\n",
      "520/520 - 93s - loss: 0.0528 - val_loss: 0.0511\n",
      "Epoch 48/250\n",
      "520/520 - 92s - loss: 0.0519 - val_loss: 0.0502\n",
      "Epoch 49/250\n",
      "520/520 - 93s - loss: 0.0510 - val_loss: 0.0494\n",
      "Epoch 50/250\n",
      "520/520 - 93s - loss: 0.0501 - val_loss: 0.0486\n",
      "Epoch 51/250\n",
      "520/520 - 92s - loss: 0.0493 - val_loss: 0.0478\n",
      "Epoch 52/250\n",
      "520/520 - 93s - loss: 0.0486 - val_loss: 0.0470\n",
      "Epoch 53/250\n",
      "520/520 - 93s - loss: 0.0478 - val_loss: 0.0463\n",
      "Epoch 54/250\n",
      "520/520 - 92s - loss: 0.0471 - val_loss: 0.0457\n",
      "Epoch 55/250\n",
      "520/520 - 94s - loss: 0.0465 - val_loss: 0.0450\n",
      "Epoch 56/250\n",
      "520/520 - 93s - loss: 0.0458 - val_loss: 0.0444\n",
      "Epoch 57/250\n",
      "520/520 - 93s - loss: 0.0452 - val_loss: 0.0438\n",
      "Epoch 58/250\n",
      "520/520 - 94s - loss: 0.0446 - val_loss: 0.0433\n",
      "Epoch 59/250\n",
      "520/520 - 92s - loss: 0.0440 - val_loss: 0.0427\n",
      "Epoch 60/250\n",
      "520/520 - 93s - loss: 0.0435 - val_loss: 0.0422\n",
      "Epoch 61/250\n",
      "520/520 - 94s - loss: 0.0429 - val_loss: 0.0416\n",
      "Epoch 62/250\n",
      "520/520 - 92s - loss: 0.0424 - val_loss: 0.0412\n",
      "Epoch 63/250\n",
      "520/520 - 91s - loss: 0.0419 - val_loss: 0.0407\n",
      "Epoch 64/250\n",
      "520/520 - 92s - loss: 0.0414 - val_loss: 0.0402\n",
      "Epoch 65/250\n",
      "520/520 - 92s - loss: 0.0410 - val_loss: 0.0398\n",
      "Epoch 66/250\n",
      "520/520 - 93s - loss: 0.0405 - val_loss: 0.0393\n",
      "Epoch 67/250\n",
      "520/520 - 92s - loss: 0.0401 - val_loss: 0.0389\n",
      "Epoch 68/250\n",
      "520/520 - 92s - loss: 0.0396 - val_loss: 0.0385\n",
      "Epoch 69/250\n",
      "520/520 - 92s - loss: 0.0392 - val_loss: 0.0381\n",
      "Epoch 70/250\n",
      "520/520 - 91s - loss: 0.0388 - val_loss: 0.0377\n",
      "Epoch 71/250\n",
      "520/520 - 92s - loss: 0.0384 - val_loss: 0.0373\n",
      "Epoch 72/250\n",
      "520/520 - 92s - loss: 0.0380 - val_loss: 0.0369\n",
      "Epoch 73/250\n",
      "520/520 - 89s - loss: 0.0377 - val_loss: 0.0366\n",
      "Epoch 74/250\n",
      "520/520 - 91s - loss: 0.0373 - val_loss: 0.0362\n",
      "Epoch 75/250\n",
      "520/520 - 91s - loss: 0.0369 - val_loss: 0.0359\n",
      "Epoch 76/250\n",
      "520/520 - 90s - loss: 0.0366 - val_loss: 0.0355\n",
      "Epoch 77/250\n",
      "520/520 - 89s - loss: 0.0363 - val_loss: 0.0352\n",
      "Epoch 78/250\n",
      "520/520 - 92s - loss: 0.0359 - val_loss: 0.0349\n",
      "Epoch 79/250\n",
      "520/520 - 91s - loss: 0.0356 - val_loss: 0.0346\n",
      "Epoch 80/250\n",
      "520/520 - 90s - loss: 0.0353 - val_loss: 0.0343\n",
      "Epoch 81/250\n",
      "520/520 - 91s - loss: 0.0350 - val_loss: 0.0340\n",
      "Epoch 82/250\n",
      "520/520 - 91s - loss: 0.0347 - val_loss: 0.0337\n",
      "Epoch 83/250\n",
      "520/520 - 91s - loss: 0.0344 - val_loss: 0.0334\n",
      "Epoch 84/250\n",
      "520/520 - 91s - loss: 0.0341 - val_loss: 0.0331\n",
      "Epoch 85/250\n",
      "520/520 - 91s - loss: 0.0338 - val_loss: 0.0328\n",
      "Epoch 86/250\n",
      "520/520 - 91s - loss: 0.0335 - val_loss: 0.0326\n",
      "Epoch 87/250\n",
      "520/520 - 91s - loss: 0.0333 - val_loss: 0.0323\n",
      "Epoch 88/250\n",
      "520/520 - 91s - loss: 0.0330 - val_loss: 0.0320\n",
      "Epoch 89/250\n",
      "520/520 - 90s - loss: 0.0327 - val_loss: 0.0318\n",
      "Epoch 90/250\n",
      "520/520 - 91s - loss: 0.0325 - val_loss: 0.0315\n",
      "Epoch 91/250\n",
      "520/520 - 90s - loss: 0.0322 - val_loss: 0.0313\n",
      "Epoch 92/250\n",
      "520/520 - 89s - loss: 0.0320 - val_loss: 0.0311\n",
      "Epoch 93/250\n",
      "520/520 - 90s - loss: 0.0317 - val_loss: 0.0308\n",
      "Epoch 94/250\n",
      "520/520 - 90s - loss: 0.0315 - val_loss: 0.0306\n",
      "Epoch 95/250\n",
      "520/520 - 91s - loss: 0.0313 - val_loss: 0.0304\n",
      "Epoch 96/250\n",
      "520/520 - 90s - loss: 0.0310 - val_loss: 0.0301\n",
      "Epoch 97/250\n",
      "520/520 - 90s - loss: 0.0308 - val_loss: 0.0299\n",
      "Epoch 98/250\n",
      "520/520 - 90s - loss: 0.0306 - val_loss: 0.0297\n",
      "Epoch 99/250\n",
      "520/520 - 92s - loss: 0.0303 - val_loss: 0.0295\n",
      "Epoch 100/250\n",
      "520/520 - 89s - loss: 0.0301 - val_loss: 0.0293\n",
      "Epoch 101/250\n",
      "520/520 - 90s - loss: 0.0299 - val_loss: 0.0291\n",
      "Epoch 102/250\n",
      "520/520 - 91s - loss: 0.0297 - val_loss: 0.0289\n",
      "Epoch 103/250\n",
      "520/520 - 90s - loss: 0.0295 - val_loss: 0.0287\n",
      "Epoch 104/250\n",
      "520/520 - 89s - loss: 0.0293 - val_loss: 0.0285\n",
      "Epoch 105/250\n",
      "520/520 - 91s - loss: 0.0291 - val_loss: 0.0283\n",
      "Epoch 106/250\n",
      "520/520 - 91s - loss: 0.0289 - val_loss: 0.0281\n",
      "Epoch 107/250\n",
      "520/520 - 91s - loss: 0.0287 - val_loss: 0.0279\n",
      "Epoch 108/250\n",
      "520/520 - 90s - loss: 0.0285 - val_loss: 0.0277\n",
      "Epoch 109/250\n",
      "520/520 - 91s - loss: 0.0283 - val_loss: 0.0276\n",
      "Epoch 110/250\n",
      "520/520 - 90s - loss: 0.0282 - val_loss: 0.0274\n",
      "Epoch 111/250\n",
      "520/520 - 91s - loss: 0.0280 - val_loss: 0.0272\n",
      "Epoch 112/250\n",
      "520/520 - 89s - loss: 0.0278 - val_loss: 0.0270\n",
      "Epoch 113/250\n",
      "520/520 - 90s - loss: 0.0276 - val_loss: 0.0269\n",
      "Epoch 114/250\n",
      "520/520 - 91s - loss: 0.0275 - val_loss: 0.0267\n",
      "Epoch 115/250\n",
      "520/520 - 90s - loss: 0.0273 - val_loss: 0.0265\n",
      "Epoch 116/250\n",
      "520/520 - 89s - loss: 0.0271 - val_loss: 0.0264\n",
      "Epoch 117/250\n",
      "520/520 - 92s - loss: 0.0270 - val_loss: 0.0262\n",
      "Epoch 118/250\n",
      "520/520 - 91s - loss: 0.0268 - val_loss: 0.0261\n",
      "Epoch 119/250\n",
      "520/520 - 90s - loss: 0.0267 - val_loss: 0.0259\n",
      "Epoch 120/250\n",
      "520/520 - 90s - loss: 0.0265 - val_loss: 0.0258\n",
      "Epoch 121/250\n",
      "520/520 - 90s - loss: 0.0264 - val_loss: 0.0256\n",
      "Epoch 122/250\n",
      "520/520 - 90s - loss: 0.0262 - val_loss: 0.0255\n",
      "Epoch 123/250\n",
      "520/520 - 90s - loss: 0.0261 - val_loss: 0.0253\n",
      "Epoch 124/250\n",
      "520/520 - 91s - loss: 0.0259 - val_loss: 0.0252\n",
      "Epoch 125/250\n",
      "520/520 - 91s - loss: 0.0258 - val_loss: 0.0250\n",
      "Epoch 126/250\n",
      "520/520 - 91s - loss: 0.0256 - val_loss: 0.0249\n",
      "Epoch 127/250\n",
      "520/520 - 90s - loss: 0.0255 - val_loss: 0.0248\n",
      "Epoch 128/250\n",
      "520/520 - 91s - loss: 0.0253 - val_loss: 0.0246\n",
      "Epoch 129/250\n",
      "520/520 - 90s - loss: 0.0252 - val_loss: 0.0245\n",
      "Epoch 130/250\n",
      "520/520 - 91s - loss: 0.0251 - val_loss: 0.0244\n",
      "Epoch 131/250\n",
      "520/520 - 90s - loss: 0.0250 - val_loss: 0.0243\n",
      "Epoch 132/250\n",
      "520/520 - 90s - loss: 0.0248 - val_loss: 0.0241\n",
      "Epoch 133/250\n",
      "520/520 - 90s - loss: 0.0247 - val_loss: 0.0240\n",
      "Epoch 134/250\n",
      "520/520 - 92s - loss: 0.0246 - val_loss: 0.0239\n",
      "Epoch 135/250\n",
      "520/520 - 90s - loss: 0.0244 - val_loss: 0.0238\n",
      "Epoch 136/250\n",
      "520/520 - 90s - loss: 0.0243 - val_loss: 0.0236\n",
      "Epoch 137/250\n",
      "520/520 - 91s - loss: 0.0242 - val_loss: 0.0235\n",
      "Epoch 138/250\n",
      "520/520 - 91s - loss: 0.0241 - val_loss: 0.0234\n",
      "Epoch 139/250\n",
      "520/520 - 89s - loss: 0.0240 - val_loss: 0.0233\n",
      "Epoch 140/250\n",
      "520/520 - 91s - loss: 0.0239 - val_loss: 0.0232\n",
      "Epoch 141/250\n",
      "520/520 - 90s - loss: 0.0238 - val_loss: 0.0231\n",
      "Epoch 142/250\n",
      "520/520 - 91s - loss: 0.0236 - val_loss: 0.0230\n",
      "Epoch 143/250\n",
      "520/520 - 90s - loss: 0.0235 - val_loss: 0.0229\n",
      "Epoch 144/250\n",
      "520/520 - 90s - loss: 0.0234 - val_loss: 0.0228\n",
      "Epoch 145/250\n",
      "520/520 - 90s - loss: 0.0233 - val_loss: 0.0227\n",
      "Epoch 146/250\n",
      "520/520 - 91s - loss: 0.0232 - val_loss: 0.0226\n",
      "Epoch 147/250\n",
      "520/520 - 89s - loss: 0.0231 - val_loss: 0.0225\n",
      "Epoch 148/250\n",
      "520/520 - 91s - loss: 0.0230 - val_loss: 0.0224\n",
      "Epoch 149/250\n",
      "520/520 - 91s - loss: 0.0229 - val_loss: 0.0223\n",
      "Epoch 150/250\n",
      "520/520 - 90s - loss: 0.0228 - val_loss: 0.0222\n",
      "Epoch 151/250\n",
      "520/520 - 90s - loss: 0.0227 - val_loss: 0.0221\n",
      "Epoch 152/250\n",
      "520/520 - 91s - loss: 0.0226 - val_loss: 0.0220\n",
      "Epoch 153/250\n",
      "520/520 - 90s - loss: 0.0226 - val_loss: 0.0219\n",
      "Epoch 154/250\n",
      "520/520 - 90s - loss: 0.0225 - val_loss: 0.0219\n",
      "Epoch 155/250\n",
      "520/520 - 87s - loss: 0.0224 - val_loss: 0.0217\n",
      "Epoch 156/250\n",
      "520/520 - 89s - loss: 0.0223 - val_loss: 0.0217\n",
      "Epoch 157/250\n",
      "520/520 - 90s - loss: 0.0222 - val_loss: 0.0216\n",
      "Epoch 158/250\n",
      "520/520 - 90s - loss: 0.0221 - val_loss: 0.0215\n",
      "Epoch 159/250\n",
      "520/520 - 89s - loss: 0.0220 - val_loss: 0.0214\n",
      "Epoch 160/250\n",
      "520/520 - 89s - loss: 0.0219 - val_loss: 0.0214\n",
      "Epoch 161/250\n",
      "520/520 - 89s - loss: 0.0219 - val_loss: 0.0213\n",
      "Epoch 162/250\n",
      "520/520 - 89s - loss: 0.0218 - val_loss: 0.0212\n",
      "Epoch 163/250\n",
      "520/520 - 89s - loss: 0.0217 - val_loss: 0.0211\n",
      "Epoch 164/250\n",
      "520/520 - 90s - loss: 0.0216 - val_loss: 0.0210\n",
      "Epoch 165/250\n",
      "520/520 - 89s - loss: 0.0215 - val_loss: 0.0210\n",
      "Epoch 166/250\n",
      "520/520 - 90s - loss: 0.0215 - val_loss: 0.0209\n",
      "Epoch 167/250\n",
      "520/520 - 89s - loss: 0.0214 - val_loss: 0.0208\n",
      "Epoch 168/250\n",
      "520/520 - 89s - loss: 0.0213 - val_loss: 0.0208\n",
      "Epoch 169/250\n",
      "520/520 - 89s - loss: 0.0212 - val_loss: 0.0207\n",
      "Epoch 170/250\n",
      "520/520 - 89s - loss: 0.0212 - val_loss: 0.0205\n",
      "Epoch 171/250\n",
      "520/520 - 90s - loss: 0.0211 - val_loss: 0.0206\n",
      "Epoch 172/250\n",
      "520/520 - 89s - loss: 0.0210 - val_loss: 0.0204\n",
      "Epoch 173/250\n",
      "520/520 - 89s - loss: 0.0209 - val_loss: 0.0203\n",
      "Epoch 174/250\n",
      "520/520 - 89s - loss: 0.0209 - val_loss: 0.0203\n",
      "Epoch 175/250\n",
      "520/520 - 89s - loss: 0.0208 - val_loss: 0.0202\n",
      "Epoch 176/250\n",
      "520/520 - 90s - loss: 0.0207 - val_loss: 0.0202\n",
      "Epoch 177/250\n",
      "520/520 - 90s - loss: 0.0206 - val_loss: 0.0201\n",
      "Epoch 178/250\n",
      "520/520 - 88s - loss: 0.0206 - val_loss: 0.0200\n",
      "Epoch 179/250\n",
      "520/520 - 90s - loss: 0.0205 - val_loss: 0.0199\n",
      "Epoch 180/250\n",
      "520/520 - 89s - loss: 0.0204 - val_loss: 0.0198\n",
      "Epoch 181/250\n",
      "520/520 - 89s - loss: 0.0204 - val_loss: 0.0198\n",
      "Epoch 182/250\n",
      "520/520 - 90s - loss: 0.0203 - val_loss: 0.0197\n",
      "Epoch 183/250\n",
      "520/520 - 89s - loss: 0.0202 - val_loss: 0.0197\n",
      "Epoch 184/250\n",
      "520/520 - 88s - loss: 0.0202 - val_loss: 0.0196\n",
      "Epoch 185/250\n",
      "520/520 - 90s - loss: 0.0201 - val_loss: 0.0196\n",
      "Epoch 186/250\n",
      "520/520 - 89s - loss: 0.0200 - val_loss: 0.0195\n",
      "Epoch 187/250\n",
      "520/520 - 90s - loss: 0.0200 - val_loss: 0.0195\n",
      "Epoch 188/250\n",
      "520/520 - 90s - loss: 0.0199 - val_loss: 0.0194\n",
      "Epoch 189/250\n",
      "520/520 - 89s - loss: 0.0198 - val_loss: 0.0194\n",
      "Epoch 190/250\n",
      "520/520 - 89s - loss: 0.0198 - val_loss: 0.0192\n",
      "Epoch 191/250\n",
      "520/520 - 89s - loss: 0.0197 - val_loss: 0.0192\n",
      "Epoch 192/250\n",
      "520/520 - 89s - loss: 0.0197 - val_loss: 0.0191\n",
      "Epoch 193/250\n",
      "520/520 - 89s - loss: 0.0196 - val_loss: 0.0191\n",
      "Epoch 194/250\n",
      "520/520 - 90s - loss: 0.0195 - val_loss: 0.0190\n",
      "Epoch 195/250\n",
      "520/520 - 88s - loss: 0.0195 - val_loss: 0.0189\n",
      "Epoch 196/250\n",
      "520/520 - 89s - loss: 0.0194 - val_loss: 0.0189\n",
      "Epoch 197/250\n",
      "520/520 - 89s - loss: 0.0194 - val_loss: 0.0188\n",
      "Epoch 198/250\n",
      "520/520 - 89s - loss: 0.0193 - val_loss: 0.0188\n",
      "Epoch 199/250\n",
      "520/520 - 89s - loss: 0.0192 - val_loss: 0.0188\n",
      "Epoch 200/250\n",
      "520/520 - 89s - loss: 0.0192 - val_loss: 0.0187\n",
      "Epoch 201/250\n",
      "520/520 - 90s - loss: 0.0191 - val_loss: 0.0186\n",
      "Epoch 202/250\n",
      "520/520 - 89s - loss: 0.0191 - val_loss: 0.0185\n",
      "Epoch 203/250\n",
      "520/520 - 89s - loss: 0.0190 - val_loss: 0.0185\n",
      "Epoch 204/250\n",
      "520/520 - 90s - loss: 0.0190 - val_loss: 0.0185\n",
      "Epoch 205/250\n",
      "520/520 - 89s - loss: 0.0189 - val_loss: 0.0184\n",
      "Epoch 206/250\n",
      "520/520 - 89s - loss: 0.0188 - val_loss: 0.0183\n",
      "Epoch 207/250\n",
      "520/520 - 90s - loss: 0.0188 - val_loss: 0.0183\n",
      "Epoch 208/250\n",
      "520/520 - 89s - loss: 0.0187 - val_loss: 0.0183\n",
      "Epoch 209/250\n",
      "520/520 - 90s - loss: 0.0187 - val_loss: 0.0182\n",
      "Epoch 210/250\n",
      "520/520 - 90s - loss: 0.0186 - val_loss: 0.0181\n",
      "Epoch 211/250\n",
      "520/520 - 89s - loss: 0.0186 - val_loss: 0.0181\n",
      "Epoch 212/250\n",
      "520/520 - 89s - loss: 0.0185 - val_loss: 0.0180\n",
      "Epoch 213/250\n",
      "520/520 - 90s - loss: 0.0185 - val_loss: 0.0180\n",
      "Epoch 214/250\n",
      "520/520 - 89s - loss: 0.0184 - val_loss: 0.0180\n",
      "Epoch 215/250\n",
      "520/520 - 89s - loss: 0.0184 - val_loss: 0.0179\n",
      "Epoch 216/250\n",
      "520/520 - 89s - loss: 0.0183 - val_loss: 0.0179\n",
      "Epoch 217/250\n",
      "520/520 - 88s - loss: 0.0183 - val_loss: 0.0177\n",
      "Epoch 218/250\n",
      "520/520 - 89s - loss: 0.0182 - val_loss: 0.0178\n",
      "Epoch 219/250\n",
      "520/520 - 89s - loss: 0.0182 - val_loss: 0.0177\n",
      "Epoch 220/250\n",
      "520/520 - 89s - loss: 0.0181 - val_loss: 0.0177\n",
      "Epoch 221/250\n",
      "520/520 - 89s - loss: 0.0181 - val_loss: 0.0176\n",
      "Epoch 222/250\n",
      "520/520 - 90s - loss: 0.0180 - val_loss: 0.0175\n",
      "Epoch 223/250\n",
      "520/520 - 88s - loss: 0.0180 - val_loss: 0.0175\n",
      "Epoch 224/250\n",
      "520/520 - 89s - loss: 0.0179 - val_loss: 0.0175\n",
      "Epoch 225/250\n",
      "520/520 - 90s - loss: 0.0179 - val_loss: 0.0174\n",
      "Epoch 226/250\n",
      "520/520 - 90s - loss: 0.0178 - val_loss: 0.0174\n",
      "Epoch 227/250\n",
      "520/520 - 89s - loss: 0.0178 - val_loss: 0.0174\n",
      "Epoch 228/250\n",
      "520/520 - 90s - loss: 0.0177 - val_loss: 0.0174\n",
      "Epoch 229/250\n",
      "520/520 - 88s - loss: 0.0177 - val_loss: 0.0173\n",
      "Epoch 230/250\n",
      "520/520 - 89s - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 231/250\n",
      "520/520 - 89s - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 232/250\n",
      "520/520 - 90s - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 233/250\n",
      "520/520 - 89s - loss: 0.0175 - val_loss: 0.0171\n",
      "Epoch 234/250\n",
      "520/520 - 89s - loss: 0.0175 - val_loss: 0.0170\n",
      "Epoch 235/250\n",
      "520/520 - 89s - loss: 0.0175 - val_loss: 0.0170\n",
      "Epoch 236/250\n",
      "520/520 - 89s - loss: 0.0174 - val_loss: 0.0170\n",
      "Epoch 237/250\n",
      "520/520 - 90s - loss: 0.0173 - val_loss: 0.0169\n",
      "Epoch 238/250\n",
      "520/520 - 89s - loss: 0.0173 - val_loss: 0.0169\n",
      "Epoch 239/250\n",
      "520/520 - 89s - loss: 0.0173 - val_loss: 0.0169\n",
      "Epoch 240/250\n",
      "520/520 - 89s - loss: 0.0172 - val_loss: 0.0168\n",
      "Epoch 241/250\n",
      "520/520 - 89s - loss: 0.0172 - val_loss: 0.0167\n",
      "Epoch 242/250\n",
      "520/520 - 90s - loss: 0.0171 - val_loss: 0.0168\n",
      "Epoch 243/250\n",
      "520/520 - 90s - loss: 0.0171 - val_loss: 0.0167\n",
      "Epoch 244/250\n",
      "520/520 - 89s - loss: 0.0171 - val_loss: 0.0167\n",
      "Epoch 245/250\n",
      "520/520 - 89s - loss: 0.0170 - val_loss: 0.0166\n",
      "Epoch 246/250\n",
      "520/520 - 88s - loss: 0.0170 - val_loss: 0.0166\n",
      "Epoch 247/250\n",
      "520/520 - 87s - loss: 0.0169 - val_loss: 0.0165\n",
      "Epoch 248/250\n",
      "520/520 - 87s - loss: 0.0169 - val_loss: 0.0165\n",
      "Epoch 249/250\n",
      "520/520 - 89s - loss: 0.0169 - val_loss: 0.0164\n",
      "Epoch 250/250\n",
      "520/520 - 88s - loss: 0.0168 - val_loss: 0.0164\n",
      "training layer conv5_block2_2_conv\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 520 steps, validate for 104 steps\n",
      "Epoch 1/250\n",
      "520/520 - 94s - loss: 0.0654 - val_loss: 0.0627\n",
      "Epoch 2/250\n",
      "520/520 - 94s - loss: 0.0628 - val_loss: 0.0625\n",
      "Epoch 3/250\n",
      "520/520 - 93s - loss: 0.0627 - val_loss: 0.0625\n",
      "Epoch 4/250\n",
      "520/520 - 94s - loss: 0.0627 - val_loss: 0.0626\n",
      "Epoch 5/250\n",
      "520/520 - 94s - loss: 0.0627 - val_loss: 0.0625\n",
      "Epoch 6/250\n",
      "520/520 - 92s - loss: 0.0627 - val_loss: 0.0625\n",
      "Epoch 7/250\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.030000000447034835.\n",
      "520/520 - 95s - loss: 0.0627 - val_loss: 0.0625\n",
      "Epoch 8/250\n",
      "520/520 - 94s - loss: 0.0627 - val_loss: 0.0625\n",
      "Epoch 9/250\n",
      "520/520 - 93s - loss: 0.0627 - val_loss: 0.0625\n",
      "Epoch 10/250\n",
      "520/520 - 95s - loss: 0.0627 - val_loss: 0.0625\n",
      "Epoch 11/250\n",
      "520/520 - 94s - loss: 0.0626 - val_loss: 0.0625\n",
      "Epoch 12/250\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.009000000357627868.\n",
      "520/520 - 93s - loss: 0.0627 - val_loss: 0.0625\n",
      "Epoch 13/250\n",
      "520/520 - 94s - loss: 0.0627 - val_loss: 0.0625\n",
      "Epoch 14/250\n",
      "520/520 - 92s - loss: 0.0627 - val_loss: 0.0625\n",
      "Epoch 15/250\n",
      "520/520 - 93s - loss: 0.0627 - val_loss: 0.0625\n",
      "Epoch 16/250\n",
      "520/520 - 94s - loss: 0.0627 - val_loss: 0.0625\n",
      "Epoch 17/250\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.002700000163167715.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "520/520 - 95s - loss: 0.0627 - val_loss: 0.0625\n",
      "Epoch 00017: early stopping\n",
      "training layer conv5_block3_2_conv\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 520 steps, validate for 104 steps\n",
      "Epoch 1/250\n",
      "520/520 - 98s - loss: 0.1088 - val_loss: 0.1034\n",
      "Epoch 2/250\n",
      "520/520 - 95s - loss: 0.1044 - val_loss: 0.1031\n",
      "Epoch 3/250\n",
      "520/520 - 97s - loss: 0.1041 - val_loss: 0.1031\n",
      "Epoch 4/250\n",
      "520/520 - 98s - loss: 0.1042 - val_loss: 0.1031\n",
      "Epoch 5/250\n",
      "520/520 - 98s - loss: 0.1042 - val_loss: 0.1031\n",
      "Epoch 6/250\n",
      "520/520 - 97s - loss: 0.1040 - val_loss: 0.1030\n",
      "Epoch 7/250\n",
      "520/520 - 96s - loss: 0.1038 - val_loss: 0.1028\n",
      "Epoch 8/250\n",
      "520/520 - 97s - loss: 0.1032 - val_loss: 0.1017\n",
      "Epoch 9/250\n",
      "520/520 - 98s - loss: 0.1018 - val_loss: 0.0998\n",
      "Epoch 10/250\n",
      "520/520 - 96s - loss: 0.0999 - val_loss: 0.0984\n",
      "Epoch 11/250\n",
      "520/520 - 98s - loss: 0.0989 - val_loss: 0.0976\n",
      "Epoch 12/250\n",
      "520/520 - 97s - loss: 0.0984 - val_loss: 0.0970\n",
      "Epoch 13/250\n",
      "520/520 - 97s - loss: 0.0978 - val_loss: 0.0965\n",
      "Epoch 14/250\n",
      "520/520 - 97s - loss: 0.0973 - val_loss: 0.0962\n",
      "Epoch 15/250\n",
      "520/520 - 97s - loss: 0.0971 - val_loss: 0.0958\n",
      "Epoch 16/250\n",
      "520/520 - 99s - loss: 0.0967 - val_loss: 0.0953\n",
      "Epoch 17/250\n",
      "520/520 - 97s - loss: 0.0963 - val_loss: 0.0948\n",
      "Epoch 18/250\n",
      "520/520 - 97s - loss: 0.0956 - val_loss: 0.0941\n",
      "Epoch 19/250\n",
      "520/520 - 97s - loss: 0.0950 - val_loss: 0.0933\n",
      "Epoch 20/250\n",
      "520/520 - 97s - loss: 0.0941 - val_loss: 0.0926\n",
      "Epoch 21/250\n",
      "520/520 - 97s - loss: 0.0935 - val_loss: 0.0919\n",
      "Epoch 22/250\n",
      "520/520 - 97s - loss: 0.0928 - val_loss: 0.0911\n",
      "Epoch 23/250\n",
      "520/520 - 95s - loss: 0.0920 - val_loss: 0.0903\n",
      "Epoch 24/250\n",
      "520/520 - 98s - loss: 0.0912 - val_loss: 0.0894\n",
      "Epoch 25/250\n",
      "520/520 - 96s - loss: 0.0903 - val_loss: 0.0885\n",
      "Epoch 26/250\n",
      "520/520 - 97s - loss: 0.0893 - val_loss: 0.0874\n",
      "Epoch 27/250\n",
      "520/520 - 97s - loss: 0.0883 - val_loss: 0.0861\n",
      "Epoch 28/250\n",
      "520/520 - 94s - loss: 0.0870 - val_loss: 0.0848\n",
      "Epoch 29/250\n",
      "520/520 - 97s - loss: 0.0854 - val_loss: 0.0832\n",
      "Epoch 30/250\n",
      "520/520 - 96s - loss: 0.0840 - val_loss: 0.0817\n",
      "Epoch 31/250\n",
      "520/520 - 96s - loss: 0.0823 - val_loss: 0.0802\n",
      "Epoch 32/250\n",
      "520/520 - 95s - loss: 0.0809 - val_loss: 0.0786\n",
      "Epoch 33/250\n",
      "520/520 - 96s - loss: 0.0793 - val_loss: 0.0771\n",
      "Epoch 34/250\n",
      "520/520 - 96s - loss: 0.0779 - val_loss: 0.0756\n",
      "Epoch 35/250\n",
      "520/520 - 97s - loss: 0.0763 - val_loss: 0.0740\n",
      "Epoch 36/250\n",
      "520/520 - 95s - loss: 0.0747 - val_loss: 0.0724\n",
      "Epoch 37/250\n",
      "520/520 - 97s - loss: 0.0731 - val_loss: 0.0710\n",
      "Epoch 38/250\n",
      "520/520 - 96s - loss: 0.0719 - val_loss: 0.0695\n",
      "Epoch 39/250\n",
      "520/520 - 95s - loss: 0.0702 - val_loss: 0.0679\n",
      "Epoch 40/250\n",
      "520/520 - 97s - loss: 0.0687 - val_loss: 0.0665\n",
      "Epoch 41/250\n",
      "520/520 - 96s - loss: 0.0673 - val_loss: 0.0651\n",
      "Epoch 42/250\n",
      "520/520 - 96s - loss: 0.0658 - val_loss: 0.0636\n",
      "Epoch 43/250\n",
      "520/520 - 97s - loss: 0.0643 - val_loss: 0.0622\n",
      "Epoch 44/250\n",
      "520/520 - 97s - loss: 0.0629 - val_loss: 0.0608\n",
      "Epoch 45/250\n",
      "520/520 - 96s - loss: 0.0615 - val_loss: 0.0595\n",
      "Epoch 46/250\n",
      "520/520 - 96s - loss: 0.0602 - val_loss: 0.0582\n",
      "Epoch 47/250\n",
      "520/520 - 96s - loss: 0.0590 - val_loss: 0.0570\n",
      "Epoch 48/250\n",
      "520/520 - 96s - loss: 0.0576 - val_loss: 0.0557\n",
      "Epoch 49/250\n",
      "520/520 - 95s - loss: 0.0565 - val_loss: 0.0546\n",
      "Epoch 50/250\n",
      "520/520 - 96s - loss: 0.0554 - val_loss: 0.0535\n",
      "Epoch 51/250\n",
      "520/520 - 97s - loss: 0.0542 - val_loss: 0.0524\n",
      "Epoch 52/250\n",
      "520/520 - 96s - loss: 0.0530 - val_loss: 0.0514\n",
      "Epoch 53/250\n",
      "520/520 - 96s - loss: 0.0520 - val_loss: 0.0503\n",
      "Epoch 54/250\n",
      "520/520 - 95s - loss: 0.0510 - val_loss: 0.0493\n",
      "Epoch 55/250\n",
      "520/520 - 96s - loss: 0.0500 - val_loss: 0.0484\n",
      "Epoch 56/250\n",
      "520/520 - 96s - loss: 0.0490 - val_loss: 0.0474\n",
      "Epoch 57/250\n",
      "520/520 - 95s - loss: 0.0480 - val_loss: 0.0466\n",
      "Epoch 58/250\n",
      "520/520 - 95s - loss: 0.0471 - val_loss: 0.0457\n",
      "Epoch 59/250\n",
      "520/520 - 96s - loss: 0.0463 - val_loss: 0.0449\n",
      "Epoch 60/250\n",
      "520/520 - 96s - loss: 0.0455 - val_loss: 0.0440\n",
      "Epoch 61/250\n",
      "520/520 - 96s - loss: 0.0447 - val_loss: 0.0433\n",
      "Epoch 62/250\n",
      "520/520 - 96s - loss: 0.0438 - val_loss: 0.0425\n",
      "Epoch 63/250\n",
      "520/520 - 95s - loss: 0.0431 - val_loss: 0.0418\n",
      "Epoch 64/250\n",
      "520/520 - 96s - loss: 0.0423 - val_loss: 0.0411\n",
      "Epoch 65/250\n",
      "520/520 - 95s - loss: 0.0416 - val_loss: 0.0404\n",
      "Epoch 66/250\n",
      "520/520 - 97s - loss: 0.0409 - val_loss: 0.0397\n",
      "Epoch 67/250\n",
      "520/520 - 94s - loss: 0.0403 - val_loss: 0.0391\n",
      "Epoch 68/250\n",
      "520/520 - 96s - loss: 0.0396 - val_loss: 0.0385\n",
      "Epoch 69/250\n",
      "520/520 - 97s - loss: 0.0390 - val_loss: 0.0379\n",
      "Epoch 70/250\n",
      "520/520 - 95s - loss: 0.0384 - val_loss: 0.0374\n",
      "Epoch 71/250\n",
      "520/520 - 96s - loss: 0.0378 - val_loss: 0.0368\n",
      "Epoch 72/250\n",
      "520/520 - 95s - loss: 0.0373 - val_loss: 0.0363\n",
      "Epoch 73/250\n",
      "520/520 - 95s - loss: 0.0367 - val_loss: 0.0357\n",
      "Epoch 74/250\n",
      "520/520 - 96s - loss: 0.0362 - val_loss: 0.0352\n",
      "Epoch 75/250\n",
      "520/520 - 95s - loss: 0.0357 - val_loss: 0.0348\n",
      "Epoch 76/250\n",
      "520/520 - 95s - loss: 0.0352 - val_loss: 0.0343\n",
      "Epoch 77/250\n",
      "520/520 - 97s - loss: 0.0347 - val_loss: 0.0338\n",
      "Epoch 78/250\n",
      "520/520 - 94s - loss: 0.0343 - val_loss: 0.0334\n",
      "Epoch 79/250\n",
      "520/520 - 96s - loss: 0.0338 - val_loss: 0.0330\n",
      "Epoch 80/250\n",
      "520/520 - 96s - loss: 0.0334 - val_loss: 0.0326\n",
      "Epoch 81/250\n",
      "520/520 - 95s - loss: 0.0330 - val_loss: 0.0321\n",
      "Epoch 82/250\n",
      "520/520 - 95s - loss: 0.0325 - val_loss: 0.0318\n",
      "Epoch 83/250\n",
      "520/520 - 95s - loss: 0.0322 - val_loss: 0.0314\n",
      "Epoch 84/250\n",
      "520/520 - 95s - loss: 0.0317 - val_loss: 0.0310\n",
      "Epoch 85/250\n",
      "520/520 - 96s - loss: 0.0313 - val_loss: 0.0307\n",
      "Epoch 86/250\n",
      "520/520 - 95s - loss: 0.0310 - val_loss: 0.0303\n",
      "Epoch 87/250\n",
      "520/520 - 95s - loss: 0.0306 - val_loss: 0.0299\n",
      "Epoch 88/250\n",
      "520/520 - 96s - loss: 0.0303 - val_loss: 0.0296\n",
      "Epoch 89/250\n",
      "520/520 - 94s - loss: 0.0300 - val_loss: 0.0293\n",
      "Epoch 90/250\n",
      "520/520 - 95s - loss: 0.0296 - val_loss: 0.0290\n",
      "Epoch 91/250\n",
      "520/520 - 95s - loss: 0.0293 - val_loss: 0.0287\n",
      "Epoch 92/250\n",
      "520/520 - 95s - loss: 0.0290 - val_loss: 0.0284\n",
      "Epoch 93/250\n",
      "520/520 - 96s - loss: 0.0287 - val_loss: 0.0281\n",
      "Epoch 94/250\n",
      "520/520 - 96s - loss: 0.0284 - val_loss: 0.0278\n",
      "Epoch 95/250\n",
      "520/520 - 96s - loss: 0.0281 - val_loss: 0.0275\n",
      "Epoch 96/250\n",
      "520/520 - 96s - loss: 0.0278 - val_loss: 0.0273\n",
      "Epoch 97/250\n",
      "520/520 - 96s - loss: 0.0276 - val_loss: 0.0270\n",
      "Epoch 98/250\n",
      "520/520 - 96s - loss: 0.0273 - val_loss: 0.0268\n",
      "Epoch 99/250\n",
      "520/520 - 95s - loss: 0.0270 - val_loss: 0.0265\n",
      "Epoch 100/250\n",
      "520/520 - 95s - loss: 0.0268 - val_loss: 0.0263\n",
      "Epoch 101/250\n",
      "520/520 - 94s - loss: 0.0265 - val_loss: 0.0260\n",
      "Epoch 102/250\n",
      "520/520 - 95s - loss: 0.0263 - val_loss: 0.0258\n",
      "Epoch 103/250\n",
      "520/520 - 97s - loss: 0.0260 - val_loss: 0.0256\n",
      "Epoch 104/250\n",
      "520/520 - 95s - loss: 0.0258 - val_loss: 0.0253\n",
      "Epoch 105/250\n",
      "520/520 - 95s - loss: 0.0256 - val_loss: 0.0252\n",
      "Epoch 106/250\n",
      "520/520 - 96s - loss: 0.0254 - val_loss: 0.0249\n",
      "Epoch 107/250\n",
      "520/520 - 95s - loss: 0.0252 - val_loss: 0.0247\n",
      "Epoch 108/250\n",
      "520/520 - 96s - loss: 0.0250 - val_loss: 0.0245\n",
      "Epoch 109/250\n",
      "520/520 - 96s - loss: 0.0247 - val_loss: 0.0243\n",
      "Epoch 110/250\n",
      "520/520 - 95s - loss: 0.0245 - val_loss: 0.0241\n",
      "Epoch 111/250\n",
      "520/520 - 96s - loss: 0.0244 - val_loss: 0.0239\n",
      "Epoch 112/250\n",
      "520/520 - 96s - loss: 0.0242 - val_loss: 0.0238\n",
      "Epoch 113/250\n",
      "520/520 - 94s - loss: 0.0240 - val_loss: 0.0236\n",
      "Epoch 114/250\n",
      "520/520 - 95s - loss: 0.0238 - val_loss: 0.0234\n",
      "Epoch 115/250\n",
      "520/520 - 95s - loss: 0.0236 - val_loss: 0.0232\n",
      "Epoch 116/250\n",
      "520/520 - 95s - loss: 0.0234 - val_loss: 0.0231\n",
      "Epoch 117/250\n",
      "520/520 - 96s - loss: 0.0233 - val_loss: 0.0229\n",
      "Epoch 118/250\n",
      "520/520 - 96s - loss: 0.0231 - val_loss: 0.0227\n",
      "Epoch 119/250\n",
      "520/520 - 95s - loss: 0.0229 - val_loss: 0.0226\n",
      "Epoch 120/250\n",
      "520/520 - 94s - loss: 0.0228 - val_loss: 0.0224\n",
      "Epoch 121/250\n",
      "520/520 - 95s - loss: 0.0226 - val_loss: 0.0223\n",
      "Epoch 122/250\n",
      "520/520 - 96s - loss: 0.0224 - val_loss: 0.0221\n",
      "Epoch 123/250\n",
      "520/520 - 95s - loss: 0.0223 - val_loss: 0.0220\n",
      "Epoch 124/250\n",
      "520/520 - 94s - loss: 0.0222 - val_loss: 0.0218\n",
      "Epoch 125/250\n",
      "520/520 - 96s - loss: 0.0220 - val_loss: 0.0217\n",
      "Epoch 126/250\n",
      "520/520 - 95s - loss: 0.0219 - val_loss: 0.0215\n",
      "Epoch 127/250\n",
      "520/520 - 96s - loss: 0.0217 - val_loss: 0.0214\n",
      "Epoch 128/250\n",
      "520/520 - 95s - loss: 0.0216 - val_loss: 0.0212\n",
      "Epoch 129/250\n",
      "520/520 - 95s - loss: 0.0214 - val_loss: 0.0211\n",
      "Epoch 130/250\n",
      "520/520 - 96s - loss: 0.0213 - val_loss: 0.0210\n",
      "Epoch 131/250\n",
      "520/520 - 94s - loss: 0.0211 - val_loss: 0.0209\n",
      "Epoch 132/250\n",
      "520/520 - 94s - loss: 0.0210 - val_loss: 0.0207\n",
      "Epoch 133/250\n",
      "520/520 - 96s - loss: 0.0209 - val_loss: 0.0206\n",
      "Epoch 134/250\n",
      "520/520 - 96s - loss: 0.0208 - val_loss: 0.0205\n",
      "Epoch 135/250\n",
      "520/520 - 96s - loss: 0.0206 - val_loss: 0.0203\n",
      "Epoch 136/250\n",
      "520/520 - 95s - loss: 0.0205 - val_loss: 0.0202\n",
      "Epoch 137/250\n",
      "520/520 - 96s - loss: 0.0204 - val_loss: 0.0201\n",
      "Epoch 138/250\n",
      "520/520 - 95s - loss: 0.0203 - val_loss: 0.0200\n",
      "Epoch 139/250\n",
      "520/520 - 95s - loss: 0.0202 - val_loss: 0.0199\n",
      "Epoch 140/250\n",
      "520/520 - 95s - loss: 0.0200 - val_loss: 0.0198\n",
      "Epoch 141/250\n",
      "520/520 - 95s - loss: 0.0199 - val_loss: 0.0196\n",
      "Epoch 142/250\n",
      "520/520 - 96s - loss: 0.0198 - val_loss: 0.0195\n",
      "Epoch 143/250\n",
      "520/520 - 96s - loss: 0.0197 - val_loss: 0.0194\n",
      "Epoch 144/250\n",
      "520/520 - 96s - loss: 0.0196 - val_loss: 0.0193\n",
      "Epoch 145/250\n",
      "520/520 - 95s - loss: 0.0195 - val_loss: 0.0192\n",
      "Epoch 146/250\n",
      "520/520 - 97s - loss: 0.0194 - val_loss: 0.0191\n",
      "Epoch 147/250\n",
      "520/520 - 95s - loss: 0.0193 - val_loss: 0.0190\n",
      "Epoch 148/250\n",
      "520/520 - 95s - loss: 0.0191 - val_loss: 0.0189\n",
      "Epoch 149/250\n",
      "520/520 - 96s - loss: 0.0190 - val_loss: 0.0188\n",
      "Epoch 150/250\n",
      "520/520 - 94s - loss: 0.0190 - val_loss: 0.0187\n",
      "Epoch 151/250\n",
      "520/520 - 96s - loss: 0.0189 - val_loss: 0.0186\n",
      "Epoch 152/250\n",
      "520/520 - 96s - loss: 0.0188 - val_loss: 0.0185\n",
      "Epoch 153/250\n",
      "520/520 - 95s - loss: 0.0187 - val_loss: 0.0184\n",
      "Epoch 154/250\n",
      "520/520 - 96s - loss: 0.0186 - val_loss: 0.0184\n",
      "Epoch 155/250\n",
      "520/520 - 95s - loss: 0.0185 - val_loss: 0.0183\n",
      "Epoch 156/250\n",
      "520/520 - 95s - loss: 0.0184 - val_loss: 0.0182\n",
      "Epoch 157/250\n",
      "520/520 - 95s - loss: 0.0183 - val_loss: 0.0181\n",
      "Epoch 158/250\n",
      "520/520 - 95s - loss: 0.0182 - val_loss: 0.0180\n",
      "Epoch 159/250\n",
      "520/520 - 96s - loss: 0.0181 - val_loss: 0.0179\n",
      "Epoch 160/250\n",
      "520/520 - 95s - loss: 0.0180 - val_loss: 0.0178\n",
      "Epoch 161/250\n",
      "520/520 - 95s - loss: 0.0180 - val_loss: 0.0178\n",
      "Epoch 162/250\n",
      "520/520 - 95s - loss: 0.0179 - val_loss: 0.0177\n",
      "Epoch 163/250\n",
      "520/520 - 94s - loss: 0.0178 - val_loss: 0.0176\n",
      "Epoch 164/250\n",
      "520/520 - 94s - loss: 0.0177 - val_loss: 0.0175\n",
      "Epoch 165/250\n",
      "520/520 - 95s - loss: 0.0177 - val_loss: 0.0175\n",
      "Epoch 166/250\n",
      "520/520 - 96s - loss: 0.0176 - val_loss: 0.0174\n",
      "Epoch 167/250\n",
      "520/520 - 95s - loss: 0.0175 - val_loss: 0.0173\n",
      "Epoch 168/250\n",
      "520/520 - 96s - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 169/250\n",
      "520/520 - 95s - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 170/250\n",
      "520/520 - 96s - loss: 0.0173 - val_loss: 0.0171\n",
      "Epoch 171/250\n",
      "520/520 - 95s - loss: 0.0172 - val_loss: 0.0170\n",
      "Epoch 172/250\n",
      "520/520 - 95s - loss: 0.0172 - val_loss: 0.0170\n",
      "Epoch 173/250\n",
      "520/520 - 96s - loss: 0.0171 - val_loss: 0.0169\n",
      "Epoch 174/250\n",
      "520/520 - 95s - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 175/250\n",
      "520/520 - 95s - loss: 0.0170 - val_loss: 0.0168\n",
      "Epoch 176/250\n",
      "520/520 - 96s - loss: 0.0169 - val_loss: 0.0167\n",
      "Epoch 177/250\n",
      "520/520 - 96s - loss: 0.0168 - val_loss: 0.0167\n",
      "Epoch 178/250\n",
      "520/520 - 96s - loss: 0.0168 - val_loss: 0.0166\n",
      "Epoch 179/250\n",
      "520/520 - 96s - loss: 0.0167 - val_loss: 0.0165\n",
      "Epoch 180/250\n",
      "520/520 - 95s - loss: 0.0167 - val_loss: 0.0165\n",
      "Epoch 181/250\n",
      "520/520 - 92s - loss: 0.0166 - val_loss: 0.0164\n",
      "Epoch 182/250\n",
      "520/520 - 94s - loss: 0.0165 - val_loss: 0.0164\n",
      "Epoch 183/250\n",
      "520/520 - 95s - loss: 0.0165 - val_loss: 0.0163\n",
      "Epoch 184/250\n",
      "520/520 - 94s - loss: 0.0164 - val_loss: 0.0163\n",
      "Epoch 185/250\n",
      "520/520 - 94s - loss: 0.0164 - val_loss: 0.0162\n",
      "Epoch 186/250\n",
      "520/520 - 94s - loss: 0.0163 - val_loss: 0.0162\n",
      "Epoch 187/250\n",
      "520/520 - 94s - loss: 0.0163 - val_loss: 0.0161\n",
      "Epoch 188/250\n",
      "520/520 - 94s - loss: 0.0162 - val_loss: 0.0161\n",
      "Epoch 189/250\n",
      "520/520 - 95s - loss: 0.0162 - val_loss: 0.0160\n",
      "Epoch 190/250\n",
      "520/520 - 93s - loss: 0.0161 - val_loss: 0.0160\n",
      "Epoch 191/250\n",
      "520/520 - 95s - loss: 0.0161 - val_loss: 0.0159\n",
      "Epoch 192/250\n",
      "520/520 - 94s - loss: 0.0161 - val_loss: 0.0159\n",
      "Epoch 193/250\n",
      "520/520 - 94s - loss: 0.0160 - val_loss: 0.0158\n",
      "Epoch 194/250\n",
      "520/520 - 95s - loss: 0.0160 - val_loss: 0.0158\n",
      "Epoch 195/250\n",
      "520/520 - 94s - loss: 0.0159 - val_loss: 0.0158\n",
      "Epoch 196/250\n",
      "520/520 - 95s - loss: 0.0159 - val_loss: 0.0157\n",
      "Epoch 197/250\n",
      "520/520 - 95s - loss: 0.0158 - val_loss: 0.0157\n",
      "Epoch 198/250\n",
      "520/520 - 94s - loss: 0.0158 - val_loss: 0.0156\n",
      "Epoch 199/250\n",
      "520/520 - 95s - loss: 0.0157 - val_loss: 0.0156\n",
      "Epoch 200/250\n",
      "520/520 - 95s - loss: 0.0157 - val_loss: 0.0155\n",
      "Epoch 201/250\n",
      "520/520 - 95s - loss: 0.0157 - val_loss: 0.0155\n",
      "Epoch 202/250\n",
      "520/520 - 95s - loss: 0.0156 - val_loss: 0.0155\n",
      "Epoch 203/250\n",
      "520/520 - 94s - loss: 0.0156 - val_loss: 0.0154\n",
      "Epoch 204/250\n",
      "520/520 - 95s - loss: 0.0155 - val_loss: 0.0154\n",
      "Epoch 205/250\n",
      "520/520 - 95s - loss: 0.0155 - val_loss: 0.0153\n",
      "Epoch 206/250\n",
      "520/520 - 94s - loss: 0.0155 - val_loss: 0.0153\n",
      "Epoch 207/250\n",
      "520/520 - 95s - loss: 0.0154 - val_loss: 0.0153\n",
      "Epoch 208/250\n",
      "520/520 - 94s - loss: 0.0154 - val_loss: 0.0152\n",
      "Epoch 209/250\n",
      "520/520 - 94s - loss: 0.0153 - val_loss: 0.0152\n",
      "Epoch 210/250\n",
      "520/520 - 94s - loss: 0.0153 - val_loss: 0.0152\n",
      "Epoch 211/250\n",
      "520/520 - 94s - loss: 0.0153 - val_loss: 0.0151\n",
      "Epoch 212/250\n",
      "520/520 - 93s - loss: 0.0153 - val_loss: 0.0151\n",
      "Epoch 213/250\n",
      "520/520 - 95s - loss: 0.0152 - val_loss: 0.0151\n",
      "Epoch 214/250\n",
      "520/520 - 95s - loss: 0.0152 - val_loss: 0.0150\n",
      "Epoch 215/250\n",
      "520/520 - 94s - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 216/250\n",
      "520/520 - 94s - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 217/250\n",
      "520/520 - 94s - loss: 0.0151 - val_loss: 0.0149\n",
      "Epoch 218/250\n",
      "520/520 - 95s - loss: 0.0151 - val_loss: 0.0149\n",
      "Epoch 219/250\n",
      "520/520 - 94s - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 220/250\n",
      "520/520 - 95s - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 221/250\n",
      "520/520 - 95s - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 222/250\n",
      "520/520 - 95s - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 223/250\n",
      "520/520 - 95s - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 224/250\n",
      "520/520 - 94s - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 225/250\n",
      "520/520 - 94s - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 226/250\n",
      "520/520 - 96s - loss: 0.0148 - val_loss: 0.0146\n",
      "Epoch 227/250\n",
      "520/520 - 95s - loss: 0.0148 - val_loss: 0.0146\n",
      "Epoch 228/250\n",
      "520/520 - 94s - loss: 0.0147 - val_loss: 0.0146\n",
      "Epoch 229/250\n",
      "520/520 - 95s - loss: 0.0147 - val_loss: 0.0146\n",
      "Epoch 230/250\n",
      "520/520 - 94s - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 231/250\n",
      "520/520 - 95s - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 232/250\n",
      "520/520 - 94s - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 233/250\n",
      "520/520 - 94s - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 234/250\n",
      "520/520 - 95s - loss: 0.0146 - val_loss: 0.0144\n",
      "Epoch 235/250\n",
      "520/520 - 94s - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 236/250\n",
      "520/520 - 94s - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 237/250\n",
      "520/520 - 95s - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 238/250\n",
      "520/520 - 95s - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 239/250\n",
      "520/520 - 94s - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 240/250\n",
      "520/520 - 94s - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 241/250\n",
      "520/520 - 94s - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 242/250\n",
      "520/520 - 95s - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 243/250\n",
      "520/520 - 95s - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 244/250\n",
      "520/520 - 94s - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 245/250\n",
      "520/520 - 95s - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 246/250\n",
      "520/520 - 95s - loss: 0.0143 - val_loss: 0.0141\n",
      "Epoch 247/250\n",
      "520/520 - 95s - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 248/250\n",
      "520/520 - 94s - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 249/250\n",
      "520/520 - 93s - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 250/250\n",
      "520/520 - 94s - loss: 0.0142 - val_loss: 0.0140\n",
      "This run of \"layers\" ran for 3:04:44 and logs are available locally at: /root/.hyperdash/logs/layers/layers_2019-12-31t01-56-44-766198.log\n"
     ]
    }
   ],
   "source": [
    "%%monitor_cell \"layers\"\n",
    "for target in targets:\n",
    "    \n",
    "    print(f\"training layer {target['name']}\")\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = tf.keras.models.load_model('base_model_cifar10_resnet50.h5')\n",
    "    in_layer, out_layer = target['to_replace'][0][1], target['to_replace'][-1][1]\n",
    "    get_output = tf.keras.Model(inputs=model.input, outputs=[model.layers[in_layer - 1].output, model.layers[out_layer].output])\n",
    "\n",
    "\n",
    "    replacement_layers = build_replacement(get_output, layers=2)\n",
    "    replacement_len = len(replacement_layers.layers)\n",
    "    layer_train_gen = LayerBatch(get_output, train_dataset)\n",
    "    layer_test_gen = LayerTest(get_output, test_dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    MSE = tf.losses.MeanSquaredError()\n",
    "\n",
    "    optimizer=tf.keras.optimizers.SGD(.1, momentum=.9, nesterov=True)\n",
    "    replacement_layers.compile(loss=MSE, optimizer=optimizer)\n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(patience=5, min_lr=.0001, factor=.3, verbose=1)\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(patience=15, min_delta=.0001, restore_best_weights=True, verbose=1)\n",
    "    history = replacement_layers.fit(x=layer_train_gen,\n",
    "                                   epochs=250,\n",
    "                                   steps_per_epoch=TRAIN_SIZE // global_batch_size,\n",
    "                                   validation_data=layer_test_gen,\n",
    "                                   shuffle=False,\n",
    "                                   callbacks=[reduce_lr, early_stop],\n",
    "                                   validation_steps=VALIDATION_SIZE // global_batch_size,\n",
    "                                   verbose=2)\n",
    "    target['weights'] = [replacement_layers.layers[1].get_weights(), replacement_layers.layers[3].get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 684
    },
    "colab_type": "code",
    "id": "7aFvw1tnEftn",
    "outputId": "c4b12909-606f-4bfc-e88e-07f814aa46ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing Layer conv2_block1_2_conv\n",
      "replacing conv2_block1_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_32 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_32 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv2_block1_2_bn\n",
      "deleting conv2_block1_2_relu\n",
      "104/104 [==============================] - 36s 345ms/step - loss: 0.1446 - accuracy: 0.9525\n",
      "Replacing Layer conv2_block2_2_conv\n",
      "replacing conv2_block2_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_34 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_34 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv2_block2_2_bn\n",
      "deleting conv2_block2_2_relu\n",
      "104/104 [==============================] - 12s 112ms/step - loss: 0.1430 - accuracy: 0.9530\n",
      "Replacing Layer conv2_block3_2_conv\n",
      "replacing conv2_block3_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_36 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_36 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv2_block3_2_bn\n",
      "deleting conv2_block3_2_relu\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.1412 - accuracy: 0.9536\n",
      "Replacing Layer conv3_block1_2_conv\n",
      "replacing conv3_block1_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_38 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_38 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv3_block1_2_bn\n",
      "deleting conv3_block1_2_relu\n",
      "104/104 [==============================] - 10s 95ms/step - loss: 0.1427 - accuracy: 0.9527\n",
      "Replacing Layer conv3_block2_2_conv\n",
      "replacing conv3_block2_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_40 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_40 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv3_block2_2_bn\n",
      "deleting conv3_block2_2_relu\n",
      "104/104 [==============================] - 10s 92ms/step - loss: 0.1426 - accuracy: 0.9522\n",
      "Replacing Layer conv3_block3_2_conv\n",
      "replacing conv3_block3_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_42 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_42 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv3_block3_2_bn\n",
      "deleting conv3_block3_2_relu\n",
      "104/104 [==============================] - 9s 91ms/step - loss: 0.1430 - accuracy: 0.9522\n",
      "Replacing Layer conv3_block4_2_conv\n",
      "replacing conv3_block4_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_44 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_44 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv3_block4_2_bn\n",
      "deleting conv3_block4_2_relu\n",
      "104/104 [==============================] - 11s 106ms/step - loss: 0.1447 - accuracy: 0.9529\n",
      "Replacing Layer conv4_block1_2_conv\n",
      "replacing conv4_block1_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_46 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_46 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv4_block1_2_bn\n",
      "deleting conv4_block1_2_relu\n",
      "104/104 [==============================] - 10s 100ms/step - loss: 0.1439 - accuracy: 0.9509\n",
      "Replacing Layer conv4_block2_2_conv\n",
      "replacing conv4_block2_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_48 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_48 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv4_block2_2_bn\n",
      "deleting conv4_block2_2_relu\n",
      "104/104 [==============================] - 15s 147ms/step - loss: 0.1422 - accuracy: 0.9521\n",
      "Replacing Layer conv4_block3_2_conv\n",
      "replacing conv4_block3_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_50 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_50 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv4_block3_2_bn\n",
      "deleting conv4_block3_2_relu\n",
      "104/104 [==============================] - 8s 80ms/step - loss: 0.1421 - accuracy: 0.9523\n",
      "Replacing Layer conv4_block4_2_conv\n",
      "replacing conv4_block4_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_52 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_52 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv4_block4_2_bn\n",
      "deleting conv4_block4_2_relu\n",
      "104/104 [==============================] - 8s 82ms/step - loss: 0.1456 - accuracy: 0.9527\n",
      "Replacing Layer conv4_block5_2_conv\n",
      "replacing conv4_block5_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_54 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_54 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv4_block5_2_bn\n",
      "deleting conv4_block5_2_relu\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 0.1434 - accuracy: 0.9532\n",
      "Replacing Layer conv4_block6_2_conv\n",
      "replacing conv4_block6_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_56 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_56 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv4_block6_2_bn\n",
      "deleting conv4_block6_2_relu\n",
      "104/104 [==============================] - 11s 103ms/step - loss: 0.1425 - accuracy: 0.9525\n",
      "Replacing Layer conv5_block1_2_conv\n",
      "replacing conv5_block1_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_58 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_58 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv5_block1_2_bn\n",
      "deleting conv5_block1_2_relu\n",
      "104/104 [==============================] - 9s 82ms/step - loss: 0.1464 - accuracy: 0.9517\n",
      "Replacing Layer conv5_block2_2_conv\n",
      "replacing conv5_block2_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_60 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_60 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv5_block2_2_bn\n",
      "deleting conv5_block2_2_relu\n",
      "104/104 [==============================] - 9s 86ms/step - loss: 0.2146 - accuracy: 0.9348\n",
      "Replacing Layer conv5_block3_2_conv\n",
      "replacing conv5_block3_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_62 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_62 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv5_block3_2_bn\n",
      "deleting conv5_block3_2_relu\n",
      "104/104 [==============================] - 9s 84ms/step - loss: 0.1423 - accuracy: 0.9534\n"
     ]
    }
   ],
   "source": [
    "for target in targets:\n",
    "    \n",
    "    print(f'Replacing Layer {target[\"name\"]}')\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    model = tf.keras.models.load_model('base_model_cifar10_resnet50.h5')\n",
    "    \n",
    "    layers_to_replace = [x[0] for x in target['to_replace']]\n",
    "    weights_to_replace = [target['to_replace'][0][1], target['to_replace'][-1][1]]\n",
    "    \n",
    "    new_model = replace_layer(model, layers_to_replace, lambda x: replac(x))\n",
    "    new_model.layers[weights_to_replace[0]].set_weights(target['weights'][0])\n",
    "    new_model.layers[weights_to_replace[1]].set_weights(target['weights'][1])\n",
    "    new_model.compile(optimizer=tf.keras.optimizers.SGD(.1), loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    target['score'] = new_model.evaluate(test_dataset, steps=VALIDATION_SIZE // global_batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SMzvFVVVVKPP",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'name: conv2_block1_2_conv score: [0.14458354241931096, 0.95252407]'\n",
      "'name: conv2_block2_2_conv score: [0.1429631541698025, 0.95302486]'\n",
      "'name: conv2_block3_2_conv score: [0.14124455573395467, 0.9536258]'\n",
      "'name: conv3_block1_2_conv score: [0.14273115303009176, 0.95272434]'\n",
      "'name: conv3_block2_2_conv score: [0.1425617459910707, 0.95222354]'\n",
      "'name: conv3_block3_2_conv score: [0.1430274860288661, 0.95222354]'\n",
      "'name: conv3_block4_2_conv score: [0.14467338993787193, 0.95292467]'\n",
      "'name: conv4_block1_2_conv score: [0.14392931879354784, 0.9509215]'\n",
      "'name: conv4_block2_2_conv score: [0.14221949184026855, 0.9521234]'\n",
      "'name: conv4_block3_2_conv score: [0.14207436884037003, 0.95232373]'\n",
      "'name: conv4_block4_2_conv score: [0.1456324967304961, 0.95272434]'\n",
      "'name: conv4_block5_2_conv score: [0.14340634094193005, 0.95322514]'\n",
      "'name: conv4_block6_2_conv score: [0.1425402238069532, 0.95252407]'\n",
      "'name: conv5_block1_2_conv score: [0.14638534492741412, 0.95172274]'\n",
      "'name: conv5_block2_2_conv score: [0.21462320837263876, 0.9347957]'\n",
      "'name: conv5_block3_2_conv score: [0.14231674718813828, 0.95342547]'\n"
     ]
    }
   ],
   "source": [
    "for target in targets:\n",
    "    pprint.pprint(f\"name: {target['name']} score: {target['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('resnet.pickle', 'wb') as f:\n",
    "    pickle.dump(targets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resnet.pickle', 'rb') as f:\n",
    "    targets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 64, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]['weights'][1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 684
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "7aFvw1tnEftn",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "c4b12909-606f-4bfc-e88e-07f814aa46ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing Layer conv5_block3_2_conv\n",
      "replacing conv5_block3_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_62 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_62 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv5_block3_2_bn\n",
      "deleting conv5_block3_2_relu\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing Layer conv5_block1_2_conv\n",
      "replacing conv5_block1_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_64 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_64 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv5_block1_2_bn\n",
      "deleting conv5_block1_2_relu\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing Layer conv4_block6_2_conv\n",
      "replacing conv4_block6_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_66 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_66 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv4_block6_2_bn\n",
      "deleting conv4_block6_2_relu\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing Layer conv4_block5_2_conv\n",
      "replacing conv4_block5_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_68 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_68 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv4_block5_2_bn\n",
      "deleting conv4_block5_2_relu\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing Layer conv4_block4_2_conv\n",
      "replacing conv4_block4_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_70 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_70 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv4_block4_2_bn\n",
      "deleting conv4_block4_2_relu\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing Layer conv4_block3_2_conv\n",
      "replacing conv4_block3_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_72 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_72 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv4_block3_2_bn\n",
      "deleting conv4_block3_2_relu\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing Layer conv4_block2_2_conv\n",
      "replacing conv4_block2_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_74 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_74 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv4_block2_2_bn\n",
      "deleting conv4_block2_2_relu\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing Layer conv4_block1_2_conv\n",
      "replacing conv4_block1_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_76 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_76 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv4_block1_2_bn\n",
      "deleting conv4_block1_2_relu\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing Layer conv3_block4_2_conv\n",
      "replacing conv3_block4_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_78 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_78 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv3_block4_2_bn\n",
      "deleting conv3_block4_2_relu\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing Layer conv3_block3_2_conv\n",
      "replacing conv3_block3_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_80 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_80 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv3_block3_2_bn\n",
      "deleting conv3_block3_2_relu\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing Layer conv3_block2_2_conv\n",
      "replacing conv3_block2_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_82 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_82 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv3_block2_2_bn\n",
      "deleting conv3_block2_2_relu\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing Layer conv3_block1_2_conv\n",
      "replacing conv3_block1_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_84 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_84 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv3_block1_2_bn\n",
      "deleting conv3_block1_2_relu\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing Layer conv2_block3_2_conv\n",
      "replacing conv2_block3_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_86 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_86 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv2_block3_2_bn\n",
      "deleting conv2_block3_2_relu\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing Layer conv2_block2_2_conv\n",
      "replacing conv2_block2_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_88 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_88 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv2_block2_2_bn\n",
      "deleting conv2_block2_2_relu\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing Layer conv2_block1_2_conv\n",
      "replacing conv2_block1_2_conv\n",
      "WARNING:tensorflow:Layer sep_conv_90 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sep_conv_90 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting conv2_block1_2_bn\n",
      "deleting conv2_block1_2_relu\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 12s 116ms/step - loss: 0.1662 - accuracy: 0.9453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1661724245104079, 0.9453125]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('base_model_cifar10_resnet50.h5')\n",
    "for target in targets[::-1]:\n",
    "    \n",
    "    if results[1] - target['score'][1] < .01:\n",
    "    \n",
    "        print(f'Replacing Layer {target[\"name\"]}')\n",
    "\n",
    "\n",
    "        layers_to_replace = [x[0] for x in target['to_replace']]\n",
    "        weights_to_replace = [target['to_replace'][0][1], target['to_replace'][-1][1]]\n",
    "\n",
    "        model = replace_layer(model, layers_to_replace, lambda x: replac(x))\n",
    "        model.layers[weights_to_replace[0]].set_weights(target['weights'][0])\n",
    "        model.layers[weights_to_replace[1]].set_weights(target['weights'][1])\n",
    "\n",
    "\n",
    "\n",
    "        model.save('resnet_modified.h5')\n",
    "        tf.keras.backend.clear_session()\n",
    "        model = tf.keras.models.load_model('resnet_modified.h5')\n",
    "\n",
    "    \n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(.1), loss=\"categorical_crossentropy\", metrics=['accuracy']) \n",
    "model.evaluate(test_dataset, steps=VALIDATION_SIZE//global_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 520 steps, validate for 104 steps\n",
      "Epoch 1/30\n",
      "520/520 [==============================] - 176s 339ms/step - loss: 0.1086 - accuracy: 0.9644 - val_loss: 0.1492 - val_accuracy: 0.9505\n",
      "Epoch 2/30\n",
      "520/520 [==============================] - 169s 325ms/step - loss: 0.1031 - accuracy: 0.9661 - val_loss: 0.1447 - val_accuracy: 0.9531\n",
      "Epoch 3/30\n",
      "520/520 [==============================] - 168s 323ms/step - loss: 0.1001 - accuracy: 0.9670 - val_loss: 0.1443 - val_accuracy: 0.9503\n",
      "Epoch 4/30\n",
      "520/520 [==============================] - 168s 324ms/step - loss: 0.0965 - accuracy: 0.9687 - val_loss: 0.1441 - val_accuracy: 0.9523\n",
      "Epoch 5/30\n",
      "520/520 [==============================] - 169s 324ms/step - loss: 0.0951 - accuracy: 0.9694 - val_loss: 0.1446 - val_accuracy: 0.9533\n",
      "Epoch 6/30\n",
      "520/520 [==============================] - 169s 326ms/step - loss: 0.0906 - accuracy: 0.9711 - val_loss: 0.1450 - val_accuracy: 0.9522\n",
      "Epoch 7/30\n",
      "520/520 [==============================] - 169s 324ms/step - loss: 0.0928 - accuracy: 0.9698 - val_loss: 0.1402 - val_accuracy: 0.9535\n",
      "Epoch 8/30\n",
      "520/520 [==============================] - 169s 324ms/step - loss: 0.0879 - accuracy: 0.9713 - val_loss: 0.1439 - val_accuracy: 0.9528\n",
      "Epoch 9/30\n",
      "520/520 [==============================] - 169s 325ms/step - loss: 0.0868 - accuracy: 0.9724 - val_loss: 0.1416 - val_accuracy: 0.9542\n",
      "Epoch 10/30\n",
      "520/520 [==============================] - 169s 325ms/step - loss: 0.0878 - accuracy: 0.9722 - val_loss: 0.1443 - val_accuracy: 0.9529\n",
      "Epoch 11/30\n",
      "520/520 [==============================] - 169s 325ms/step - loss: 0.0847 - accuracy: 0.9725 - val_loss: 0.1455 - val_accuracy: 0.9518\n",
      "Epoch 12/30\n",
      "520/520 [==============================] - 169s 325ms/step - loss: 0.0815 - accuracy: 0.9742 - val_loss: 0.1437 - val_accuracy: 0.9516\n",
      "Epoch 13/30\n",
      "520/520 [==============================] - 169s 324ms/step - loss: 0.0815 - accuracy: 0.9740 - val_loss: 0.1416 - val_accuracy: 0.9544\n",
      "Epoch 14/30\n",
      "520/520 [==============================] - 169s 325ms/step - loss: 0.0803 - accuracy: 0.9737 - val_loss: 0.1421 - val_accuracy: 0.9526\n",
      "Epoch 15/30\n",
      "520/520 [==============================] - 168s 324ms/step - loss: 0.0765 - accuracy: 0.9758 - val_loss: 0.1400 - val_accuracy: 0.9547\n",
      "Epoch 16/30\n",
      "520/520 [==============================] - 169s 325ms/step - loss: 0.0805 - accuracy: 0.9740 - val_loss: 0.1453 - val_accuracy: 0.9524\n",
      "Epoch 17/30\n",
      "520/520 [==============================] - 169s 326ms/step - loss: 0.0772 - accuracy: 0.9752 - val_loss: 0.1453 - val_accuracy: 0.9521\n",
      "Epoch 18/30\n",
      "520/520 [==============================] - 169s 325ms/step - loss: 0.0771 - accuracy: 0.9749 - val_loss: 0.1421 - val_accuracy: 0.9535\n",
      "Epoch 19/30\n",
      "520/520 [==============================] - 169s 324ms/step - loss: 0.0781 - accuracy: 0.9751 - val_loss: 0.1417 - val_accuracy: 0.9542\n",
      "Epoch 20/30\n",
      "520/520 [==============================] - 169s 324ms/step - loss: 0.0750 - accuracy: 0.9761 - val_loss: 0.1380 - val_accuracy: 0.9558\n",
      "Epoch 21/30\n",
      "520/520 [==============================] - 169s 324ms/step - loss: 0.0732 - accuracy: 0.9765 - val_loss: 0.1394 - val_accuracy: 0.9559\n",
      "Epoch 22/30\n",
      "520/520 [==============================] - 169s 325ms/step - loss: 0.0717 - accuracy: 0.9767 - val_loss: 0.1408 - val_accuracy: 0.9561\n",
      "Epoch 23/30\n",
      "520/520 [==============================] - 169s 325ms/step - loss: 0.0754 - accuracy: 0.9762 - val_loss: 0.1433 - val_accuracy: 0.9539\n",
      "Epoch 24/30\n",
      "520/520 [==============================] - 169s 325ms/step - loss: 0.0694 - accuracy: 0.9776 - val_loss: 0.1402 - val_accuracy: 0.9535\n",
      "Epoch 25/30\n",
      "520/520 [==============================] - 169s 325ms/step - loss: 0.0717 - accuracy: 0.9774 - val_loss: 0.1405 - val_accuracy: 0.9543\n",
      "Epoch 26/30\n",
      "520/520 [==============================] - 169s 325ms/step - loss: 0.0673 - accuracy: 0.9796 - val_loss: 0.1377 - val_accuracy: 0.9558\n",
      "Epoch 27/30\n",
      "520/520 [==============================] - 169s 325ms/step - loss: 0.0685 - accuracy: 0.9780 - val_loss: 0.1412 - val_accuracy: 0.9556\n",
      "Epoch 28/30\n",
      "520/520 [==============================] - 169s 325ms/step - loss: 0.0670 - accuracy: 0.9789 - val_loss: 0.1395 - val_accuracy: 0.9555\n",
      "Epoch 29/30\n",
      "520/520 [==============================] - 169s 325ms/step - loss: 0.0684 - accuracy: 0.9780 - val_loss: 0.1413 - val_accuracy: 0.9555\n",
      "Epoch 30/30\n",
      "520/520 [==============================] - 168s 323ms/step - loss: 0.0680 - accuracy: 0.9782 - val_loss: 0.1413 - val_accuracy: 0.9554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdbf43c5e48>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(.0001, momentum=.9, nesterov=True), loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_dataset,\n",
    "          epochs=30,\n",
    "          steps_per_epoch=TRAIN_SIZE//global_batch_size,\n",
    "          validation_data=test_dataset, \n",
    "          validation_steps=VALIDATION_SIZE//global_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_90 (SeparableConv2D)   (None, None, None, 6 4736        conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "relu_90 (ReLU)                  (None, None, None, 6 0           sep_conv_90[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_91 (SeparableConv2D)   (None, None, None, 6 4736        relu_90[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_91 (ReLU)                  (None, None, None, 6 0           sep_conv_91[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       relu_91[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_88 (SeparableConv2D)   (None, None, None, 6 4736        conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "relu_88 (ReLU)                  (None, None, None, 6 0           sep_conv_88[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_89 (SeparableConv2D)   (None, None, None, 6 4736        relu_88[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_89 (ReLU)                  (None, None, None, 6 0           sep_conv_89[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       relu_89[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_86 (SeparableConv2D)   (None, None, None, 6 4736        conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "relu_86 (ReLU)                  (None, None, None, 6 0           sep_conv_86[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_87 (SeparableConv2D)   (None, None, None, 6 4736        relu_86[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_87 (ReLU)                  (None, None, None, 6 0           sep_conv_87[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       relu_87[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_84 (SeparableConv2D)   (None, None, None, 1 17664       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "relu_84 (ReLU)                  (None, None, None, 1 0           sep_conv_84[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_85 (SeparableConv2D)   (None, None, None, 1 17664       relu_84[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_85 (ReLU)                  (None, None, None, 1 0           sep_conv_85[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       relu_85[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_82 (SeparableConv2D)   (None, None, None, 1 17664       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "relu_82 (ReLU)                  (None, None, None, 1 0           sep_conv_82[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_83 (SeparableConv2D)   (None, None, None, 1 17664       relu_82[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_83 (ReLU)                  (None, None, None, 1 0           sep_conv_83[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       relu_83[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_80 (SeparableConv2D)   (None, None, None, 1 17664       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "relu_80 (ReLU)                  (None, None, None, 1 0           sep_conv_80[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_81 (SeparableConv2D)   (None, None, None, 1 17664       relu_80[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_81 (ReLU)                  (None, None, None, 1 0           sep_conv_81[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       relu_81[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_78 (SeparableConv2D)   (None, None, None, 1 17664       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "relu_78 (ReLU)                  (None, None, None, 1 0           sep_conv_78[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_79 (SeparableConv2D)   (None, None, None, 1 17664       relu_78[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_79 (ReLU)                  (None, None, None, 1 0           sep_conv_79[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       relu_79[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_76 (SeparableConv2D)   (None, None, None, 2 68096       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "relu_76 (ReLU)                  (None, None, None, 2 0           sep_conv_76[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_77 (SeparableConv2D)   (None, None, None, 2 68096       relu_76[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_77 (ReLU)                  (None, None, None, 2 0           sep_conv_77[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      relu_77[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_74 (SeparableConv2D)   (None, None, None, 2 68096       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "relu_74 (ReLU)                  (None, None, None, 2 0           sep_conv_74[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_75 (SeparableConv2D)   (None, None, None, 2 68096       relu_74[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_75 (ReLU)                  (None, None, None, 2 0           sep_conv_75[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      relu_75[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_72 (SeparableConv2D)   (None, None, None, 2 68096       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "relu_72 (ReLU)                  (None, None, None, 2 0           sep_conv_72[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_73 (SeparableConv2D)   (None, None, None, 2 68096       relu_72[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_73 (ReLU)                  (None, None, None, 2 0           sep_conv_73[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      relu_73[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_70 (SeparableConv2D)   (None, None, None, 2 68096       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "relu_70 (ReLU)                  (None, None, None, 2 0           sep_conv_70[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_71 (SeparableConv2D)   (None, None, None, 2 68096       relu_70[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_71 (ReLU)                  (None, None, None, 2 0           sep_conv_71[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      relu_71[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_68 (SeparableConv2D)   (None, None, None, 2 68096       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "relu_68 (ReLU)                  (None, None, None, 2 0           sep_conv_68[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_69 (SeparableConv2D)   (None, None, None, 2 68096       relu_68[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_69 (ReLU)                  (None, None, None, 2 0           sep_conv_69[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      relu_69[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_66 (SeparableConv2D)   (None, None, None, 2 68096       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "relu_66 (ReLU)                  (None, None, None, 2 0           sep_conv_66[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_67 (SeparableConv2D)   (None, None, None, 2 68096       relu_66[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_67 (ReLU)                  (None, None, None, 2 0           sep_conv_67[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      relu_67[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_64 (SeparableConv2D)   (None, None, None, 5 267264      conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "relu_64 (ReLU)                  (None, None, None, 5 0           sep_conv_64[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_65 (SeparableConv2D)   (None, None, None, 5 267264      relu_64[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_65 (ReLU)                  (None, None, None, 5 0           sep_conv_65[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     relu_65[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_62 (SeparableConv2D)   (None, None, None, 5 267264      conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "relu_62 (ReLU)                  (None, None, None, 5 0           sep_conv_62[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_63 (SeparableConv2D)   (None, None, None, 5 267264      relu_62[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_63 (ReLU)                  (None, None, None, 5 0           sep_conv_63[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     relu_63[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           20490       global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 10)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 16,689,866\n",
      "Trainable params: 16,643,274\n",
      "Non-trainable params: 46,592\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = tf.keras.models.load_model('base_model_cifar10_resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = tf.keras.models.load_model('base_model_cifar10_resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           20490       global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 10)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 23,555,082\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "original.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of resnet_compression_playground.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00bbf559bc2b4382a8f8cc7efec1e215": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c17f9a971b5b4b25ae18d6cde04f210b",
      "placeholder": "​",
      "style": "IPY_MODEL_aeb85b20a90e4d9bb284c8dec0143d16",
      "value": " 5000/? [00:00&lt;00:00, 139267.92 examples/s]"
     }
    },
    "00ea0dbf84e84d96af7065bfb535faba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6ff5a866f4424ab699f7320d228b3624",
       "IPY_MODEL_e942eb48d26f44f8a255b030b8523426"
      ],
      "layout": "IPY_MODEL_faab1fbeb7324d07a5532654955162c0"
     }
    },
    "01df06a2707a486a99028df405c4cf17": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "037d640ac4344184acd4dbd27f3d1e65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Dl Completed...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01df06a2707a486a99028df405c4cf17",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c882433eb399416b860cbd6e81ef29ef",
      "value": 1
     }
    },
    "050aacaf209547d0bc9899c6f3f4d604": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6fd2321c588b4d6a88d217b38f7913b4",
       "IPY_MODEL_e51abbcd797a4f22a31f322979a1a821"
      ],
      "layout": "IPY_MODEL_8c5e71a92ff4497aa6163288cf7ede91"
     }
    },
    "061c75d2a6c0422881c00dcf2078c42a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0cd4f58e1c2c466e971f7be8d6d35768",
       "IPY_MODEL_76e757f0395e46b29cca95688d2279e8"
      ],
      "layout": "IPY_MODEL_b6b7230688334a79a95670ca8cbf5b45"
     }
    },
    "088197bb7e574f9a9777596e3eff2e7a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bcb0f74d29c48daa5580e3a00b920c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Reading...: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8b079b263ec46d7a8a545d45beb9f57",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_913be084e16e46b5b56a60e6bf3fec65",
      "value": 1
     }
    },
    "0cd4f58e1c2c466e971f7be8d6d35768": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Writing...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89972f1978be44d893c42720b83cc758",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bfc07890a6124155891b4180012ff16a",
      "value": 5000
     }
    },
    "1235e70c7520425fa23d470e34e6a418": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "136a59f531af4aff946c056d35d16cc1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1520a6bb52ac48269b13fc0154e56311": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "178f108b968647e69f4cfc8b92d58c6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "17f56706a93a4b3a889572a44f8ca2cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6b2973eb04484bd9be0d312b8b8cf795",
       "IPY_MODEL_fdad4d08019145bb8fabfc2a26581757"
      ],
      "layout": "IPY_MODEL_dd3e90b7e53e4f5d9b3ce02e7e66b04c"
     }
    },
    "196648347fb74e668b9e205f3afc157a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a7a8f8f906a45a0b469682fda4d5b48": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1cd3102e4bcb4852a131fcf237a4f823": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d6de2d069cb40469647afe97dbedafa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e925e3031b84395ad9d91cf620c1aee": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20dae69db80943bbb771468b2dd3bbd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a7e0f33ef31340e08c5d054d757f7ff7",
       "IPY_MODEL_b532e0d5f5bb4fe48e5837b24089cbc4"
      ],
      "layout": "IPY_MODEL_4d882e72c59f414a8a5592f6820793f0"
     }
    },
    "2213f20428444ffe91ea8ec4fca4d937": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "22ea888608bb446e9047981855ee06aa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2319ccc93aa54b4a84de0fd0f8638278": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23353a3aa8b948fa82f8aef2127170a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7c0ed0caa2044d5d97d36df4437342b3",
       "IPY_MODEL_2e1fd6599f5844ab954a8342222f6d41"
      ],
      "layout": "IPY_MODEL_37d80bb8cf0a40f1991c2029d050d8a4"
     }
    },
    "2363abb3bee745a292a8b313016b9d37": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2547014e99a0411cbce96d806b7eec8e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26d8caefc8754651abf70d13d6fc16ce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26dba2cdb1594b728eaa5cbdafe00c6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_abb6ef548f64470e919e3b09b8266bcb",
      "placeholder": "​",
      "style": "IPY_MODEL_7ccbd3d75d1c4cb08c0cb291086c047c",
      "value": " 5000/5000 [00:00&lt;00:00, 106737.79 examples/s]"
     }
    },
    "27e833a113b74846906f34612ab4ab3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Shuffling...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aed75a1fb79a4f08861245ae4927a57e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2213f20428444ffe91ea8ec4fca4d937",
      "value": 1
     }
    },
    "28dca6cd4300492a8e8f13a0e41ccd22": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29fe3ee019404fea8d836ad8142bf1bb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a4bf872871045e28f58266aff72db3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a81db0a5e874d2ab27702967997add4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92c5f2bbaf594a70b4a484d1927ea636",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_319b7e4dbdaf43359fa5d4e244f16e74",
      "value": 1
     }
    },
    "2ab619854393458f89b10cf629d66f16": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1cd3102e4bcb4852a131fcf237a4f823",
      "placeholder": "​",
      "style": "IPY_MODEL_363269bd4c2648068daeeccc55eb4362",
      "value": " 5000/? [00:00&lt;00:00, 140660.66 examples/s]"
     }
    },
    "2e1fd6599f5844ab954a8342222f6d41": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2547014e99a0411cbce96d806b7eec8e",
      "placeholder": "​",
      "style": "IPY_MODEL_f207995c4dbe4806884d759e9a70edde",
      "value": " 10000/? [00:00&lt;00:00, 197142.44 examples/s]"
     }
    },
    "2fbe8b93ad484562a5f560e1ac30a98c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3037c2a0ab13465281680dd390aded89": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3071e0a0a0584f298e6dc73dfe5a9574": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Reading...: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bebcb612c1454e47892a9686eb4c5c57",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_593fc579dec14f5d8f39a75e0d8a4445",
      "value": 1
     }
    },
    "319b7e4dbdaf43359fa5d4e244f16e74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "327614665cd44d5c8e499d15deabdb54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3309caa1185749b8a4cc046052312f28": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3345eb5900d84a36ae7e0dc842086b69": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29fe3ee019404fea8d836ad8142bf1bb",
      "placeholder": "​",
      "style": "IPY_MODEL_ad695bf29ce04fa3914d0cfb98cfa271",
      "value": " 5000/? [00:00&lt;00:00, 130566.06 examples/s]"
     }
    },
    "34f27f156c7f443093ca85f20332444e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "351ff6e9d03c49fa9407956ccdf55882": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_490491523e3d429cb3d138f597ec30ea",
      "placeholder": "​",
      "style": "IPY_MODEL_3a3a67866dfb4140be51c74d530be281",
      "value": " 5000/5000 [00:00&lt;00:00, 120946.51 examples/s]"
     }
    },
    "35c068fdce914e60a3d3b90bb54616e4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "363269bd4c2648068daeeccc55eb4362": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37d80bb8cf0a40f1991c2029d050d8a4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a3a67866dfb4140be51c74d530be281": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3afe7a98e460439c8d2d137664cb644d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Writing...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e24526fcc2c34fbe93bc3201472aacd3",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f314b77939d94027b5279559e8d439e9",
      "value": 5000
     }
    },
    "3b5e718e47564e63a5b445b785050af8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e95c14ba2c134328bb5cc9e47e96c849",
       "IPY_MODEL_00bbf559bc2b4382a8f8cc7efec1e215"
      ],
      "layout": "IPY_MODEL_8cb85ec15c1642088b913b0df8418569"
     }
    },
    "3bf80b32406e40cf8777f027aa0fcb67": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c99e900eb4b49759d39221f3b97057f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b607cbe7df244c3aaf5a407bc25ec6b",
      "placeholder": "​",
      "style": "IPY_MODEL_6b0705a1c162438fa01dc8723ab7cf39",
      "value": " 5000/? [00:00&lt;00:00, 142369.94 examples/s]"
     }
    },
    "3c9d01b657df4e8fa99b5a905225a5ca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d86e7fe99444af8ba96666a06a5d048": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ebb2da0813c470b815d537b0fde2f5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a470465eeb243358efd8260502d9da2",
      "placeholder": "​",
      "style": "IPY_MODEL_59e5e76bf0a84fd99ef61df58cf6aa74",
      "value": " 5000/5000 [00:00&lt;00:00, 115827.64 examples/s]"
     }
    },
    "3f064a661b064c9dbe8565226d6e8b57": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ff0c249f9014799babc3d99627e50f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b30f8f0caa4437f83e07be0429cf06f",
      "placeholder": "​",
      "style": "IPY_MODEL_ef78e1d4fdb947c9940eac1944c8ea32",
      "value": " 5000/? [00:00&lt;00:00, 144569.36 examples/s]"
     }
    },
    "445a35e0d6744ea09f15c2d434726f38": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44d14ef9e5064e548fa1a1ba6b9e0bd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ffa8e1877134430c973c9d605406dd2c",
      "placeholder": "​",
      "style": "IPY_MODEL_c7111c5161464283aa9075cecddeab22",
      "value": " 162/162 [00:29&lt;00:00,  5.57 MiB/s]"
     }
    },
    "457d3c84187c48d580f3f58898a65020": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "488530f0e5464c6881a96624fcb3f104": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "490491523e3d429cb3d138f597ec30ea": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "494b5bde4c4c48c5ad384603eae6aef3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Writing...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9521dbb25a443f1839db5fbc7676e77",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e11c504fc39146138d3dc43df5fd6bc4",
      "value": 5000
     }
    },
    "4b58120421154f5bafdb685bc27f0291": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4be93a6d768645e5ad4f1b4d1502d908": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c7737be5fac490ca86d490a617ad2d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d21268bcab14126a9ea6fac94831b84": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_457d3c84187c48d580f3f58898a65020",
      "placeholder": "​",
      "style": "IPY_MODEL_2a4bf872871045e28f58266aff72db3f",
      "value": " 1/1 [00:00&lt;00:00,  4.61 shard/s]"
     }
    },
    "4d4db9b8c8fb4351be91b3700431d081": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d882e72c59f414a8a5592f6820793f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50fe61b368464dc1aac03d2f5a9b3353": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Reading...: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a7a8f8f906a45a0b469682fda4d5b48",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cccea809b5cb43ceb227477a50827d73",
      "value": 1
     }
    },
    "56986dc4f2254c67af73140ca4dfedbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5820293dba6e46f482464ced31ab9d00": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_75dd9abf182246e3993d20832a564f52",
       "IPY_MODEL_3c99e900eb4b49759d39221f3b97057f"
      ],
      "layout": "IPY_MODEL_8804782648e947d59100306fd1cbb113"
     }
    },
    "593fc579dec14f5d8f39a75e0d8a4445": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "59e5e76bf0a84fd99ef61df58cf6aa74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b02c906910147b7af7f0dc54b4b948a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b30f8f0caa4437f83e07be0429cf06f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b607cbe7df244c3aaf5a407bc25ec6b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bd2c5a241d64785b2e22b1a2524e768": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71e7570521624ca6b48d751f4c02dda9",
      "placeholder": "​",
      "style": "IPY_MODEL_b2c7e622431d4b6e90761e83d537a85f",
      "value": " 5000/5000 [00:00&lt;00:00, 122387.11 examples/s]"
     }
    },
    "5e550bdef03b4b399a95794b90c0c6f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b78074873b24b17951a0cf621ee7398",
      "placeholder": "​",
      "style": "IPY_MODEL_ec7f49f9e75d44a78dff4dd544c262f4",
      "value": " 1/1 [00:29&lt;00:00, 29.04s/ file]"
     }
    },
    "6283aac770ee4f3099d3d296c48601b0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "645ff814089b424ea3da696f6e219815": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6631d750d8cc40d3913134626f89176e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6822853cea6d4a6e95575f6950330be2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69cba96b0f4a4686be29d62d8c9b342d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6a141d5397e8415eb4dd45b69efabcce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Reading...: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0a7f7d0162042b5b411703c3e00ecc5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_deadeff67052419cb78bee3638fc2abf",
      "value": 1
     }
    },
    "6a24850934ca4c32b3caf4534103a529": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_088197bb7e574f9a9777596e3eff2e7a",
      "placeholder": "​",
      "style": "IPY_MODEL_9551c270aed34b9080308cf79245c15a",
      "value": " 5000/? [00:00&lt;00:00, 118932.69 examples/s]"
     }
    },
    "6b0705a1c162438fa01dc8723ab7cf39": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b2973eb04484bd9be0d312b8b8cf795": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Shuffling...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d86e7fe99444af8ba96666a06a5d048",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b3fcf5db95c4c6396dcdf682a2358cc",
      "value": 10
     }
    },
    "6b3fcf5db95c4c6396dcdf682a2358cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6badd05a454f4d55941d941cf8549357": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6bf9513279eb41b1955eb80a2cb88d6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Reading...: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b23f4177df314748b1d89a8d517483da",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dc066bc0384747c2bb5cc9e38cc83fe9",
      "value": 1
     }
    },
    "6c286d9756054a60a77124df7cf49357": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fd2321c588b4d6a88d217b38f7913b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Reading...: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22ea888608bb446e9047981855ee06aa",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3037c2a0ab13465281680dd390aded89",
      "value": 1
     }
    },
    "6ff5a866f4424ab699f7320d228b3624": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Writing...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aef0f19968184c6b9265f740a35a26f6",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6badd05a454f4d55941d941cf8549357",
      "value": 10000
     }
    },
    "7137ed2e9650437e8b46124c4a291194": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Writing...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc231257ca024a76abc7fb01987e1a80",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1520a6bb52ac48269b13fc0154e56311",
      "value": 5000
     }
    },
    "718b66ad3bb647e086e0763657c6adc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_80914034cd9d4b84bf9a86cbfa92dcb0",
       "IPY_MODEL_fe098d028b6148dfb24c8d76f8defa5d"
      ],
      "layout": "IPY_MODEL_e5f4852f417b493daa2363dc89aba6ad"
     }
    },
    "71e7570521624ca6b48d751f4c02dda9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72d73c0a269643f38f41f7168b2b7273": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "749e5f565efe4925aa792ec8dc317dae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Writing...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa68b8c8d9f34d8193ab02c53e997c6a",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f1ee8b521d7416eb5fe9d6a14ed83f5",
      "value": 5000
     }
    },
    "7571f585dcaf412c8fabfe3da4e90a72": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_494b5bde4c4c48c5ad384603eae6aef3",
       "IPY_MODEL_7a18bce53be24c3a8d79f44cb78f76c0"
      ],
      "layout": "IPY_MODEL_2319ccc93aa54b4a84de0fd0f8638278"
     }
    },
    "75dd9abf182246e3993d20832a564f52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Reading...: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4abe08501cb485e88c0b7a1a34d66b1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9536d331871f4ab79b784bef66f480e8",
      "value": 1
     }
    },
    "75ed948182124fd88ac3383684630432": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76e757f0395e46b29cca95688d2279e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6283aac770ee4f3099d3d296c48601b0",
      "placeholder": "​",
      "style": "IPY_MODEL_e2933054e28c460eae2888ef050c8f3b",
      "value": " 5000/5000 [00:00&lt;00:00, 101569.29 examples/s]"
     }
    },
    "7968af4d08a84ee688361761964f0ce0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79de1f81bfd945cea860042f08b09c20": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a18bce53be24c3a8d79f44cb78f76c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28dca6cd4300492a8e8f13a0e41ccd22",
      "placeholder": "​",
      "style": "IPY_MODEL_871123b141d8405580c1a0b47c8f193c",
      "value": " 5000/5000 [00:00&lt;00:00, 121240.88 examples/s]"
     }
    },
    "7a470465eeb243358efd8260502d9da2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b98191fb51d4a3aae1cf1dcf546448c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c0ed0caa2044d5d97d36df4437342b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Reading...: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2abbd1283984189aaf562eff5dd563e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_34f27f156c7f443093ca85f20332444e",
      "value": 1
     }
    },
    "7cca8a3371284de9871a0bafec58b618": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e925e3031b84395ad9d91cf620c1aee",
      "placeholder": "​",
      "style": "IPY_MODEL_72d73c0a269643f38f41f7168b2b7273",
      "value": " 50000/? [00:17&lt;00:00, 2827.38 examples/s]"
     }
    },
    "7ccbd3d75d1c4cb08c0cb291086c047c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7cd9023fe33a4f19bc45c8529e33002c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Writing...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8fdaed4cca534c7a87d82bbdb756d255",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_178f108b968647e69f4cfc8b92d58c6f",
      "value": 5000
     }
    },
    "7dad383ee1744684addc94a7196cfc27": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e029e943a4c4ce0bf706aacb526f427": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e920f480a3b6466fa3d97a312b2c593e",
       "IPY_MODEL_c7d7e95fe9264adeb95c249b4c87b746"
      ],
      "layout": "IPY_MODEL_9e9bfd6e60264400a6ee1903b435b276"
     }
    },
    "801e08b3293646b7be3b3551dcc6a814": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80914034cd9d4b84bf9a86cbfa92dcb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Writing...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35c068fdce914e60a3d3b90bb54616e4",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4b58120421154f5bafdb685bc27f0291",
      "value": 5000
     }
    },
    "8143f2874af440a5bbf44763e9e8d88d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8444725e7bc04db18ad12ec10b8200f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_749e5f565efe4925aa792ec8dc317dae",
       "IPY_MODEL_5bd2c5a241d64785b2e22b1a2524e768"
      ],
      "layout": "IPY_MODEL_9788f736aed049c286ba5f5c5e3e7132"
     }
    },
    "8529c01dc6d74199bf27620d0e0bed75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7cd9023fe33a4f19bc45c8529e33002c",
       "IPY_MODEL_e9c899f4ac254c41b9e97242f331cf65"
      ],
      "layout": "IPY_MODEL_a064129c1e2844fd8102a0ba2b3605f0"
     }
    },
    "85b3369294534e9a9ba5688aefa6b4a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_037d640ac4344184acd4dbd27f3d1e65",
       "IPY_MODEL_89f1b8ed63c3489198e17b8e8ab2be81"
      ],
      "layout": "IPY_MODEL_6822853cea6d4a6e95575f6950330be2"
     }
    },
    "86e1e68d54394142a94fa4e405116ace": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6bf9513279eb41b1955eb80a2cb88d6b",
       "IPY_MODEL_2ab619854393458f89b10cf629d66f16"
      ],
      "layout": "IPY_MODEL_7b98191fb51d4a3aae1cf1dcf546448c"
     }
    },
    "871123b141d8405580c1a0b47c8f193c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8804782648e947d59100306fd1cbb113": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "886b091d3c504c93b39596cd8ce52345": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89972f1978be44d893c42720b83cc758": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89f1b8ed63c3489198e17b8e8ab2be81": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7968af4d08a84ee688361761964f0ce0",
      "placeholder": "​",
      "style": "IPY_MODEL_6631d750d8cc40d3913134626f89176e",
      "value": " 1/1 [00:29&lt;00:00, 29.08s/ url]"
     }
    },
    "8c5e71a92ff4497aa6163288cf7ede91": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cb85ec15c1642088b913b0df8418569": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8dd41daa3cbd4b5498f1218db858546f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fadedd1c55a432c96905e2bb68282e0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fdaed4cca534c7a87d82bbdb756d255": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "913be084e16e46b5b56a60e6bf3fec65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "92c5f2bbaf594a70b4a484d1927ea636": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "932df094e004439490a17f21ab36d951": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93e8cf3b87a9438785fa91bcf741f63a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "94d26bdc3d3f49adbc2929876737643d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa48a8c281df4b32b69cbb6c57ab3bc6",
       "IPY_MODEL_26dba2cdb1594b728eaa5cbdafe00c6d"
      ],
      "layout": "IPY_MODEL_75ed948182124fd88ac3383684630432"
     }
    },
    "9536d331871f4ab79b784bef66f480e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9551c270aed34b9080308cf79245c15a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "973972ee071f4177b78d8c360db6bc16": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3309caa1185749b8a4cc046052312f28",
      "placeholder": "​",
      "style": "IPY_MODEL_56986dc4f2254c67af73140ca4dfedbc",
      "value": " 5000/? [00:00&lt;00:00, 143020.47 examples/s]"
     }
    },
    "9788f736aed049c286ba5f5c5e3e7132": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99ffcf9dd93f4cfbb3ceddc2bb641054": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b78074873b24b17951a0cf621ee7398": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9deb7e94f2e74480ac22752417dccbf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9e9bfd6e60264400a6ee1903b435b276": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f1ee8b521d7416eb5fe9d6a14ed83f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a01bfa27d30c4893b93b93b990a9db8b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a064129c1e2844fd8102a0ba2b3605f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0eec14ac94744c598bf2cef825cae25": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1073d8a8f2448cf98493ac47ffc6c97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7137ed2e9650437e8b46124c4a291194",
       "IPY_MODEL_351ff6e9d03c49fa9407956ccdf55882"
      ],
      "layout": "IPY_MODEL_8dd41daa3cbd4b5498f1218db858546f"
     }
    },
    "a13da48b270f412e95427f399e6e172c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0bcb0f74d29c48daa5580e3a00b920c5",
       "IPY_MODEL_6a24850934ca4c32b3caf4534103a529"
      ],
      "layout": "IPY_MODEL_79de1f81bfd945cea860042f08b09c20"
     }
    },
    "a164b382a8934cdb922318d53f4f2d5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b05976a78a694bcb8d6f3c427af2a428",
       "IPY_MODEL_44d14ef9e5064e548fa1a1ba6b9e0bd2"
      ],
      "layout": "IPY_MODEL_8fadedd1c55a432c96905e2bb68282e0"
     }
    },
    "a1e4a810cdd9474eaa76e25b3ef8d387": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c18c87dd3f1d44769263a45094f633f1",
       "IPY_MODEL_5e550bdef03b4b399a95794b90c0c6f5"
      ],
      "layout": "IPY_MODEL_196648347fb74e668b9e205f3afc157a"
     }
    },
    "a2abbd1283984189aaf562eff5dd563e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a34e1edc304b420f8bf278189c79d163": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dcb1e0ef4eb14de48c26262195c9ced9",
       "IPY_MODEL_3345eb5900d84a36ae7e0dc842086b69"
      ],
      "layout": "IPY_MODEL_801e08b3293646b7be3b3551dcc6a814"
     }
    },
    "a7e0f33ef31340e08c5d054d757f7ff7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c7737be5fac490ca86d490a617ad2d3",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c792ac14b5114d9b842d929b46c187bf",
      "value": 1
     }
    },
    "aa2bfdf132884c778be3168c59d030df": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab0e9d315b1d4ba6ae3af8c4eaac5caf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cf649c70c2114fddb27c86a3562b271b",
       "IPY_MODEL_3ff0c249f9014799babc3d99627e50f8"
      ],
      "layout": "IPY_MODEL_3f064a661b064c9dbe8565226d6e8b57"
     }
    },
    "abb6ef548f64470e919e3b09b8266bcb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad695bf29ce04fa3914d0cfb98cfa271": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aeb85b20a90e4d9bb284c8dec0143d16": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aed75a1fb79a4f08861245ae4927a57e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aef0f19968184c6b9265f740a35a26f6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b003544ca82c4aa8955367d28e6beab3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b05976a78a694bcb8d6f3c427af2a428": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Dl Size...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ccfe163873d944f98cae06a04e4120d2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b5d613d984154ad394dfa15aec5b03e2",
      "value": 1
     }
    },
    "b23f4177df314748b1d89a8d517483da": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2c7e622431d4b6e90761e83d537a85f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b532e0d5f5bb4fe48e5837b24089cbc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d6de2d069cb40469647afe97dbedafa",
      "placeholder": "​",
      "style": "IPY_MODEL_bb8b22d4b2bf451f895bbb5fe58f0d5c",
      "value": " 10000/? [00:03&lt;00:00, 2817.40 examples/s]"
     }
    },
    "b5d613d984154ad394dfa15aec5b03e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b6b7230688334a79a95670ca8cbf5b45": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb8b22d4b2bf451f895bbb5fe58f0d5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bebcb612c1454e47892a9686eb4c5c57": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf37f4c25df0407fb8500e88656fef12": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bfc07890a6124155891b4180012ff16a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c09bd93b56524a169a638ed6304854aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3071e0a0a0584f298e6dc73dfe5a9574",
       "IPY_MODEL_973972ee071f4177b78d8c360db6bc16"
      ],
      "layout": "IPY_MODEL_b003544ca82c4aa8955367d28e6beab3"
     }
    },
    "c17f9a971b5b4b25ae18d6cde04f210b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18c87dd3f1d44769263a45094f633f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Extraction completed...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2363abb3bee745a292a8b313016b9d37",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_69cba96b0f4a4686be29d62d8c9b342d",
      "value": 1
     }
    },
    "c229e5748afa453986e6a4ec0412eea4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4abe08501cb485e88c0b7a1a34d66b1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7111c5161464283aa9075cecddeab22": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c792ac14b5114d9b842d929b46c187bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c7d7e95fe9264adeb95c249b4c87b746": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c286d9756054a60a77124df7cf49357",
      "placeholder": "​",
      "style": "IPY_MODEL_d9d25f537a9949a2ae272159cf26fd77",
      "value": " 5000/5000 [00:00&lt;00:00, 110531.16 examples/s]"
     }
    },
    "c882433eb399416b860cbd6e81ef29ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cccea809b5cb43ceb227477a50827d73": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ccf20edd1af245b39937aaa40fdf31f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6a141d5397e8415eb4dd45b69efabcce",
       "IPY_MODEL_f8406bd06c1047009746d0d5336d9073"
      ],
      "layout": "IPY_MODEL_645ff814089b424ea3da696f6e219815"
     }
    },
    "ccfe163873d944f98cae06a04e4120d2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd3d52f58a43462d871d2f3ba46e7337": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd6df235ab5b4eb2b7751d73e3b95328": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cf649c70c2114fddb27c86a3562b271b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Reading...: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa2bfdf132884c778be3168c59d030df",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9deb7e94f2e74480ac22752417dccbf1",
      "value": 1
     }
    },
    "d2a9b67bea774176a8ea7b8a527c9244": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5c79dc23c2a4ebfa2b05653eeb48172": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_50fe61b368464dc1aac03d2f5a9b3353",
       "IPY_MODEL_f1ee35450304428eae8445e012e06c62"
      ],
      "layout": "IPY_MODEL_136a59f531af4aff946c056d35d16cc1"
     }
    },
    "d7d2796702524d30b526b31c54052ca8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8b079b263ec46d7a8a545d45beb9f57": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9521dbb25a443f1839db5fbc7676e77": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9d25f537a9949a2ae272159cf26fd77": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc066bc0384747c2bb5cc9e38cc83fe9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "dc231257ca024a76abc7fb01987e1a80": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcb1e0ef4eb14de48c26262195c9ced9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Reading...: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7d2796702524d30b526b31c54052ca8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8143f2874af440a5bbf44763e9e8d88d",
      "value": 1
     }
    },
    "dd3e90b7e53e4f5d9b3ce02e7e66b04c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "deadeff67052419cb78bee3638fc2abf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "df2f582d95e64f38b43f6e46c304b58b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e00625c08d424230abc03200b127fa99": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0a7f7d0162042b5b411703c3e00ecc5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e11c504fc39146138d3dc43df5fd6bc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e24526fcc2c34fbe93bc3201472aacd3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2933054e28c460eae2888ef050c8f3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e51abbcd797a4f22a31f322979a1a821": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1235e70c7520425fa23d470e34e6a418",
      "placeholder": "​",
      "style": "IPY_MODEL_5b02c906910147b7af7f0dc54b4b948a",
      "value": " 5000/? [00:00&lt;00:00, 137378.53 examples/s]"
     }
    },
    "e5f4852f417b493daa2363dc89aba6ad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6eb8c0850fb4aaf8470b98b2f1a9590": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8f93da361554abea6cb1397d8efcc63": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Writing...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c9d01b657df4e8fa99b5a905225a5ca",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_93e8cf3b87a9438785fa91bcf741f63a",
      "value": 5000
     }
    },
    "e920f480a3b6466fa3d97a312b2c593e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Writing...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0eec14ac94744c598bf2cef825cae25",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd6df235ab5b4eb2b7751d73e3b95328",
      "value": 5000
     }
    },
    "e942eb48d26f44f8a255b030b8523426": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_886b091d3c504c93b39596cd8ce52345",
      "placeholder": "​",
      "style": "IPY_MODEL_e9b5734a4ed34779a19e89ef23b91191",
      "value": " 10000/10000 [00:00&lt;00:00, 142174.98 examples/s]"
     }
    },
    "e94eb88a34b447f79b67e4dc0f437084": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2a81db0a5e874d2ab27702967997add4",
       "IPY_MODEL_7cca8a3371284de9871a0bafec58b618"
      ],
      "layout": "IPY_MODEL_d2a9b67bea774176a8ea7b8a527c9244"
     }
    },
    "e95c14ba2c134328bb5cc9e47e96c849": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Reading...: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_932df094e004439490a17f21ab36d951",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df2f582d95e64f38b43f6e46c304b58b",
      "value": 1
     }
    },
    "e9665f28c72642e18a8a019e1fca2ca1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e8f93da361554abea6cb1397d8efcc63",
       "IPY_MODEL_3ebb2da0813c470b815d537b0fde2f5a"
      ],
      "layout": "IPY_MODEL_4be93a6d768645e5ad4f1b4d1502d908"
     }
    },
    "e990e901afaf46ccbfd1bee97ace949d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_27e833a113b74846906f34612ab4ab3b",
       "IPY_MODEL_4d21268bcab14126a9ea6fac94831b84"
      ],
      "layout": "IPY_MODEL_3bf80b32406e40cf8777f027aa0fcb67"
     }
    },
    "e9b5734a4ed34779a19e89ef23b91191": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9c899f4ac254c41b9e97242f331cf65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a01bfa27d30c4893b93b93b990a9db8b",
      "placeholder": "​",
      "style": "IPY_MODEL_488530f0e5464c6881a96624fcb3f104",
      "value": " 5000/5000 [00:00&lt;00:00, 121304.00 examples/s]"
     }
    },
    "ec710e458b094cfbbe4fc833eea8b0a8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec7f49f9e75d44a78dff4dd544c262f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef78e1d4fdb947c9940eac1944c8ea32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "efe1da6d661c4ad29804e15499822646": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec710e458b094cfbbe4fc833eea8b0a8",
      "placeholder": "​",
      "style": "IPY_MODEL_e00625c08d424230abc03200b127fa99",
      "value": " 5000/5000 [00:00&lt;00:00, 118471.79 examples/s]"
     }
    },
    "f1ee35450304428eae8445e012e06c62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6eb8c0850fb4aaf8470b98b2f1a9590",
      "placeholder": "​",
      "style": "IPY_MODEL_4d4db9b8c8fb4351be91b3700431d081",
      "value": " 5000/? [00:00&lt;00:00, 134488.86 examples/s]"
     }
    },
    "f207995c4dbe4806884d759e9a70edde": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f314b77939d94027b5279559e8d439e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f8406bd06c1047009746d0d5336d9073": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26d8caefc8754651abf70d13d6fc16ce",
      "placeholder": "​",
      "style": "IPY_MODEL_99ffcf9dd93f4cfbb3ceddc2bb641054",
      "value": " 5000/? [00:00&lt;00:00, 122470.01 examples/s]"
     }
    },
    "f8d0898ddeda41dd8da824b5f328af1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3afe7a98e460439c8d2d137664cb644d",
       "IPY_MODEL_efe1da6d661c4ad29804e15499822646"
      ],
      "layout": "IPY_MODEL_7dad383ee1744684addc94a7196cfc27"
     }
    },
    "fa48a8c281df4b32b69cbb6c57ab3bc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Writing...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c229e5748afa453986e6a4ec0412eea4",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_327614665cd44d5c8e499d15deabdb54",
      "value": 5000
     }
    },
    "fa68b8c8d9f34d8193ab02c53e997c6a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "faab1fbeb7324d07a5532654955162c0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdad4d08019145bb8fabfc2a26581757": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_445a35e0d6744ea09f15c2d434726f38",
      "placeholder": "​",
      "style": "IPY_MODEL_bf37f4c25df0407fb8500e88656fef12",
      "value": " 10/10 [00:00&lt;00:00, 10.72 shard/s]"
     }
    },
    "fe098d028b6148dfb24c8d76f8defa5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2fbe8b93ad484562a5f560e1ac30a98c",
      "placeholder": "​",
      "style": "IPY_MODEL_cd3d52f58a43462d871d2f3ba46e7337",
      "value": " 5000/5000 [00:00&lt;00:00, 118007.14 examples/s]"
     }
    },
    "ffa8e1877134430c973c9d605406dd2c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
